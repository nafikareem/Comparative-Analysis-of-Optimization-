{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backhoe</th>\n",
       "      <th>HP(watt)</th>\n",
       "      <th>Norm_MAP</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Age</th>\n",
       "      <th>Load_Factor</th>\n",
       "      <th>Engine_Tier</th>\n",
       "      <th>TEMP[C]</th>\n",
       "      <th>Fuel[g/s]</th>\n",
       "      <th>NOx[g/s]</th>\n",
       "      <th>...</th>\n",
       "      <th>NOx[g/hr]</th>\n",
       "      <th>HC[g/hr]</th>\n",
       "      <th>CO[g/hr]</th>\n",
       "      <th>CO2[g/hr]</th>\n",
       "      <th>PM[mg/hr]</th>\n",
       "      <th>Nox (g/kl)</th>\n",
       "      <th>HC (g/kl)</th>\n",
       "      <th>CO (g/kl)</th>\n",
       "      <th>CO2 (g/kl)</th>\n",
       "      <th>PM (g/kl)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>833.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.024090</td>\n",
       "      <td>...</td>\n",
       "      <td>86.724000</td>\n",
       "      <td>25.848000</td>\n",
       "      <td>13.176000</td>\n",
       "      <td>4780.656000</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3730.117500</td>\n",
       "      <td>1111.757728</td>\n",
       "      <td>566.717728</td>\n",
       "      <td>2.056225e+05</td>\n",
       "      <td>0.619362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>800.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>...</td>\n",
       "      <td>109.152000</td>\n",
       "      <td>25.668000</td>\n",
       "      <td>16.164000</td>\n",
       "      <td>7008.264000</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4694.776362</td>\n",
       "      <td>1104.015681</td>\n",
       "      <td>695.235681</td>\n",
       "      <td>3.014350e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>826.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>...</td>\n",
       "      <td>110.628000</td>\n",
       "      <td>10.980000</td>\n",
       "      <td>10.584000</td>\n",
       "      <td>5722.920000</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4758.261138</td>\n",
       "      <td>472.264772</td>\n",
       "      <td>455.232272</td>\n",
       "      <td>2.461506e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>831.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.390522</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>...</td>\n",
       "      <td>85.293664</td>\n",
       "      <td>20.747853</td>\n",
       "      <td>4.825082</td>\n",
       "      <td>4382.553038</td>\n",
       "      <td>21.6</td>\n",
       "      <td>3668.596780</td>\n",
       "      <td>892.393432</td>\n",
       "      <td>207.533355</td>\n",
       "      <td>1.884996e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>834.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.413024</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>...</td>\n",
       "      <td>93.985262</td>\n",
       "      <td>6.979907</td>\n",
       "      <td>9.880556</td>\n",
       "      <td>4673.503069</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4042.434273</td>\n",
       "      <td>300.215326</td>\n",
       "      <td>424.976193</td>\n",
       "      <td>2.010137e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37523</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>...</td>\n",
       "      <td>211.788000</td>\n",
       "      <td>19.908000</td>\n",
       "      <td>28.152000</td>\n",
       "      <td>17957.592000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>445343.100000</td>\n",
       "      <td>41862.100000</td>\n",
       "      <td>59197.400000</td>\n",
       "      <td>3.776083e+07</td>\n",
       "      <td>3785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37524</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>...</td>\n",
       "      <td>214.200000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>30.780000</td>\n",
       "      <td>14905.044000</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>542545.340909</td>\n",
       "      <td>50151.250000</td>\n",
       "      <td>77962.397727</td>\n",
       "      <td>3.775286e+07</td>\n",
       "      <td>4194.468182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37525</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>...</td>\n",
       "      <td>214.704000</td>\n",
       "      <td>21.744000</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>17349.048000</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>469179.694118</td>\n",
       "      <td>47515.850980</td>\n",
       "      <td>73948.509804</td>\n",
       "      <td>3.791183e+07</td>\n",
       "      <td>4090.768627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37526</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>...</td>\n",
       "      <td>202.320000</td>\n",
       "      <td>22.356000</td>\n",
       "      <td>34.740000</td>\n",
       "      <td>19948.572000</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>384340.943182</td>\n",
       "      <td>42468.990341</td>\n",
       "      <td>65994.485795</td>\n",
       "      <td>3.789568e+07</td>\n",
       "      <td>3761.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37527</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>...</td>\n",
       "      <td>191.556000</td>\n",
       "      <td>21.168000</td>\n",
       "      <td>29.880000</td>\n",
       "      <td>19825.308000</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>365972.298857</td>\n",
       "      <td>40441.968000</td>\n",
       "      <td>57086.451429</td>\n",
       "      <td>3.787672e+07</td>\n",
       "      <td>3232.606286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37528 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backhoe  HP(watt)  Norm_MAP     RPM  Age  Load_Factor  Engine_Tier  \\\n",
       "0            1   65621.6  0.000000   833.0   12         0.21            2   \n",
       "1            1   65621.6  0.012346   800.0   12         0.21            2   \n",
       "2            1   65621.6  0.012346   826.0   12         0.21            2   \n",
       "3            1   65621.6  0.012346   831.0   12         0.21            2   \n",
       "4            1   65621.6  0.012346   834.0   12         0.21            2   \n",
       "...        ...       ...       ...     ...  ...          ...          ...   \n",
       "37523        8   72332.9  0.975904  1676.0   36         0.21            2   \n",
       "37524        8   72332.9  0.975904  1683.0   36         0.21            2   \n",
       "37525        8   72332.9  0.975904  1846.0   36         0.21            2   \n",
       "37526        8   72332.9  0.987952  1876.0   36         0.21            2   \n",
       "37527        8   72332.9  1.000000  1762.0   36         0.21            2   \n",
       "\n",
       "       TEMP[C]  Fuel[g/s]  NOx[g/s]  ...   NOx[g/hr]   HC[g/hr]   CO[g/hr]  \\\n",
       "0         22.0   0.430000  0.024090  ...   86.724000  25.848000  13.176000   \n",
       "1         22.0   0.620000  0.030320  ...  109.152000  25.668000  16.164000   \n",
       "2         22.0   0.510000  0.030730  ...  110.628000  10.980000  10.584000   \n",
       "3         22.0   0.390522  0.023693  ...   85.293664  20.747853   4.825082   \n",
       "4         22.0   0.413024  0.026107  ...   93.985262   6.979907   9.880556   \n",
       "...        ...        ...       ...  ...         ...        ...        ...   \n",
       "37523     41.0   1.590000  0.058830  ...  211.788000  19.908000  28.152000   \n",
       "37524     42.0   1.320000  0.059500  ...  214.200000  19.800000  30.780000   \n",
       "37525     42.0   1.530000  0.059640  ...  214.704000  21.744000  33.840000   \n",
       "37526     42.0   1.760000  0.056200  ...  202.320000  22.356000  34.740000   \n",
       "37527     42.0   1.750000  0.053210  ...  191.556000  21.168000  29.880000   \n",
       "\n",
       "          CO2[g/hr]  PM[mg/hr]     Nox (g/kl)     HC (g/kl)     CO (g/kl)  \\\n",
       "0       4780.656000       14.4    3730.117500   1111.757728    566.717728   \n",
       "1       7008.264000       21.6    4694.776362   1104.015681    695.235681   \n",
       "2       5722.920000       21.6    4758.261138    472.264772    455.232272   \n",
       "3       4382.553038       21.6    3668.596780    892.393432    207.533355   \n",
       "4       4673.503069       21.6    4042.434273    300.215326    424.976193   \n",
       "...             ...        ...            ...           ...           ...   \n",
       "37523  17957.592000     1800.0  445343.100000  41862.100000  59197.400000   \n",
       "37524  14905.044000     1656.0  542545.340909  50151.250000  77962.397727   \n",
       "37525  17349.048000     1872.0  469179.694118  47515.850980  73948.509804   \n",
       "37526  19948.572000     1980.0  384340.943182  42468.990341  65994.485795   \n",
       "37527  19825.308000     1692.0  365972.298857  40441.968000  57086.451429   \n",
       "\n",
       "         CO2 (g/kl)    PM (g/kl)  \n",
       "0      2.056225e+05     0.619362  \n",
       "1      3.014350e+05     0.929047  \n",
       "2      2.461506e+05     0.929047  \n",
       "3      1.884996e+05     0.929047  \n",
       "4      2.010137e+05     0.929047  \n",
       "...             ...          ...  \n",
       "37523  3.776083e+07  3785.000000  \n",
       "37524  3.775286e+07  4194.468182  \n",
       "37525  3.791183e+07  4090.768627  \n",
       "37526  3.789568e+07  3761.343750  \n",
       "37527  3.787672e+07  3232.606286  \n",
       "\n",
       "[37528 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data diolah darin.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37527 entries, 0 to 37527\n",
      "Data columns (total 30 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Backhoe      37527 non-null  int64  \n",
      " 1   HP(watt)     37527 non-null  float64\n",
      " 2   Norm_MAP     37527 non-null  float64\n",
      " 3   RPM          37527 non-null  float64\n",
      " 4   Age          37527 non-null  int64  \n",
      " 5   Load_Factor  37527 non-null  float64\n",
      " 6   Engine_Tier  37527 non-null  int64  \n",
      " 7   TEMP[C]      37527 non-null  float64\n",
      " 8   Fuel[g/s]    37527 non-null  float64\n",
      " 9   NOx[g/s]     37527 non-null  float64\n",
      " 10  HC[g/s]      37527 non-null  float64\n",
      " 11  CO[g/s]      37527 non-null  float64\n",
      " 12  CO2[g/s]     37527 non-null  float64\n",
      " 13  PM[mg/s]     37527 non-null  float64\n",
      " 14  Nox (g/l)    37527 non-null  float64\n",
      " 15  HC (g/l)     37527 non-null  float64\n",
      " 16  CO (g/l)     37527 non-null  float64\n",
      " 17  CO2 (g/l)    37527 non-null  float64\n",
      " 18  PM (g/l)     37527 non-null  float64\n",
      " 19  Fuel[g/hr]   37527 non-null  float64\n",
      " 20  NOx[g/hr]    37527 non-null  float64\n",
      " 21  HC[g/hr]     37527 non-null  float64\n",
      " 22  CO[g/hr]     37527 non-null  float64\n",
      " 23  CO2[g/hr]    37527 non-null  float64\n",
      " 24  PM[mg/hr]    37527 non-null  float64\n",
      " 25  Nox (g/kl)   37527 non-null  float64\n",
      " 26  HC (g/kl)    37527 non-null  float64\n",
      " 27  CO (g/kl)    37527 non-null  float64\n",
      " 28  CO2 (g/kl)   37527 non-null  float64\n",
      " 29  PM (g/kl)    37527 non-null  float64\n",
      "dtypes: float64(27), int64(3)\n",
      "memory usage: 8.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Backhoe', 'HP(watt)', 'Norm_MAP', 'RPM', 'Age', 'Load_Factor', 'Engine_Tier']]\n",
    "y = df['CO[g/s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26268, 7)\n",
      "(26268,)\n",
      "(11259, 7)\n",
      "(11259,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(loss='squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.fit(X_train,y_train)\n",
    "y_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.02\n",
      "MAPE: 23500927611.50%\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "rmse_score = rmse(y_test, y_pred)\n",
    "mape_score = mape(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_score:.2f}')\n",
    "print(f\"MAPE: {mape_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': np.arange(0.1, 1.0, 0.1),\n",
    "    'n_estimators': np.arange(1, 51, 5),\n",
    "    'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "    'min_samples_split': range(2, 11),\n",
    "    'min_samples_leaf': range(1, 11),\n",
    "    'max_depth': range(1, 26)\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1012500 candidates, totalling 2025000 fits\n",
      "Best: 0.039222 using {'learning_rate': 0.9, 'max_depth': 17, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 41, 'subsample': 0.5}\n",
      "Best RMSE: 0.03922246887364486\n",
      "Best MAPE: 28243907408.94867\n",
      "Execution time: 58437.76297521591 s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=params,\n",
    "    scoring={'RMSE': rmse_scorer, 'MAPE': mape_scorer},\n",
    "    refit='RMSE', \n",
    "    cv=2,  \n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "gbr_result = grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print(\"Best RMSE:\", grid.best_score_)\n",
    "print(\"Best MAPE:\", grid.cv_results_['mean_test_MAPE'][grid.best_index_])\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.03414291724288041\n",
      "MAPE: 39526819740.62%\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid.best_estimator_\n",
    "y_pred_grid = best_grid.predict(X_test)\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test, y_pred_grid))\n",
    "mape_grid = mean_absolute_percentage_error(y_test, y_pred_grid)\n",
    "print(f\"RMSE: {rmse_grid}\")\n",
    "print(f\"MAPE: {mape_grid:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "pd.DataFrame(grid.cv_results_).to_excel('GBR_GS_unscal_CO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.024542 using {'subsample': 0.6, 'n_estimators': 16, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 13, 'learning_rate': 0.9}\n",
      "Best RMSE: 0.02454224949795181\n",
      "Best MAPE: 24597187578.555626\n",
      "Execution time: 16.614335775375366 s\n"
     ]
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(\n",
    "    gbr,\n",
    "    params,\n",
    "    scoring={'RMSE': rmse_scorer, 'MAPE': mape_scorer},\n",
    "    refit='RMSE',\n",
    "    n_iter=100,\n",
    "    cv=5,  \n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "rs_result = rs.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (rs.best_score_, rs.best_params_))\n",
    "print(\"Best RMSE:\", rs.best_score_)\n",
    "print(\"Best MAPE:\", rs.cv_results_['mean_test_MAPE'][rs.best_index_])\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.025074231156944193\n",
      "MAPE: 33891484332.92%\n"
     ]
    }
   ],
   "source": [
    "best_rs = rs.best_estimator_\n",
    "y_pred_rs = best_rs.predict(X_test)\n",
    "rmse_rs = np.sqrt(mean_squared_error(y_test, y_pred_rs))\n",
    "mape_rs = mean_absolute_percentage_error(y_test, y_pred_rs)\n",
    "print(f\"RMSE: {rmse_rs}\")\n",
    "print(f\"MAPE: {mape_rs:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.27567363, 1.41032286, 1.09178982, 0.26426058, 0.52499962,\n",
       "        0.03750067, 0.60312524, 1.21965809, 0.42217922, 0.28705697,\n",
       "        2.51761031, 0.45330491, 0.31881166, 1.21989131, 1.32952456,\n",
       "        0.21888614, 0.00312457, 0.13749905, 0.17529497, 1.24448233,\n",
       "        0.33154154, 0.63164616, 0.1062501 , 0.39726911, 0.93797722,\n",
       "        0.20937519, 0.02812414, 0.21875024, 0.43789582, 0.52852187,\n",
       "        0.27852101, 1.14141054, 1.36016326, 0.09687552, 0.30351787,\n",
       "        0.55976667, 0.07187595, 1.95472889, 0.03125005, 0.65039706,\n",
       "        0.45014768, 0.36948714, 0.13164334, 0.50378413, 0.10646052,\n",
       "        0.80351782, 0.78476677, 1.37625618, 0.23750038, 0.65039706,\n",
       "        0.28164701, 0.14083886, 0.16562572, 1.66313977, 0.62890258,\n",
       "        0.05937581, 0.80117798, 0.9882113 , 0.15312538, 0.37852411,\n",
       "        0.87192698, 0.21250162, 0.14062538, 0.74130726, 0.38122211,\n",
       "        0.98003244, 0.37301259, 0.67695084, 0.81531639, 0.11875067,\n",
       "        0.25041809, 0.02922864, 1.86821814, 0.60654097, 0.04204583,\n",
       "        0.48670602, 0.0603961 , 0.43296642, 1.52981925, 2.4911726 ,\n",
       "        0.29967422, 0.02887435, 0.63444505, 0.57135801, 0.17695155,\n",
       "        0.04195442, 0.48116975, 0.04728112, 2.04509554, 0.76371193,\n",
       "        1.09634986, 0.7723392 , 1.81240535, 0.03074613, 0.51761136,\n",
       "        1.02147532, 0.61928663, 0.03619552, 0.69102502, 1.02571249]),\n",
       " 'std_fit_time': array([7.93759369e-03, 4.16904765e-02, 5.26329408e-02, 2.29637717e-02,\n",
       "        3.64435066e-02, 7.65488914e-03, 5.09671930e-02, 8.47824421e-02,\n",
       "        2.21524395e-02, 2.15239524e-02, 1.03628654e-01, 3.58091308e-02,\n",
       "        2.11665833e-02, 6.71485780e-02, 8.67647005e-02, 1.68093634e-02,\n",
       "        6.24914169e-03, 1.16936352e-02, 1.16918030e-02, 8.93096296e-02,\n",
       "        2.30470892e-02, 5.28493180e-02, 1.16923225e-02, 3.90318865e-02,\n",
       "        1.97658321e-02, 7.65430512e-03, 6.24957101e-03, 1.97655925e-02,\n",
       "        4.07456733e-02, 3.61738230e-02, 2.29646153e-02, 6.77519929e-02,\n",
       "        7.96724511e-02, 1.53103720e-02, 2.72450985e-02, 4.35264325e-02,\n",
       "        7.65436366e-03, 1.38120017e-01, 1.42573513e-06, 2.53867044e-02,\n",
       "        4.91078502e-02, 1.25009901e-02, 7.65469448e-03, 3.03474103e-02,\n",
       "        1.17475982e-02, 6.05957745e-02, 5.44867537e-02, 1.03028841e-01,\n",
       "        6.24980931e-03, 5.00006676e-02, 1.71146758e-02, 9.75977218e-03,\n",
       "        1.24994040e-02, 1.04307704e-01, 4.67704242e-02, 1.53097197e-02,\n",
       "        3.87788699e-02, 8.28467668e-02, 6.24947550e-03, 6.24952317e-03,\n",
       "        3.49572940e-02, 1.87495470e-02, 9.88196711e-03, 6.05978524e-02,\n",
       "        2.91352129e-02, 4.11894303e-02, 3.30484215e-02, 4.33166084e-02,\n",
       "        5.10324121e-02, 1.25012279e-02, 2.82205374e-02, 6.43656930e-03,\n",
       "        1.38121872e-01, 3.49156871e-02, 6.76526564e-03, 6.59732372e-03,\n",
       "        7.68641773e-03, 2.59947024e-02, 1.32680138e-01, 1.21196972e-01,\n",
       "        2.57939484e-02, 6.35862929e-03, 1.28728124e-02, 1.78982520e-02,\n",
       "        1.38453142e-02, 9.74677610e-03, 1.12589146e-02, 3.05910553e-03,\n",
       "        7.12196507e-02, 4.19571779e-02, 3.86057140e-02, 3.02913970e-02,\n",
       "        8.34078218e-02, 6.13655306e-03, 1.13408781e-02, 2.39532106e-02,\n",
       "        2.46797403e-02, 7.48915190e-03, 3.12390031e-02, 2.69760941e-02]),\n",
       " 'mean_score_time': array([0.00625057, 0.02130218, 0.01249976, 0.        , 0.00937576,\n",
       "        0.00625014, 0.00625048, 0.01875162, 0.0124999 , 0.00393572,\n",
       "        0.02187524, 0.00624981, 0.00624971, 0.00937624, 0.01247578,\n",
       "        0.00312481, 0.00312562, 0.0031251 , 0.00312629, 0.00932751,\n",
       "        0.0062501 , 0.00624981, 0.        , 0.01249971, 0.0187489 ,\n",
       "        0.00937519, 0.00625029, 0.0062499 , 0.01250229, 0.00312486,\n",
       "        0.        , 0.02812605, 0.01249957, 0.00624905, 0.00624943,\n",
       "        0.00625   , 0.        , 0.02500248, 0.        , 0.01562481,\n",
       "        0.00937605, 0.00312481, 0.00625   , 0.00312495, 0.00312519,\n",
       "        0.00937414, 0.01249995, 0.0125    , 0.00947685, 0.00312486,\n",
       "        0.00312471, 0.        , 0.00312505, 0.01605182, 0.01562519,\n",
       "        0.        , 0.00625019, 0.00937548, 0.00625   , 0.00624971,\n",
       "        0.00633001, 0.        , 0.        , 0.00937524, 0.00320311,\n",
       "        0.01679978, 0.00937529, 0.00332208, 0.01034346, 0.        ,\n",
       "        0.01135693, 0.00681868, 0.03565092, 0.0069427 , 0.        ,\n",
       "        0.00991497, 0.00090284, 0.        , 0.01788449, 0.02439914,\n",
       "        0.00010557, 0.00062532, 0.00707211, 0.01010857, 0.01132903,\n",
       "        0.00080018, 0.00766392, 0.00093074, 0.02970676, 0.00444193,\n",
       "        0.00332808, 0.01148939, 0.02671399, 0.00350122, 0.00713148,\n",
       "        0.01053858, 0.01806879, 0.        , 0.00832276, 0.01682391]),\n",
       " 'std_score_time': array([7.65535625e-03, 7.00327246e-03, 6.24988084e-03, 0.00000000e+00,\n",
       "        7.65527844e-03, 7.65483073e-03, 7.65523946e-03, 6.24919043e-03,\n",
       "        6.24995236e-03, 6.05465100e-03, 7.65475283e-03, 7.65442184e-03,\n",
       "        7.65430508e-03, 7.65566832e-03, 6.23806011e-03, 6.24961853e-03,\n",
       "        6.25123978e-03, 6.25019073e-03, 6.25257492e-03, 7.61600701e-03,\n",
       "        7.65477227e-03, 7.65442185e-03, 0.00000000e+00, 6.24985698e-03,\n",
       "        6.25019095e-03, 7.65481124e-03, 7.65500590e-03, 7.65453865e-03,\n",
       "        6.25114451e-03, 6.24971390e-03, 0.00000000e+00, 6.25004865e-03,\n",
       "        6.24978559e-03, 7.65348753e-03, 7.65395476e-03, 7.65465545e-03,\n",
       "        0.00000000e+00, 7.65531784e-03, 0.00000000e+00, 9.88143922e-03,\n",
       "        7.65551202e-03, 6.24961853e-03, 7.65465548e-03, 6.24990463e-03,\n",
       "        6.25038147e-03, 7.65395490e-03, 6.24997616e-03, 6.25000005e-03,\n",
       "        7.74000512e-03, 6.24971390e-03, 6.24942780e-03, 0.00000000e+00,\n",
       "        6.25009537e-03, 8.28919189e-04, 3.81469727e-07, 0.00000000e+00,\n",
       "        7.65488905e-03, 7.65504481e-03, 7.65465545e-03, 7.65430506e-03,\n",
       "        7.75358741e-03, 0.00000000e+00, 0.00000000e+00, 7.65485012e-03,\n",
       "        6.40621185e-03, 1.02653158e-02, 7.65488907e-03, 6.64415359e-03,\n",
       "        7.76893450e-03, 0.00000000e+00, 7.08304497e-03, 7.80839050e-03,\n",
       "        7.74568640e-03, 7.80716624e-03, 0.00000000e+00, 8.10113221e-03,\n",
       "        1.11759308e-03, 0.00000000e+00, 2.52943810e-03, 6.49257186e-03,\n",
       "        2.11143494e-04, 8.14058226e-04, 8.00209877e-03, 6.21782526e-03,\n",
       "        7.07689811e-03, 1.60036087e-03, 7.57173873e-03, 8.73406944e-04,\n",
       "        3.99173954e-03, 6.29451957e-03, 6.65616989e-03, 8.09183927e-03,\n",
       "        8.51641802e-03, 6.05249980e-03, 5.84484568e-03, 7.17751658e-03,\n",
       "        2.63792251e-03, 0.00000000e+00, 7.06041928e-03, 2.10952759e-04]),\n",
       " 'param_subsample': masked_array(data=[0.7, 0.8999999999999999, 0.5, 0.8999999999999999, 0.6,\n",
       "                    0.7, 0.8999999999999999, 0.7, 0.6, 0.5,\n",
       "                    0.8999999999999999, 0.6, 0.7999999999999999, 0.7,\n",
       "                    0.8999999999999999, 0.7999999999999999, 0.5, 0.5, 0.6,\n",
       "                    0.8999999999999999, 0.6, 0.6, 0.7999999999999999, 0.7,\n",
       "                    0.5, 0.7, 0.6, 0.7999999999999999, 0.8999999999999999,\n",
       "                    0.7999999999999999, 0.7999999999999999, 0.6,\n",
       "                    0.7999999999999999, 0.8999999999999999,\n",
       "                    0.7999999999999999, 0.5, 0.5, 0.7999999999999999, 0.6,\n",
       "                    0.7, 0.6, 0.6, 0.5, 0.8999999999999999, 0.7,\n",
       "                    0.7999999999999999, 0.8999999999999999,\n",
       "                    0.8999999999999999, 0.6, 0.8999999999999999, 0.6,\n",
       "                    0.8999999999999999, 0.5, 0.8999999999999999, 0.5,\n",
       "                    0.8999999999999999, 0.6, 0.7999999999999999, 0.7, 0.5,\n",
       "                    0.8999999999999999, 0.7999999999999999,\n",
       "                    0.7999999999999999, 0.7, 0.6, 0.7, 0.6,\n",
       "                    0.7999999999999999, 0.6, 0.7999999999999999, 0.5, 0.7,\n",
       "                    0.6, 0.8999999999999999, 0.7999999999999999, 0.5, 0.7,\n",
       "                    0.7, 0.7999999999999999, 0.8999999999999999, 0.5,\n",
       "                    0.8999999999999999, 0.7, 0.7, 0.5, 0.5, 0.6,\n",
       "                    0.7999999999999999, 0.6, 0.8999999999999999,\n",
       "                    0.8999999999999999, 0.6, 0.5, 0.8999999999999999, 0.5,\n",
       "                    0.8999999999999999, 0.5, 0.6, 0.8999999999999999, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[41, 26, 46, 6, 16, 1, 11, 26, 16, 36, 46, 16, 26, 36,\n",
       "                    46, 26, 1, 6, 36, 36, 11, 26, 21, 11, 31, 6, 1, 6, 11,\n",
       "                    41, 36, 31, 36, 11, 6, 31, 6, 46, 1, 31, 16, 36, 6, 21,\n",
       "                    21, 31, 26, 31, 36, 41, 41, 26, 6, 36, 21, 11, 31, 36,\n",
       "                    31, 16, 21, 21, 26, 26, 11, 31, 11, 16, 31, 11, 11, 1,\n",
       "                    41, 11, 1, 26, 6, 16, 31, 36, 11, 1, 16, 11, 6, 1, 36,\n",
       "                    1, 46, 46, 41, 21, 41, 1, 26, 31, 21, 1, 16, 41],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[6, 5, 2, 8, 6, 6, 3, 5, 5, 7, 4, 6, 3, 10, 3, 5, 3, 10,\n",
       "                    3, 2, 2, 4, 10, 10, 4, 5, 10, 8, 9, 8, 6, 4, 8, 2, 8,\n",
       "                    4, 10, 10, 7, 9, 3, 10, 2, 7, 10, 4, 10, 10, 5, 5, 8,\n",
       "                    2, 9, 5, 2, 7, 10, 9, 10, 7, 2, 3, 5, 2, 8, 2, 6, 3, 5,\n",
       "                    4, 5, 2, 4, 9, 7, 4, 10, 8, 6, 8, 5, 8, 7, 6, 9, 5, 4,\n",
       "                    4, 10, 9, 3, 3, 7, 8, 5, 3, 8, 2, 9, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[5, 2, 5, 6, 5, 4, 4, 4, 9, 8, 5, 4, 6, 10, 9, 1, 6, 7,\n",
       "                    2, 9, 9, 10, 6, 10, 10, 9, 5, 6, 3, 8, 4, 1, 7, 2, 1,\n",
       "                    10, 9, 1, 5, 1, 1, 6, 3, 2, 4, 4, 2, 2, 4, 4, 10, 7, 6,\n",
       "                    9, 10, 10, 10, 4, 9, 8, 5, 9, 10, 6, 5, 8, 1, 9, 6, 4,\n",
       "                    7, 10, 2, 3, 2, 9, 2, 7, 10, 3, 5, 1, 7, 9, 9, 4, 1, 6,\n",
       "                    9, 6, 1, 10, 2, 6, 4, 5, 9, 9, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[2, 22, 14, 20, 23, 24, 24, 23, 13, 3, 23, 15, 4, 16,\n",
       "                    11, 2, 1, 15, 1, 13, 20, 12, 1, 21, 22, 23, 20, 16, 17,\n",
       "                    4, 2, 20, 16, 2, 22, 10, 5, 17, 20, 9, 13, 4, 12, 8, 1,\n",
       "                    10, 11, 16, 2, 5, 2, 1, 20, 20, 22, 1, 13, 10, 1, 15,\n",
       "                    17, 3, 1, 12, 22, 15, 20, 20, 14, 3, 12, 19, 20, 24,\n",
       "                    17, 11, 3, 12, 18, 23, 15, 5, 15, 21, 14, 22, 4, 20,\n",
       "                    19, 4, 7, 16, 20, 8, 8, 9, 17, 25, 13, 23],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.9, 0.6, 0.9, 0.5, 0.2, 0.9, 0.6, 0.5, 0.5, 0.8, 0.4,\n",
       "                    0.1, 0.9, 0.6, 0.1, 0.7000000000000001, 0.9, 0.1,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.9,\n",
       "                    0.7000000000000001, 0.4, 0.9, 0.5, 0.5, 0.5, 0.2,\n",
       "                    0.30000000000000004, 0.5, 0.1, 0.5, 0.7000000000000001,\n",
       "                    0.8, 0.30000000000000004, 0.9, 0.6, 0.1, 0.6, 0.9, 0.4,\n",
       "                    0.8, 0.2, 0.8, 0.4, 0.6, 0.5, 0.2, 0.2,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.4, 0.2, 0.5,\n",
       "                    0.2, 0.6, 0.8, 0.1, 0.7000000000000001,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.6,\n",
       "                    0.30000000000000004, 0.4, 0.4, 0.2, 0.7000000000000001,\n",
       "                    0.1, 0.4, 0.5, 0.8, 0.5, 0.6, 0.9, 0.2, 0.2, 0.8, 0.5,\n",
       "                    0.7000000000000001, 0.8, 0.5, 0.4, 0.9, 0.5,\n",
       "                    0.30000000000000004, 0.6, 0.4, 0.7000000000000001, 0.6,\n",
       "                    0.6, 0.30000000000000004, 0.8, 0.2, 0.4, 0.4, 0.1,\n",
       "                    0.7000000000000001, 0.4, 0.4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.7,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 24,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 24,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 21,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 24,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 21,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.4}],\n",
       " 'split0_test_RMSE': array([0.01715797, 0.01700964, 0.02204871, 0.01618691, 0.016334  ,\n",
       "        0.01699463, 0.01711235, 0.01652875, 0.01680268, 0.01609881,\n",
       "        0.01677829, 0.01700889, 0.0159583 , 0.01653611, 0.01571478,\n",
       "        0.01728611, 0.02508032, 0.02048341, 0.02429803, 0.0156662 ,\n",
       "        0.01580889, 0.01786777, 0.02395073, 0.01622677, 0.01843319,\n",
       "        0.0159992 , 0.02007313, 0.01597759, 0.01540767, 0.01536699,\n",
       "        0.01762147, 0.01569638, 0.0168536 , 0.01918707, 0.01755074,\n",
       "        0.01622512, 0.01748593, 0.01776521, 0.02437561, 0.01753614,\n",
       "        0.0226075 , 0.01590952, 0.01804795, 0.01524296, 0.02400048,\n",
       "        0.0169514 , 0.01664261, 0.01670233, 0.01845058, 0.01577576,\n",
       "        0.01763496, 0.02388358, 0.01645385, 0.01562438, 0.01739055,\n",
       "        0.02474343, 0.01716656, 0.01790283, 0.02464536, 0.0163933 ,\n",
       "        0.01600316, 0.01644556, 0.02395026, 0.01571681, 0.01734867,\n",
       "        0.01580583, 0.01590216, 0.01648307, 0.01552106, 0.01727474,\n",
       "        0.01634574, 0.0179355 , 0.01848982, 0.01691567, 0.01661209,\n",
       "        0.01615223, 0.01967208, 0.01790418, 0.01640182, 0.01761507,\n",
       "        0.01788519, 0.0195804 , 0.01568259, 0.0171721 , 0.0172976 ,\n",
       "        0.02177456, 0.01681457, 0.02106905, 0.01790692, 0.01551951,\n",
       "        0.01656345, 0.01580956, 0.02212736, 0.0232325 , 0.0161972 ,\n",
       "        0.01657945, 0.01716492, 0.01883548, 0.01573111, 0.01666166]),\n",
       " 'split1_test_RMSE': array([0.01522117, 0.01865922, 0.02132606, 0.01586492, 0.01501369,\n",
       "        0.01569368, 0.01669528, 0.01791383, 0.01521471, 0.01544476,\n",
       "        0.01751484, 0.01464012, 0.01585281, 0.01663563, 0.01477265,\n",
       "        0.01475871, 0.0192524 , 0.01534679, 0.01821722, 0.01554171,\n",
       "        0.01414747, 0.01773584, 0.01797012, 0.01453482, 0.01957396,\n",
       "        0.01521034, 0.01553271, 0.01459307, 0.0146549 , 0.01437185,\n",
       "        0.01467849, 0.01561085, 0.01698532, 0.01602392, 0.02079568,\n",
       "        0.01489673, 0.01508612, 0.01990257, 0.0185068 , 0.01775355,\n",
       "        0.02646983, 0.01406437, 0.01934224, 0.01453569, 0.01809668,\n",
       "        0.01624604, 0.01709085, 0.01787679, 0.01502215, 0.01483406,\n",
       "        0.01498685, 0.01795317, 0.01412083, 0.01544466, 0.01546491,\n",
       "        0.01878477, 0.01608303, 0.01683563, 0.01868431, 0.01721902,\n",
       "        0.01682706, 0.01443145, 0.01797599, 0.01516331, 0.01543542,\n",
       "        0.01520255, 0.01531701, 0.01543319, 0.01480372, 0.01409884,\n",
       "        0.0157067 , 0.01522437, 0.01893424, 0.01784401, 0.01456626,\n",
       "        0.0148695 , 0.01521411, 0.01683686, 0.01630027, 0.01749745,\n",
       "        0.01853417, 0.01586096, 0.01540504, 0.01790847, 0.01584628,\n",
       "        0.01705375, 0.01696377, 0.01579645, 0.01916438, 0.01462431,\n",
       "        0.01945967, 0.01478917, 0.02537846, 0.01738593, 0.01467202,\n",
       "        0.01646031, 0.01413215, 0.01467423, 0.01523036, 0.01615666]),\n",
       " 'split2_test_RMSE': array([0.0144685 , 0.01696658, 0.02035803, 0.01433045, 0.01410808,\n",
       "        0.01473072, 0.01536788, 0.01552168, 0.01404108, 0.01369374,\n",
       "        0.0156029 , 0.01426616, 0.01406641, 0.01498492, 0.01388444,\n",
       "        0.01443161, 0.02133165, 0.01681827, 0.02042628, 0.01425612,\n",
       "        0.01462729, 0.01641433, 0.0200988 , 0.01412522, 0.01693961,\n",
       "        0.01494869, 0.01663742, 0.01443837, 0.01426823, 0.01396953,\n",
       "        0.01424464, 0.01597612, 0.0162135 , 0.01588949, 0.01763535,\n",
       "        0.01473862, 0.01614684, 0.01690475, 0.02057443, 0.01739804,\n",
       "        0.02341355, 0.01352733, 0.01757219, 0.01342565, 0.02006119,\n",
       "        0.01494893, 0.01556228, 0.0151835 , 0.01466966, 0.01305239,\n",
       "        0.01483579, 0.01998462, 0.01488485, 0.01404611, 0.01461884,\n",
       "        0.02089125, 0.01489883, 0.01600826, 0.02079363, 0.01564722,\n",
       "        0.01430863, 0.01380107, 0.02005829, 0.01421453, 0.01484518,\n",
       "        0.01407769, 0.01606781, 0.01581309, 0.0139021 , 0.01374136,\n",
       "        0.01437043, 0.0162271 , 0.01696713, 0.01572944, 0.01727347,\n",
       "        0.01435457, 0.01631145, 0.01492385, 0.01467051, 0.01692817,\n",
       "        0.01687541, 0.01671017, 0.01450623, 0.01557557, 0.01476622,\n",
       "        0.01846414, 0.01605229, 0.0177194 , 0.01649118, 0.01425285,\n",
       "        0.01565238, 0.01426608, 0.02298555, 0.01933202, 0.0151467 ,\n",
       "        0.01376914, 0.01410818, 0.01534223, 0.0139359 , 0.01456186]),\n",
       " 'split3_test_RMSE': array([0.01984645, 0.02233724, 0.02408343, 0.01947183, 0.01934858,\n",
       "        0.02001713, 0.02046947, 0.02144675, 0.01940618, 0.01931858,\n",
       "        0.02048391, 0.01817814, 0.01986639, 0.01948799, 0.01899094,\n",
       "        0.01959259, 0.02387029, 0.01937325, 0.02284225, 0.01939117,\n",
       "        0.01826893, 0.02043345, 0.02264208, 0.01871557, 0.02186183,\n",
       "        0.0190514 , 0.0197423 , 0.0191228 , 0.01932189, 0.01907347,\n",
       "        0.01959715, 0.01987808, 0.02000321, 0.01933516, 0.02326868,\n",
       "        0.01888398, 0.01946036, 0.02384711, 0.02304703, 0.02121315,\n",
       "        0.02793045, 0.01922656, 0.02165539, 0.01923762, 0.0226551 ,\n",
       "        0.02028607, 0.02100654, 0.02150595, 0.01911624, 0.01863022,\n",
       "        0.01857362, 0.02257795, 0.01893038, 0.01941303, 0.01907573,\n",
       "        0.02355771, 0.01941508, 0.02122237, 0.02342748, 0.01987434,\n",
       "        0.01982465, 0.01879216, 0.02267898, 0.01945768, 0.01936697,\n",
       "        0.01972238, 0.0189387 , 0.02031371, 0.0188007 , 0.01884131,\n",
       "        0.01949864, 0.01893118, 0.02326001, 0.02114661, 0.01972543,\n",
       "        0.01835488, 0.01893253, 0.02055231, 0.01978408, 0.02168398,\n",
       "        0.02043923, 0.01944001, 0.0191791 , 0.02099376, 0.01840642,\n",
       "        0.02072504, 0.02014692, 0.02016114, 0.02008247, 0.01920331,\n",
       "        0.02180046, 0.01902541, 0.02627337, 0.02185932, 0.0193972 ,\n",
       "        0.01959647, 0.01785837, 0.01890026, 0.01958484, 0.01909669]),\n",
       " 'split4_test_RMSE': array([0.01397914, 0.0167099 , 0.02123685, 0.01436141, 0.01324065,\n",
       "        0.01424742, 0.01501431, 0.01586032, 0.01445128, 0.01435117,\n",
       "        0.01506962, 0.01319746, 0.0141803 , 0.01540761, 0.01366094,\n",
       "        0.01396054, 0.01902469, 0.01460485, 0.0180249 , 0.01420297,\n",
       "        0.01355936, 0.01838829, 0.01780017, 0.01421722, 0.01851562,\n",
       "        0.01391402, 0.01392237, 0.01358862, 0.01355992, 0.01353045,\n",
       "        0.01368772, 0.01487645, 0.01495312, 0.01431421, 0.01725033,\n",
       "        0.01404215, 0.01511054, 0.01672925, 0.01829398, 0.01698918,\n",
       "        0.02228993, 0.01436619, 0.01673091, 0.0137382 , 0.0178355 ,\n",
       "        0.01449182, 0.01551224, 0.0158753 , 0.01383236, 0.01384713,\n",
       "        0.01382608, 0.01774036, 0.01381998, 0.01408909, 0.01532972,\n",
       "        0.01859915, 0.01509117, 0.01640222, 0.01847906, 0.01623685,\n",
       "        0.01410722, 0.0125121 , 0.01778742, 0.01460185, 0.0149603 ,\n",
       "        0.01425818, 0.01396833, 0.01592545, 0.01324272, 0.01292809,\n",
       "        0.01426305, 0.01313125, 0.01734122, 0.0148345 , 0.01526031,\n",
       "        0.01288695, 0.01430828, 0.01542836, 0.01542665, 0.016221  ,\n",
       "        0.01699176, 0.01524876, 0.01402206, 0.01678339, 0.01418429,\n",
       "        0.01592258, 0.01509649, 0.0158605 , 0.01657016, 0.0135498 ,\n",
       "        0.01726877, 0.01337776, 0.02425562, 0.01746868, 0.01398209,\n",
       "        0.01429882, 0.01314826, 0.01344306, 0.01481164, 0.01553011]),\n",
       " 'mean_test_RMSE': array([0.01613465, 0.01833652, 0.02181062, 0.0160431 , 0.015609  ,\n",
       "        0.01633672, 0.01693186, 0.01745427, 0.01598318, 0.01578141,\n",
       "        0.01708991, 0.01545815, 0.01598484, 0.01661045, 0.01540475,\n",
       "        0.01600591, 0.02171187, 0.01732531, 0.02076174, 0.01581163,\n",
       "        0.01528239, 0.01816794, 0.02049238, 0.01556392, 0.01906484,\n",
       "        0.01582473, 0.01718158, 0.01554409, 0.01544252, 0.01526246,\n",
       "        0.01596589, 0.01640758, 0.01700175, 0.01694997, 0.01930015,\n",
       "        0.01575732, 0.01665796, 0.01902978, 0.02095957, 0.01817801,\n",
       "        0.02454225, 0.01541879, 0.01866974, 0.01523602, 0.02052979,\n",
       "        0.01658485, 0.0171629 , 0.01742877, 0.0162182 , 0.01522791,\n",
       "        0.01597146, 0.02042793, 0.01564198, 0.01572346, 0.01637595,\n",
       "        0.02131526, 0.01653094, 0.01767426, 0.02120597, 0.01707415,\n",
       "        0.01621414, 0.01519647, 0.02049019, 0.01583084, 0.01639131,\n",
       "        0.01581333, 0.0160388 , 0.0167937 , 0.01525406, 0.01537687,\n",
       "        0.01603691, 0.01628988, 0.01899849, 0.01729405, 0.01668751,\n",
       "        0.01532362, 0.01688769, 0.01712911, 0.01651667, 0.01798914,\n",
       "        0.01814515, 0.01736806, 0.01575901, 0.01768666, 0.01610017,\n",
       "        0.01878802, 0.01701481, 0.01812131, 0.01804302, 0.01542996,\n",
       "        0.01814895, 0.0154536 , 0.02420407, 0.01985569, 0.01587904,\n",
       "        0.01614084, 0.01528238, 0.01623905, 0.01585877, 0.0164014 ]),\n",
       " 'std_test_RMSE': array([0.00214855, 0.00211628, 0.00125669, 0.00187456, 0.00213196,\n",
       "        0.00206573, 0.00193526, 0.00215793, 0.00195436, 0.001956  ,\n",
       "        0.00190209, 0.00184412, 0.00209864, 0.00157325, 0.00193435,\n",
       "        0.0021317 , 0.00242569, 0.00226893, 0.00248641, 0.00189286,\n",
       "        0.00166629, 0.00130637, 0.00246358, 0.00175013, 0.00163093,\n",
       "        0.00174571, 0.0023898 , 0.00194659, 0.00202949, 0.00199997,\n",
       "        0.00226879, 0.00177288, 0.00166428, 0.00198107, 0.00236726,\n",
       "        0.00171552, 0.0016532 , 0.00265992, 0.0024206 , 0.00153792,\n",
       "        0.0022488 , 0.00206203, 0.00171562, 0.00209877, 0.00244792,\n",
       "        0.00204964, 0.00201674, 0.00222739, 0.00214023, 0.00193238,\n",
       "        0.00181109, 0.0024539 , 0.0018804 , 0.00195883, 0.0016328 ,\n",
       "        0.00247957, 0.00165285, 0.00188352, 0.00247909, 0.00148747,\n",
       "        0.0020749 , 0.00220125, 0.00247288, 0.00188337, 0.00173915,\n",
       "        0.00205352, 0.00162707, 0.00179184, 0.00193525, 0.00227636,\n",
       "        0.00190325, 0.00203964, 0.00224928, 0.00218106, 0.00179525,\n",
       "        0.00184162, 0.00208425, 0.00200799, 0.00175114, 0.00191236,\n",
       "        0.00129802, 0.00181014, 0.00181188, 0.00181788, 0.00156634,\n",
       "        0.00219065, 0.00170054, 0.00216923, 0.00141512, 0.00199077,\n",
       "        0.00221688, 0.00195168, 0.00151403, 0.00234475, 0.00190107,\n",
       "        0.00206174, 0.0018674 , 0.00223132, 0.00195391, 0.0015189 ]),\n",
       " 'rank_test_RMSE': array([ 62,  20,   3,  64,  83,  56,  43,  30,  69,  78,  38,  86,  68,\n",
       "         48,  91,  67,   4,  33,   8,  77,  94,  22,  10,  84,  15,  75,\n",
       "         35,  85,  88,  96,  71,  52,  41,  42,  14,  80,  47,  16,   7,\n",
       "         21,   1,  90,  19,  98,   9,  49,  36,  31,  59,  99,  70,  12,\n",
       "         82,  81,  55,   5,  50,  29,   6,  39,  60, 100,  11,  74,  54,\n",
       "         76,  65,  45,  97,  92,  66,  57,  17,  34,  46,  93,  44,  37,\n",
       "         51,  27,  24,  32,  79,  28,  63,  18,  40,  25,  26,  89,  23,\n",
       "         87,   2,  13,  72,  61,  95,  58,  73,  53]),\n",
       " 'split0_test_MAPE': array([1.50764282e+10, 4.39405965e+09, 1.40494705e+10, 9.82047895e+09,\n",
       "        8.03733171e+09, 8.39987694e+09, 7.31530039e+09, 1.22299290e+10,\n",
       "        1.19296330e+10, 1.19927483e+10, 4.07828610e+09, 1.25694544e+10,\n",
       "        1.20192609e+10, 1.41729028e+10, 1.18409662e+10, 1.52574999e+10,\n",
       "        2.47625246e+10, 2.01401365e+10, 1.39596501e+10, 9.28961963e+09,\n",
       "        9.38909449e+09, 1.67381783e+10, 1.58737363e+10, 7.86675115e+09,\n",
       "        5.42644133e+09, 1.05782193e+10, 2.11181792e+10, 9.79113735e+09,\n",
       "        1.03096806e+10, 1.18199300e+10, 1.39301219e+10, 4.61469755e+09,\n",
       "        6.99201512e+09, 1.93654315e+10, 7.29874401e+09, 8.59605503e+09,\n",
       "        1.02901337e+10, 3.09730791e+09, 2.82787845e+10, 1.09906336e+10,\n",
       "        9.40713344e+09, 1.15323960e+10, 5.02913568e+09, 1.12047161e+10,\n",
       "        1.57076794e+10, 6.69517292e+09, 1.16628802e+10, 8.88694520e+09,\n",
       "        1.51875219e+10, 1.12144959e+10, 1.38722257e+10, 1.32347758e+10,\n",
       "        9.26959255e+09, 8.52017898e+09, 1.75657369e+10, 2.14313490e+10,\n",
       "        1.08822314e+10, 8.77945033e+09, 1.97075445e+10, 1.44208473e+10,\n",
       "        9.74378601e+09, 1.41260592e+10, 1.36069040e+10, 1.30186198e+10,\n",
       "        8.08899016e+09, 1.35515370e+10, 8.48236902e+09, 1.64791209e+10,\n",
       "        9.97995051e+09, 1.74856988e+10, 1.15753739e+10, 1.14819287e+10,\n",
       "        8.14192909e+09, 6.70920758e+09, 1.67818832e+10, 1.13636351e+10,\n",
       "        2.17578568e+10, 1.11010086e+10, 9.88947377e+09, 7.90364762e+09,\n",
       "        1.29242897e+10, 2.27483245e+10, 7.29448046e+09, 8.90384669e+09,\n",
       "        1.46794801e+10, 2.59070477e+10, 1.09177941e+10, 2.26890034e+10,\n",
       "        2.17376077e+10, 9.36855151e+09, 9.72537704e+09, 7.06674126e+09,\n",
       "        9.65762145e+09, 2.58105498e+10, 8.94449135e+09, 8.29891031e+09,\n",
       "        1.24721223e+10, 1.50553652e+10, 9.65929917e+09, 1.20318430e+10]),\n",
       " 'split1_test_MAPE': array([2.16613637e+10, 1.84720861e+10, 1.86604624e+10, 2.10300948e+10,\n",
       "        2.19279256e+10, 2.51929827e+10, 2.04503245e+10, 2.23717588e+10,\n",
       "        1.84757759e+10, 2.17406592e+10, 1.66507791e+10, 2.86769346e+10,\n",
       "        2.27820517e+10, 1.71246595e+10, 1.89398748e+10, 2.45027053e+10,\n",
       "        5.44681229e+10, 4.51694025e+10, 2.64581263e+10, 1.65032586e+10,\n",
       "        1.50028802e+10, 1.48963771e+10, 2.38236440e+10, 2.02497553e+10,\n",
       "        2.32391789e+10, 1.84009867e+10, 4.25837986e+10, 2.18044281e+10,\n",
       "        2.38233779e+10, 2.32077007e+10, 2.24868138e+10, 2.00307156e+10,\n",
       "        1.83228621e+10, 2.96183379e+10, 1.57003348e+10, 1.75272579e+10,\n",
       "        2.39214960e+10, 1.46362051e+10, 6.24939402e+10, 1.69558363e+10,\n",
       "        1.78098927e+10, 2.16077313e+10, 1.83263564e+10, 1.97681926e+10,\n",
       "        2.82098004e+10, 1.88628859e+10, 1.88029484e+10, 1.82039401e+10,\n",
       "        2.72794130e+10, 2.23319566e+10, 2.65151431e+10, 3.13821244e+10,\n",
       "        2.25364434e+10, 1.95290330e+10, 1.73851985e+10, 4.54465382e+10,\n",
       "        1.98307897e+10, 1.96670289e+10, 4.12004111e+10, 1.77913641e+10,\n",
       "        1.82862775e+10, 2.45938902e+10, 2.64187624e+10, 1.95190144e+10,\n",
       "        1.93287413e+10, 1.83739547e+10, 2.20595019e+10, 2.30518528e+10,\n",
       "        2.11628430e+10, 2.74587917e+10, 1.90231861e+10, 2.89494579e+10,\n",
       "        1.90950420e+10, 2.13626044e+10, 2.44060560e+10, 2.01592538e+10,\n",
       "        4.39266820e+10, 1.88808906e+10, 1.76203162e+10, 1.43555606e+10,\n",
       "        1.43905865e+10, 4.67097468e+10, 2.08211187e+10, 2.01455550e+10,\n",
       "        1.91115299e+10, 5.25154153e+10, 2.00657917e+10, 4.84344294e+10,\n",
       "        1.26276566e+10, 1.74325204e+10, 1.94442634e+10, 1.69371527e+10,\n",
       "        4.12331941e+10, 5.85126183e+10, 2.07473312e+10, 1.84821782e+10,\n",
       "        2.43023123e+10, 3.58507379e+10, 1.90693301e+10, 1.69510975e+10]),\n",
       " 'split2_test_MAPE': array([2.05406829e+10, 1.58707506e+10, 5.14991565e+10, 1.48050667e+10,\n",
       "        2.03493244e+10, 2.31115434e+10, 2.73956463e+10, 1.00094064e+10,\n",
       "        1.96960018e+10, 2.07864651e+10, 2.80893062e+10, 2.75407420e+10,\n",
       "        2.82237877e+10, 1.69133527e+10, 2.34927849e+10, 2.34973606e+10,\n",
       "        5.71002612e+10, 4.92153291e+10, 1.85514682e+10, 1.38072923e+10,\n",
       "        2.14776012e+10, 2.16010365e+10, 3.04714055e+10, 1.63533257e+10,\n",
       "        4.26955930e+10, 3.25155658e+10, 5.01849807e+10, 1.29273013e+10,\n",
       "        2.08587767e+10, 2.63596149e+10, 1.99783582e+10, 1.74370751e+10,\n",
       "        2.05058258e+10, 2.28397791e+10, 1.20912861e+10, 3.03205189e+10,\n",
       "        2.45696620e+10, 1.95665594e+10, 6.29924611e+10, 1.61618186e+10,\n",
       "        2.49448449e+10, 2.70865917e+10, 2.13425506e+10, 2.19281599e+10,\n",
       "        3.43021619e+10, 1.99414624e+10, 1.34935542e+10, 2.09910497e+10,\n",
       "        2.33164963e+10, 2.69715893e+10, 2.34258275e+10, 3.47375110e+10,\n",
       "        2.26954972e+10, 2.36374982e+10, 3.06961010e+10, 4.15431470e+10,\n",
       "        4.10420141e+10, 1.35533514e+10, 3.56857844e+10, 2.24497407e+10,\n",
       "        2.44231918e+10, 1.92747398e+10, 2.77432245e+10, 1.50122024e+10,\n",
       "        2.21553823e+10, 1.88633928e+10, 2.09386585e+10, 1.04480833e+10,\n",
       "        1.90450733e+10, 2.68824303e+10, 2.21864236e+10, 2.78266247e+10,\n",
       "        1.56041725e+10, 1.98365002e+10, 2.33725343e+10, 1.43341022e+10,\n",
       "        4.17473810e+10, 2.00934834e+10, 2.34540210e+10, 1.22977848e+10,\n",
       "        1.33109262e+10, 5.27892422e+10, 2.77521106e+10, 1.38243632e+10,\n",
       "        3.59698542e+10, 5.17323488e+10, 2.30220081e+10, 4.77185515e+10,\n",
       "        3.67308129e+10, 2.77419867e+10, 1.47495162e+10, 2.16012550e+10,\n",
       "        3.58273975e+10, 6.07905759e+10, 2.14001246e+10, 1.83621626e+10,\n",
       "        2.27114575e+10, 4.36672229e+10, 1.42013008e+10, 2.67122450e+10]),\n",
       " 'split3_test_MAPE': array([3.50202167e+10, 2.54357791e+10, 2.73626357e+10, 2.77370353e+10,\n",
       "        2.81491171e+10, 3.02348501e+10, 2.54980104e+10, 2.32665593e+10,\n",
       "        2.98678366e+10, 2.09994180e+10, 2.39377320e+10, 3.97230568e+10,\n",
       "        3.31121761e+10, 2.31254196e+10, 2.62821392e+10, 3.42031603e+10,\n",
       "        8.83527281e+10, 6.68866514e+10, 3.53658911e+10, 2.72026398e+10,\n",
       "        2.87109620e+10, 2.53757660e+10, 3.68703858e+10, 2.67431310e+10,\n",
       "        2.83753746e+10, 2.83401290e+10, 6.24104867e+10, 2.81297867e+10,\n",
       "        3.19016586e+10, 2.90549129e+10, 3.09405568e+10, 2.79596878e+10,\n",
       "        2.47930544e+10, 3.51398089e+10, 2.83137293e+10, 2.44599600e+10,\n",
       "        3.32023198e+10, 2.60219394e+10, 9.54187360e+10, 2.55635776e+10,\n",
       "        5.01285316e+10, 3.04781114e+10, 2.42357965e+10, 2.81216994e+10,\n",
       "        2.97331933e+10, 2.31049210e+10, 2.42246612e+10, 2.74307378e+10,\n",
       "        3.40308595e+10, 2.93378367e+10, 3.55050000e+10, 3.30684139e+10,\n",
       "        2.83758641e+10, 2.68081188e+10, 2.40909120e+10, 6.50007341e+10,\n",
       "        2.74812433e+10, 2.30088805e+10, 5.38868291e+10, 2.99125140e+10,\n",
       "        2.71341911e+10, 2.89704696e+10, 3.30047347e+10, 2.67301614e+10,\n",
       "        2.98706930e+10, 2.82936602e+10, 3.37919465e+10, 2.73907592e+10,\n",
       "        2.81187969e+10, 3.38226483e+10, 2.53506315e+10, 4.26636542e+10,\n",
       "        3.29770187e+10, 2.64740539e+10, 3.27956986e+10, 2.62403612e+10,\n",
       "        5.60563925e+10, 2.70853383e+10, 2.86368870e+10, 3.67010532e+10,\n",
       "        2.46062267e+10, 6.97986405e+10, 2.44782788e+10, 2.64650471e+10,\n",
       "        2.91744188e+10, 7.95529117e+10, 3.03722023e+10, 7.23301419e+10,\n",
       "        2.98072680e+10, 2.51091388e+10, 2.69429572e+10, 2.64298369e+10,\n",
       "        3.43119666e+10, 8.80038693e+10, 2.51989187e+10, 2.50694740e+10,\n",
       "        3.28826044e+10, 4.92714368e+10, 2.57772159e+10, 2.46544112e+10]),\n",
       " 'split4_test_MAPE': array([1.63039049e+10, 2.01418109e+10, 1.77705950e+10, 1.35715422e+10,\n",
       "        1.53555866e+10, 1.93777775e+10, 1.32197862e+10, 1.53667592e+10,\n",
       "        1.60037601e+10, 1.35114868e+10, 1.44719398e+10, 2.35415468e+10,\n",
       "        1.84552428e+10, 1.07240602e+10, 1.46012731e+10, 1.50037347e+10,\n",
       "        4.71852019e+10, 3.87129056e+10, 1.60851888e+10, 1.39870226e+10,\n",
       "        1.32002961e+10, 1.38311084e+10, 1.78548433e+10, 1.50735172e+10,\n",
       "        2.11768775e+10, 1.41915433e+10, 3.55322604e+10, 1.39434532e+10,\n",
       "        1.87848380e+10, 1.55283802e+10, 1.55024336e+10, 1.58897842e+10,\n",
       "        1.54191821e+10, 1.77164792e+10, 1.35473443e+10, 1.34985436e+10,\n",
       "        1.39472319e+10, 1.67482424e+10, 5.58375815e+10, 1.72299038e+10,\n",
       "        2.06955352e+10, 1.40501692e+10, 1.52846096e+10, 1.58465171e+10,\n",
       "        1.90585474e+10, 1.27007814e+10, 1.12412245e+10, 1.13941295e+10,\n",
       "        1.65521372e+10, 1.55244086e+10, 1.25453406e+10, 1.85389786e+10,\n",
       "        1.72805694e+10, 1.71380929e+10, 1.30321267e+10, 3.52471157e+10,\n",
       "        1.66824634e+10, 1.32669609e+10, 3.05490037e+10, 1.31208039e+10,\n",
       "        1.39762593e+10, 1.41212001e+10, 1.77739129e+10, 1.55307450e+10,\n",
       "        1.35862063e+10, 1.29287977e+10, 2.07761710e+10, 1.63268939e+10,\n",
       "        1.63459803e+10, 1.80639623e+10, 1.18151969e+10, 2.24418573e+10,\n",
       "        1.81814220e+10, 1.59077952e+10, 1.76004929e+10, 1.47856871e+10,\n",
       "        3.36830077e+10, 8.00485875e+09, 1.29962250e+10, 1.52568764e+10,\n",
       "        1.55669141e+10, 3.96498882e+10, 1.56889556e+10, 1.54982387e+10,\n",
       "        1.74912882e+10, 4.56354246e+10, 1.85491494e+10, 4.15404291e+10,\n",
       "        1.79209407e+10, 1.17767618e+10, 1.28772502e+10, 1.23741086e+10,\n",
       "        1.25704188e+10, 5.10445769e+10, 1.45399680e+10, 1.47917923e+10,\n",
       "        1.97279219e+10, 2.83790597e+10, 1.49103591e+10, 1.74365179e+10]),\n",
       " 'mean_test_MAPE': array([2.17205193e+10, 1.68628973e+10, 2.58684640e+10, 1.73928436e+10,\n",
       "        1.87638571e+10, 2.12634061e+10, 1.87758136e+10, 1.66488825e+10,\n",
       "        1.91946015e+10, 1.78061555e+10, 1.74456087e+10, 2.64103469e+10,\n",
       "        2.29185039e+10, 1.64120790e+10, 1.90314076e+10, 2.24928922e+10,\n",
       "        5.43737677e+10, 4.40248850e+10, 2.20840649e+10, 1.61579666e+10,\n",
       "        1.75561668e+10, 1.84884932e+10, 2.49788030e+10, 1.72572961e+10,\n",
       "        2.41826931e+10, 2.08052888e+10, 4.23659412e+10, 1.73192213e+10,\n",
       "        2.11356664e+10, 2.11941077e+10, 2.05676569e+10, 1.71863920e+10,\n",
       "        1.72065879e+10, 2.49359673e+10, 1.53902877e+10, 1.88804671e+10,\n",
       "        2.11861687e+10, 1.60140508e+10, 6.10043007e+10, 1.73803540e+10,\n",
       "        2.45971876e+10, 2.09509999e+10, 1.68436897e+10, 1.93738570e+10,\n",
       "        2.54022765e+10, 1.62610447e+10, 1.58850537e+10, 1.73813605e+10,\n",
       "        2.32732856e+10, 2.10760574e+10, 2.23727074e+10, 2.61923607e+10,\n",
       "        2.00315933e+10, 1.91265844e+10, 2.05540150e+10, 4.17337768e+10,\n",
       "        2.31837484e+10, 1.56551344e+10, 3.62059146e+10, 1.95390540e+10,\n",
       "        1.87127411e+10, 2.02172718e+10, 2.37095077e+10, 1.79621486e+10,\n",
       "        1.86060026e+10, 1.84022684e+10, 2.12097294e+10, 1.87393420e+10,\n",
       "        1.89305288e+10, 2.47427063e+10, 1.79901624e+10, 2.66727046e+10,\n",
       "        1.87999169e+10, 1.80580322e+10, 2.29913330e+10, 1.73766079e+10,\n",
       "        3.94342640e+10, 1.70331159e+10, 1.85193846e+10, 1.73029845e+10,\n",
       "        1.61597887e+10, 4.63391684e+10, 1.92069888e+10, 1.69674101e+10,\n",
       "        2.32853142e+10, 5.10686296e+10, 2.05853891e+10, 4.65425111e+10,\n",
       "        2.37648572e+10, 1.82857919e+10, 1.67478728e+10, 1.68818189e+10,\n",
       "        2.67201197e+10, 5.68324380e+10, 1.81661668e+10, 1.70009035e+10,\n",
       "        2.24192837e+10, 3.44447645e+10, 1.67235010e+10, 1.95572229e+10]),\n",
       " 'std_test_MAPE': array([7.09593014e+09, 6.97554776e+09, 1.35379786e+10, 6.30668752e+09,\n",
       "        6.74214797e+09, 7.32625372e+09, 7.54329154e+09, 5.32538434e+09,\n",
       "        5.96065930e+09, 4.16651828e+09, 8.28970129e+09, 8.75721161e+09,\n",
       "        7.35920929e+09, 4.07910423e+09, 5.36309453e+09, 7.07978906e+09,\n",
       "        2.04475603e+10, 1.51631747e+10, 7.87414998e+09, 5.99194277e+09,\n",
       "        6.81177006e+09, 4.35386232e+09, 7.83027277e+09, 6.20812794e+09,\n",
       "        1.20168895e+10, 8.34289702e+09, 1.38645968e+10, 6.69839119e+09,\n",
       "        7.01335030e+09, 6.51927843e+09, 6.02230596e+09, 7.53585581e+09,\n",
       "        5.95344991e+09, 6.53588342e+09, 7.02658387e+09, 7.72749551e+09,\n",
       "        8.17855386e+09, 7.51076421e+09, 2.13924265e+10, 4.67934514e+09,\n",
       "        1.37404396e+10, 7.28250230e+09, 6.61960286e+09, 5.69880161e+09,\n",
       "        6.92928716e+09, 5.85380341e+09, 4.96335233e+09, 6.67380706e+09,\n",
       "        6.96174877e+09, 6.82147748e+09, 8.48010937e+09, 8.64530640e+09,\n",
       "        6.42473822e+09, 6.26045067e+09, 6.17934551e+09, 1.42087127e+10,\n",
       "        1.04136687e+10, 5.05111422e+09, 1.13316118e+10, 6.10778460e+09,\n",
       "        6.42788230e+09, 5.84682117e+09, 7.03286663e+09, 4.86527004e+09,\n",
       "        7.42724179e+09, 5.50529827e+09, 8.01600217e+09, 5.88418635e+09,\n",
       "        5.93655390e+09, 6.19145645e+09, 5.51601237e+09, 1.01082674e+10,\n",
       "        8.06554817e+09, 6.60805427e+09, 5.76004799e+09, 5.26183988e+09,\n",
       "        1.13785747e+10, 6.79009013e+09, 6.81914171e+09, 1.00255523e+10,\n",
       "        4.32223004e+09, 1.54490258e+10, 7.17907281e+09, 5.95590425e+09,\n",
       "        8.00787988e+09, 1.71843706e+10, 6.31818758e+09, 1.58995282e+10,\n",
       "        8.56650540e+09, 7.19152841e+09, 5.99167529e+09, 6.78374509e+09,\n",
       "        1.29811468e+10, 1.99299015e+10, 5.74054192e+09, 5.47273036e+09,\n",
       "        6.62271381e+09, 1.19966853e+10, 5.42263022e+09, 5.38695261e+09]),\n",
       " 'rank_test_MAPE': array([ 35,  88,  17,  75,  60,  36,  59,  92,  53,  72,  74,  15,  30,\n",
       "         93,  55,  31,   3,   7,  34,  96,  73,  65,  19,  81,  23,  43,\n",
       "          8,  79,  40,  38,  45,  83,  82,  20, 100,  57,  39,  97,   1,\n",
       "         77,  22,  42,  89,  51,  18,  94,  98,  76,  27,  41,  33,  16,\n",
       "         48,  54,  46,   9,  28,  99,  11,  50,  62,  47,  25,  71,  63,\n",
       "         66,  37,  61,  56,  21,  70,  14,  58,  69,  29,  78,  10,  84,\n",
       "         64,  80,  95,   6,  52,  86,  26,   4,  44,   5,  24,  67,  90,\n",
       "         87,  13,   2,  68,  85,  32,  12,  91,  49])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "      <th>split0_test_MAPE</th>\n",
       "      <th>split1_test_MAPE</th>\n",
       "      <th>split2_test_MAPE</th>\n",
       "      <th>split3_test_MAPE</th>\n",
       "      <th>split4_test_MAPE</th>\n",
       "      <th>mean_test_MAPE</th>\n",
       "      <th>std_test_MAPE</th>\n",
       "      <th>rank_test_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275674</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.7</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>62</td>\n",
       "      <td>1.507643e+10</td>\n",
       "      <td>2.166136e+10</td>\n",
       "      <td>2.054068e+10</td>\n",
       "      <td>3.502022e+10</td>\n",
       "      <td>1.630390e+10</td>\n",
       "      <td>2.172052e+10</td>\n",
       "      <td>7.095930e+09</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410323</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.9</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>20</td>\n",
       "      <td>4.394060e+09</td>\n",
       "      <td>1.847209e+10</td>\n",
       "      <td>1.587075e+10</td>\n",
       "      <td>2.543578e+10</td>\n",
       "      <td>2.014181e+10</td>\n",
       "      <td>1.686290e+10</td>\n",
       "      <td>6.975548e+09</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.091790</td>\n",
       "      <td>0.052633</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>3</td>\n",
       "      <td>1.404947e+10</td>\n",
       "      <td>1.866046e+10</td>\n",
       "      <td>5.149916e+10</td>\n",
       "      <td>2.736264e+10</td>\n",
       "      <td>1.777059e+10</td>\n",
       "      <td>2.586846e+10</td>\n",
       "      <td>1.353798e+10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264261</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>64</td>\n",
       "      <td>9.820479e+09</td>\n",
       "      <td>2.103009e+10</td>\n",
       "      <td>1.480507e+10</td>\n",
       "      <td>2.773704e+10</td>\n",
       "      <td>1.357154e+10</td>\n",
       "      <td>1.739284e+10</td>\n",
       "      <td>6.306688e+09</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.036444</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>83</td>\n",
       "      <td>8.037332e+09</td>\n",
       "      <td>2.192793e+10</td>\n",
       "      <td>2.034932e+10</td>\n",
       "      <td>2.814912e+10</td>\n",
       "      <td>1.535559e+10</td>\n",
       "      <td>1.876386e+10</td>\n",
       "      <td>6.742148e+09</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.021475</td>\n",
       "      <td>0.023953</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.9</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>61</td>\n",
       "      <td>8.298910e+09</td>\n",
       "      <td>1.848218e+10</td>\n",
       "      <td>1.836216e+10</td>\n",
       "      <td>2.506947e+10</td>\n",
       "      <td>1.479179e+10</td>\n",
       "      <td>1.700090e+10</td>\n",
       "      <td>5.472730e+09</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.619287</td>\n",
       "      <td>0.024680</td>\n",
       "      <td>0.018069</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>95</td>\n",
       "      <td>1.247212e+10</td>\n",
       "      <td>2.430231e+10</td>\n",
       "      <td>2.271146e+10</td>\n",
       "      <td>3.288260e+10</td>\n",
       "      <td>1.972792e+10</td>\n",
       "      <td>2.241928e+10</td>\n",
       "      <td>6.622714e+09</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>58</td>\n",
       "      <td>1.505537e+10</td>\n",
       "      <td>3.585074e+10</td>\n",
       "      <td>4.366722e+10</td>\n",
       "      <td>4.927144e+10</td>\n",
       "      <td>2.837906e+10</td>\n",
       "      <td>3.444476e+10</td>\n",
       "      <td>1.199669e+10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.691025</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.9</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>73</td>\n",
       "      <td>9.659299e+09</td>\n",
       "      <td>1.906933e+10</td>\n",
       "      <td>1.420130e+10</td>\n",
       "      <td>2.577722e+10</td>\n",
       "      <td>1.491036e+10</td>\n",
       "      <td>1.672350e+10</td>\n",
       "      <td>5.422630e+09</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.025712</td>\n",
       "      <td>0.026976</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>53</td>\n",
       "      <td>1.203184e+10</td>\n",
       "      <td>1.695110e+10</td>\n",
       "      <td>2.671225e+10</td>\n",
       "      <td>2.465441e+10</td>\n",
       "      <td>1.743652e+10</td>\n",
       "      <td>1.955722e+10</td>\n",
       "      <td>5.386953e+09</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.275674      0.007938         0.006251        0.007655   \n",
       "1        1.410323      0.041690         0.021302        0.007003   \n",
       "2        1.091790      0.052633         0.012500        0.006250   \n",
       "3        0.264261      0.022964         0.000000        0.000000   \n",
       "4        0.525000      0.036444         0.009376        0.007655   \n",
       "..            ...           ...              ...             ...   \n",
       "95       1.021475      0.023953         0.010539        0.007178   \n",
       "96       0.619287      0.024680         0.018069        0.002638   \n",
       "97       0.036196      0.007489         0.000000        0.000000   \n",
       "98       0.691025      0.031239         0.008323        0.007060   \n",
       "99       1.025712      0.026976         0.016824        0.000211   \n",
       "\n",
       "   param_subsample param_n_estimators param_min_samples_split  \\\n",
       "0              0.7                 41                       6   \n",
       "1              0.9                 26                       5   \n",
       "2              0.5                 46                       2   \n",
       "3              0.9                  6                       8   \n",
       "4              0.6                 16                       6   \n",
       "..             ...                ...                     ...   \n",
       "95             0.9                 31                       3   \n",
       "96             0.5                 21                       8   \n",
       "97             0.6                  1                       2   \n",
       "98             0.9                 16                       9   \n",
       "99             0.5                 41                       7   \n",
       "\n",
       "   param_min_samples_leaf param_max_depth param_learning_rate  ...  \\\n",
       "0                       5               2                 0.9  ...   \n",
       "1                       2              22                 0.6  ...   \n",
       "2                       5              14                 0.9  ...   \n",
       "3                       6              20                 0.5  ...   \n",
       "4                       5              23                 0.2  ...   \n",
       "..                    ...             ...                 ...  ...   \n",
       "95                      5               9                 0.4  ...   \n",
       "96                      9              17                 0.1  ...   \n",
       "97                      9              25                 0.7  ...   \n",
       "98                      8              13                 0.4  ...   \n",
       "99                      9              23                 0.4  ...   \n",
       "\n",
       "   std_test_RMSE  rank_test_RMSE  split0_test_MAPE  split1_test_MAPE  \\\n",
       "0       0.002149              62      1.507643e+10      2.166136e+10   \n",
       "1       0.002116              20      4.394060e+09      1.847209e+10   \n",
       "2       0.001257               3      1.404947e+10      1.866046e+10   \n",
       "3       0.001875              64      9.820479e+09      2.103009e+10   \n",
       "4       0.002132              83      8.037332e+09      2.192793e+10   \n",
       "..           ...             ...               ...               ...   \n",
       "95      0.002062              61      8.298910e+09      1.848218e+10   \n",
       "96      0.001867              95      1.247212e+10      2.430231e+10   \n",
       "97      0.002231              58      1.505537e+10      3.585074e+10   \n",
       "98      0.001954              73      9.659299e+09      1.906933e+10   \n",
       "99      0.001519              53      1.203184e+10      1.695110e+10   \n",
       "\n",
       "    split2_test_MAPE  split3_test_MAPE  split4_test_MAPE  mean_test_MAPE  \\\n",
       "0       2.054068e+10      3.502022e+10      1.630390e+10    2.172052e+10   \n",
       "1       1.587075e+10      2.543578e+10      2.014181e+10    1.686290e+10   \n",
       "2       5.149916e+10      2.736264e+10      1.777059e+10    2.586846e+10   \n",
       "3       1.480507e+10      2.773704e+10      1.357154e+10    1.739284e+10   \n",
       "4       2.034932e+10      2.814912e+10      1.535559e+10    1.876386e+10   \n",
       "..               ...               ...               ...             ...   \n",
       "95      1.836216e+10      2.506947e+10      1.479179e+10    1.700090e+10   \n",
       "96      2.271146e+10      3.288260e+10      1.972792e+10    2.241928e+10   \n",
       "97      4.366722e+10      4.927144e+10      2.837906e+10    3.444476e+10   \n",
       "98      1.420130e+10      2.577722e+10      1.491036e+10    1.672350e+10   \n",
       "99      2.671225e+10      2.465441e+10      1.743652e+10    1.955722e+10   \n",
       "\n",
       "    std_test_MAPE  rank_test_MAPE  \n",
       "0    7.095930e+09              35  \n",
       "1    6.975548e+09              88  \n",
       "2    1.353798e+10              17  \n",
       "3    6.306688e+09              75  \n",
       "4    6.742148e+09              60  \n",
       "..            ...             ...  \n",
       "95   5.472730e+09              85  \n",
       "96   6.622714e+09              32  \n",
       "97   1.199669e+10              12  \n",
       "98   5.422630e+09              91  \n",
       "99   5.386953e+09              49  \n",
       "\n",
       "[100 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "pd.DataFrame(rs.cv_results_).to_excel('GBR_RS_unscal_CO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAYESSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_regression_cv(learning_rate,n_estimators, subsample, min_samples_split, min_samples_leaf, max_depth):\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        subsample= (subsample), \n",
    "        min_samples_split=int(min_samples_split), \n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        max_depth=int(max_depth)\n",
    "    )\n",
    "    scores = cross_val_score(gbr, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    return -rmse  # Return only the RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt = BayesianOptimization(\n",
    "    gb_regression_cv,\n",
    "    {\n",
    "        'learning_rate': (0.01, 1.0),\n",
    "        'n_estimators': (1, 51),\n",
    "        'subsample': (0.5, 1.0),\n",
    "        'min_samples_split': (2, 11),\n",
    "        'min_samples_leaf': (1, 11),\n",
    "        'max_depth': (1, 26),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_sa... | min_sa... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.01897 \u001b[39m | \u001b[39m0.5355   \u001b[39m | \u001b[39m22.91    \u001b[39m | \u001b[39m2.568    \u001b[39m | \u001b[39m4.738    \u001b[39m | \u001b[39m27.95    \u001b[39m | \u001b[39m0.5259   \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m-0.01892 \u001b[39m | \u001b[35m0.9397   \u001b[39m | \u001b[35m21.57    \u001b[39m | \u001b[35m4.524    \u001b[39m | \u001b[35m9.03     \u001b[39m | \u001b[35m35.58    \u001b[39m | \u001b[35m0.9588   \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m-0.0184  \u001b[39m | \u001b[35m0.6452   \u001b[39m | \u001b[35m13.95    \u001b[39m | \u001b[35m2.687    \u001b[39m | \u001b[35m3.765    \u001b[39m | \u001b[35m41.32    \u001b[39m | \u001b[35m0.7727   \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-0.01708 \u001b[39m | \u001b[35m0.4309   \u001b[39m | \u001b[35m25.37    \u001b[39m | \u001b[35m3.083    \u001b[39m | \u001b[35m5.71     \u001b[39m | \u001b[35m13.86    \u001b[39m | \u001b[35m0.6464   \u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m-0.01651 \u001b[39m | \u001b[35m0.6337   \u001b[39m | \u001b[35m7.167    \u001b[39m | \u001b[35m10.96    \u001b[39m | \u001b[35m5.99     \u001b[39m | \u001b[35m28.22    \u001b[39m | \u001b[35m0.5776   \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-0.01513 \u001b[39m | \u001b[35m0.09894  \u001b[39m | \u001b[35m11.27    \u001b[39m | \u001b[35m4.21     \u001b[39m | \u001b[35m3.976    \u001b[39m | \u001b[35m21.4     \u001b[39m | \u001b[35m0.686    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.01617 \u001b[39m | \u001b[39m0.2937   \u001b[39m | \u001b[39m22.91    \u001b[39m | \u001b[39m6.679    \u001b[39m | \u001b[39m8.977    \u001b[39m | \u001b[39m31.87    \u001b[39m | \u001b[39m0.6412   \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.01887 \u001b[39m | \u001b[39m0.0224   \u001b[39m | \u001b[39m24.28    \u001b[39m | \u001b[39m6.215    \u001b[39m | \u001b[39m5.991    \u001b[39m | \u001b[39m16.07    \u001b[39m | \u001b[39m0.8412   \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.0197  \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m12.18    \u001b[39m | \u001b[39m4.027    \u001b[39m | \u001b[39m8.546    \u001b[39m | \u001b[39m32.75    \u001b[39m | \u001b[39m0.5177   \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.01817 \u001b[39m | \u001b[39m0.9157   \u001b[39m | \u001b[39m13.76    \u001b[39m | \u001b[39m5.885    \u001b[39m | \u001b[39m3.863    \u001b[39m | \u001b[39m26.68    \u001b[39m | \u001b[39m0.8831   \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.01521 \u001b[39m | \u001b[39m0.1003   \u001b[39m | \u001b[39m11.28    \u001b[39m | \u001b[39m4.211    \u001b[39m | \u001b[39m3.977    \u001b[39m | \u001b[39m21.4     \u001b[39m | \u001b[39m0.6873   \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.01549 \u001b[39m | \u001b[39m0.06359  \u001b[39m | \u001b[39m11.24    \u001b[39m | \u001b[39m4.174    \u001b[39m | \u001b[39m3.941    \u001b[39m | \u001b[39m21.37    \u001b[39m | \u001b[39m0.6506   \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.01674 \u001b[39m | \u001b[39m0.4834   \u001b[39m | \u001b[39m11.98    \u001b[39m | \u001b[39m4.021    \u001b[39m | \u001b[39m4.294    \u001b[39m | \u001b[39m21.4     \u001b[39m | \u001b[39m0.7668   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.01665 \u001b[39m | \u001b[39m0.05464  \u001b[39m | \u001b[39m24.29    \u001b[39m | \u001b[39m10.8     \u001b[39m | \u001b[39m7.32     \u001b[39m | \u001b[39m15.73    \u001b[39m | \u001b[39m0.8595   \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.01694 \u001b[39m | \u001b[39m0.4117   \u001b[39m | \u001b[39m23.4     \u001b[39m | \u001b[39m6.988    \u001b[39m | \u001b[39m9.131    \u001b[39m | \u001b[39m32.18    \u001b[39m | \u001b[39m0.7715   \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.01681 \u001b[39m | \u001b[39m0.03559  \u001b[39m | \u001b[39m10.81    \u001b[39m | \u001b[39m4.077    \u001b[39m | \u001b[39m3.769    \u001b[39m | \u001b[39m20.74    \u001b[39m | \u001b[39m0.7922   \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.01654 \u001b[39m | \u001b[39m0.453    \u001b[39m | \u001b[39m12.46    \u001b[39m | \u001b[39m4.116    \u001b[39m | \u001b[39m4.608    \u001b[39m | \u001b[39m21.88    \u001b[39m | \u001b[39m0.6271   \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.01597 \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m7.331    \u001b[39m | \u001b[39m10.73    \u001b[39m | \u001b[39m6.415    \u001b[39m | \u001b[39m27.84    \u001b[39m | \u001b[39m0.982    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-0.01519 \u001b[39m | \u001b[39m0.1435   \u001b[39m | \u001b[39m6.602    \u001b[39m | \u001b[39m10.94    \u001b[39m | \u001b[39m6.745    \u001b[39m | \u001b[39m27.72    \u001b[39m | \u001b[39m0.5788   \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.01564 \u001b[39m | \u001b[39m0.1469   \u001b[39m | \u001b[39m24.03    \u001b[39m | \u001b[39m7.614    \u001b[39m | \u001b[39m9.861    \u001b[39m | \u001b[39m28.48    \u001b[39m | \u001b[39m0.889    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.01866 \u001b[39m | \u001b[39m0.6533   \u001b[39m | \u001b[39m22.75    \u001b[39m | \u001b[39m6.61     \u001b[39m | \u001b[39m9.466    \u001b[39m | \u001b[39m32.44    \u001b[39m | \u001b[39m0.5112   \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.01651 \u001b[39m | \u001b[39m0.8732   \u001b[39m | \u001b[39m6.891    \u001b[39m | \u001b[39m10.5     \u001b[39m | \u001b[39m6.382    \u001b[39m | \u001b[39m28.2     \u001b[39m | \u001b[39m0.8579   \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.01748 \u001b[39m | \u001b[39m0.9858   \u001b[39m | \u001b[39m7.119    \u001b[39m | \u001b[39m9.748    \u001b[39m | \u001b[39m4.135    \u001b[39m | \u001b[39m39.5     \u001b[39m | \u001b[39m0.8122   \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-0.01925 \u001b[39m | \u001b[39m0.03219  \u001b[39m | \u001b[39m7.663    \u001b[39m | \u001b[39m8.411    \u001b[39m | \u001b[39m7.74     \u001b[39m | \u001b[39m10.31    \u001b[39m | \u001b[39m0.8632   \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.01706 \u001b[39m | \u001b[39m0.5122   \u001b[39m | \u001b[39m24.17    \u001b[39m | \u001b[39m7.263    \u001b[39m | \u001b[39m10.05    \u001b[39m | \u001b[39m28.9     \u001b[39m | \u001b[39m0.9234   \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.01722 \u001b[39m | \u001b[39m0.621    \u001b[39m | \u001b[39m17.37    \u001b[39m | \u001b[39m6.547    \u001b[39m | \u001b[39m9.998    \u001b[39m | \u001b[39m28.76    \u001b[39m | \u001b[39m0.9704   \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.0157  \u001b[39m | \u001b[39m0.2245   \u001b[39m | \u001b[39m18.84    \u001b[39m | \u001b[39m2.375    \u001b[39m | \u001b[39m3.618    \u001b[39m | \u001b[39m10.29    \u001b[39m | \u001b[39m0.581    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.01525 \u001b[39m | \u001b[39m0.2711   \u001b[39m | \u001b[39m7.46     \u001b[39m | \u001b[39m9.814    \u001b[39m | \u001b[39m6.548    \u001b[39m | \u001b[39m28.01    \u001b[39m | \u001b[39m0.8105   \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.01534 \u001b[39m | \u001b[39m0.2228   \u001b[39m | \u001b[39m6.814    \u001b[39m | \u001b[39m10.9     \u001b[39m | \u001b[39m6.588    \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.969    \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.01605 \u001b[39m | \u001b[39m0.1626   \u001b[39m | \u001b[39m18.65    \u001b[39m | \u001b[39m2.882    \u001b[39m | \u001b[39m3.725    \u001b[39m | \u001b[39m9.779    \u001b[39m | \u001b[39m0.9536   \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-0.01645 \u001b[39m | \u001b[39m0.3105   \u001b[39m | \u001b[39m18.2     \u001b[39m | \u001b[39m2.352    \u001b[39m | \u001b[39m3.579    \u001b[39m | \u001b[39m10.81    \u001b[39m | \u001b[39m0.8038   \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-0.01941 \u001b[39m | \u001b[39m0.8012   \u001b[39m | \u001b[39m23.1     \u001b[39m | \u001b[39m6.469    \u001b[39m | \u001b[39m8.725    \u001b[39m | \u001b[39m31.68    \u001b[39m | \u001b[39m0.6005   \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-0.01652 \u001b[39m | \u001b[39m0.3659   \u001b[39m | \u001b[39m12.64    \u001b[39m | \u001b[39m3.958    \u001b[39m | \u001b[39m5.464    \u001b[39m | \u001b[39m21.92    \u001b[39m | \u001b[39m0.9694   \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-0.01645 \u001b[39m | \u001b[39m0.6096   \u001b[39m | \u001b[39m7.412    \u001b[39m | \u001b[39m9.718    \u001b[39m | \u001b[39m6.086    \u001b[39m | \u001b[39m28.12    \u001b[39m | \u001b[39m0.6594   \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-0.01544 \u001b[39m | \u001b[39m0.1357   \u001b[39m | \u001b[39m12.58    \u001b[39m | \u001b[39m4.442    \u001b[39m | \u001b[39m4.987    \u001b[39m | \u001b[39m22.21    \u001b[39m | \u001b[39m0.7335   \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-0.01734 \u001b[39m | \u001b[39m0.5059   \u001b[39m | \u001b[39m18.55    \u001b[39m | \u001b[39m3.425    \u001b[39m | \u001b[39m3.779    \u001b[39m | \u001b[39m9.948    \u001b[39m | \u001b[39m0.7161   \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-0.01619 \u001b[39m | \u001b[39m0.2842   \u001b[39m | \u001b[39m16.22    \u001b[39m | \u001b[39m3.621    \u001b[39m | \u001b[39m7.93     \u001b[39m | \u001b[39m13.92    \u001b[39m | \u001b[39m0.8655   \u001b[39m |\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-0.01564 \u001b[39m | \u001b[39m0.2841   \u001b[39m | \u001b[39m12.47    \u001b[39m | \u001b[39m4.156    \u001b[39m | \u001b[39m4.753    \u001b[39m | \u001b[39m21.44    \u001b[39m | \u001b[39m0.6141   \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-0.01684 \u001b[39m | \u001b[39m0.5069   \u001b[39m | \u001b[39m12.5     \u001b[39m | \u001b[39m4.386    \u001b[39m | \u001b[39m5.488    \u001b[39m | \u001b[39m21.79    \u001b[39m | \u001b[39m0.5823   \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-0.01524 \u001b[39m | \u001b[39m0.08131  \u001b[39m | \u001b[39m5.622    \u001b[39m | \u001b[39m10.52    \u001b[39m | \u001b[39m7.036    \u001b[39m | \u001b[39m27.92    \u001b[39m | \u001b[39m0.8192   \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-0.01668 \u001b[39m | \u001b[39m0.7749   \u001b[39m | \u001b[39m7.427    \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m5.953    \u001b[39m | \u001b[39m27.47    \u001b[39m | \u001b[39m0.6299   \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-0.01582 \u001b[39m | \u001b[39m0.2847   \u001b[39m | \u001b[39m16.2     \u001b[39m | \u001b[39m3.767    \u001b[39m | \u001b[39m8.023    \u001b[39m | \u001b[39m13.43    \u001b[39m | \u001b[39m0.8232   \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-0.01663 \u001b[39m | \u001b[39m0.436    \u001b[39m | \u001b[39m20.13    \u001b[39m | \u001b[39m3.099    \u001b[39m | \u001b[39m7.824    \u001b[39m | \u001b[39m13.31    \u001b[39m | \u001b[39m0.6632   \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-0.01809 \u001b[39m | \u001b[39m0.8614   \u001b[39m | \u001b[39m22.79    \u001b[39m | \u001b[39m6.982    \u001b[39m | \u001b[39m7.862    \u001b[39m | \u001b[39m28.86    \u001b[39m | \u001b[39m0.9499   \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-0.01814 \u001b[39m | \u001b[39m0.5331   \u001b[39m | \u001b[39m18.1     \u001b[39m | \u001b[39m2.65     \u001b[39m | \u001b[39m4.095    \u001b[39m | \u001b[39m10.55    \u001b[39m | \u001b[39m0.6327   \u001b[39m |\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-0.01632 \u001b[39m | \u001b[39m0.2673   \u001b[39m | \u001b[39m22.25    \u001b[39m | \u001b[39m7.054    \u001b[39m | \u001b[39m9.434    \u001b[39m | \u001b[39m31.86    \u001b[39m | \u001b[39m0.8864   \u001b[39m |\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-0.01698 \u001b[39m | \u001b[39m0.03439  \u001b[39m | \u001b[39m11.63    \u001b[39m | \u001b[39m4.608    \u001b[39m | \u001b[39m3.865    \u001b[39m | \u001b[39m20.79    \u001b[39m | \u001b[39m0.9095   \u001b[39m |\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-0.01518 \u001b[39m | \u001b[39m0.09198  \u001b[39m | \u001b[39m5.657    \u001b[39m | \u001b[39m10.28    \u001b[39m | \u001b[39m7.389    \u001b[39m | \u001b[39m27.71    \u001b[39m | \u001b[39m0.681    \u001b[39m |\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-0.01513 \u001b[39m | \u001b[39m0.1911   \u001b[39m | \u001b[39m14.75    \u001b[39m | \u001b[39m9.52     \u001b[39m | \u001b[39m10.37    \u001b[39m | \u001b[39m15.91    \u001b[39m | \u001b[39m0.5976   \u001b[39m |\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-0.01565 \u001b[39m | \u001b[39m0.5545   \u001b[39m | \u001b[39m6.757    \u001b[39m | \u001b[39m10.4     \u001b[39m | \u001b[39m6.459    \u001b[39m | \u001b[39m28.01    \u001b[39m | \u001b[39m0.8583   \u001b[39m |\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-0.01585 \u001b[39m | \u001b[39m0.2386   \u001b[39m | \u001b[39m16.3     \u001b[39m | \u001b[39m3.529    \u001b[39m | \u001b[39m7.417    \u001b[39m | \u001b[39m13.7     \u001b[39m | \u001b[39m0.877    \u001b[39m |\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-0.01574 \u001b[39m | \u001b[39m0.04997  \u001b[39m | \u001b[39m6.738    \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m6.616    \u001b[39m | \u001b[39m27.73    \u001b[39m | \u001b[39m0.8861   \u001b[39m |\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-0.01572 \u001b[39m | \u001b[39m0.2071   \u001b[39m | \u001b[39m13.18    \u001b[39m | \u001b[39m4.554    \u001b[39m | \u001b[39m5.26     \u001b[39m | \u001b[39m22.17    \u001b[39m | \u001b[39m0.8736   \u001b[39m |\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-0.01601 \u001b[39m | \u001b[39m0.6633   \u001b[39m | \u001b[39m6.668    \u001b[39m | \u001b[39m9.826    \u001b[39m | \u001b[39m6.208    \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.7518   \u001b[39m |\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-0.01756 \u001b[39m | \u001b[39m0.4893   \u001b[39m | \u001b[39m18.9     \u001b[39m | \u001b[39m1.954    \u001b[39m | \u001b[39m3.43     \u001b[39m | \u001b[39m10.17    \u001b[39m | \u001b[39m0.8153   \u001b[39m |\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-0.01584 \u001b[39m | \u001b[39m0.1801   \u001b[39m | \u001b[39m18.76    \u001b[39m | \u001b[39m2.971    \u001b[39m | \u001b[39m3.968    \u001b[39m | \u001b[39m9.603    \u001b[39m | \u001b[39m0.8387   \u001b[39m |\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-0.01784 \u001b[39m | \u001b[39m0.7845   \u001b[39m | \u001b[39m17.05    \u001b[39m | \u001b[39m8.848    \u001b[39m | \u001b[39m3.874    \u001b[39m | \u001b[39m37.39    \u001b[39m | \u001b[39m0.8645   \u001b[39m |\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-0.01518 \u001b[39m | \u001b[39m0.1887   \u001b[39m | \u001b[39m7.602    \u001b[39m | \u001b[39m10.86    \u001b[39m | \u001b[39m5.788    \u001b[39m | \u001b[39m28.18    \u001b[39m | \u001b[39m0.824    \u001b[39m |\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m-0.017   \u001b[39m | \u001b[39m0.5236   \u001b[39m | \u001b[39m12.14    \u001b[39m | \u001b[39m3.748    \u001b[39m | \u001b[39m4.772    \u001b[39m | \u001b[39m22.06    \u001b[39m | \u001b[39m0.7912   \u001b[39m |\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-0.01547 \u001b[39m | \u001b[39m0.4557   \u001b[39m | \u001b[39m4.992    \u001b[39m | \u001b[39m10.4     \u001b[39m | \u001b[39m7.037    \u001b[39m | \u001b[39m28.18    \u001b[39m | \u001b[39m0.7086   \u001b[39m |\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m-0.01657 \u001b[39m | \u001b[39m0.3348   \u001b[39m | \u001b[39m12.74    \u001b[39m | \u001b[39m3.604    \u001b[39m | \u001b[39m5.761    \u001b[39m | \u001b[39m22.0     \u001b[39m | \u001b[39m0.8764   \u001b[39m |\n",
      "| \u001b[35m62       \u001b[39m | \u001b[35m-0.0151  \u001b[39m | \u001b[35m0.1368   \u001b[39m | \u001b[35m5.578    \u001b[39m | \u001b[35m10.41    \u001b[39m | \u001b[35m7.329    \u001b[39m | \u001b[35m27.2     \u001b[39m | \u001b[35m0.7632   \u001b[39m |\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m-0.01652 \u001b[39m | \u001b[39m0.5762   \u001b[39m | \u001b[39m13.33    \u001b[39m | \u001b[39m5.585    \u001b[39m | \u001b[39m3.739    \u001b[39m | \u001b[39m18.89    \u001b[39m | \u001b[39m0.8329   \u001b[39m |\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m-0.01723 \u001b[39m | \u001b[39m0.4866   \u001b[39m | \u001b[39m19.96    \u001b[39m | \u001b[39m2.652    \u001b[39m | \u001b[39m8.094    \u001b[39m | \u001b[39m13.46    \u001b[39m | \u001b[39m0.7933   \u001b[39m |\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m-0.01579 \u001b[39m | \u001b[39m0.2644   \u001b[39m | \u001b[39m12.36    \u001b[39m | \u001b[39m4.096    \u001b[39m | \u001b[39m4.706    \u001b[39m | \u001b[39m22.56    \u001b[39m | \u001b[39m0.6053   \u001b[39m |\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m-0.01758 \u001b[39m | \u001b[39m0.6227   \u001b[39m | \u001b[39m18.9     \u001b[39m | \u001b[39m2.641    \u001b[39m | \u001b[39m3.922    \u001b[39m | \u001b[39m9.556    \u001b[39m | \u001b[39m0.8384   \u001b[39m |\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m-0.01564 \u001b[39m | \u001b[39m0.3611   \u001b[39m | \u001b[39m7.695    \u001b[39m | \u001b[39m9.889    \u001b[39m | \u001b[39m6.249    \u001b[39m | \u001b[39m28.58    \u001b[39m | \u001b[39m0.9521   \u001b[39m |\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m-0.01564 \u001b[39m | \u001b[39m0.04788  \u001b[39m | \u001b[39m7.636    \u001b[39m | \u001b[39m10.92    \u001b[39m | \u001b[39m6.115    \u001b[39m | \u001b[39m28.03    \u001b[39m | \u001b[39m0.5251   \u001b[39m |\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m-0.01511 \u001b[39m | \u001b[39m0.1961   \u001b[39m | \u001b[39m6.637    \u001b[39m | \u001b[39m10.46    \u001b[39m | \u001b[39m6.77     \u001b[39m | \u001b[39m28.17    \u001b[39m | \u001b[39m0.5853   \u001b[39m |\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m-0.01512 \u001b[39m | \u001b[39m0.07437  \u001b[39m | \u001b[39m5.78     \u001b[39m | \u001b[39m4.158    \u001b[39m | \u001b[39m2.946    \u001b[39m | \u001b[39m45.14    \u001b[39m | \u001b[39m0.7549   \u001b[39m |\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m-0.0154  \u001b[39m | \u001b[39m0.1959   \u001b[39m | \u001b[39m4.997    \u001b[39m | \u001b[39m10.48    \u001b[39m | \u001b[39m7.296    \u001b[39m | \u001b[39m26.78    \u001b[39m | \u001b[39m0.6192   \u001b[39m |\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m-0.01583 \u001b[39m | \u001b[39m0.2377   \u001b[39m | \u001b[39m11.91    \u001b[39m | \u001b[39m6.585    \u001b[39m | \u001b[39m10.51    \u001b[39m | \u001b[39m40.87    \u001b[39m | \u001b[39m0.5362   \u001b[39m |\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m-0.01737 \u001b[39m | \u001b[39m0.455    \u001b[39m | \u001b[39m16.55    \u001b[39m | \u001b[39m3.645    \u001b[39m | \u001b[39m7.373    \u001b[39m | \u001b[39m14.13    \u001b[39m | \u001b[39m0.5662   \u001b[39m |\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m-0.01602 \u001b[39m | \u001b[39m0.8043   \u001b[39m | \u001b[39m3.184    \u001b[39m | \u001b[39m2.935    \u001b[39m | \u001b[39m9.089    \u001b[39m | \u001b[39m46.85    \u001b[39m | \u001b[39m0.9161   \u001b[39m |\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m-0.01817 \u001b[39m | \u001b[39m0.6421   \u001b[39m | \u001b[39m15.96    \u001b[39m | \u001b[39m3.352    \u001b[39m | \u001b[39m8.03     \u001b[39m | \u001b[39m13.5     \u001b[39m | \u001b[39m0.7357   \u001b[39m |\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m-0.01536 \u001b[39m | \u001b[39m0.199    \u001b[39m | \u001b[39m6.195    \u001b[39m | \u001b[39m4.224    \u001b[39m | \u001b[39m3.028    \u001b[39m | \u001b[39m45.36    \u001b[39m | \u001b[39m0.5337   \u001b[39m |\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m-0.01836 \u001b[39m | \u001b[39m0.01052  \u001b[39m | \u001b[39m5.629    \u001b[39m | \u001b[39m3.829    \u001b[39m | \u001b[39m2.651    \u001b[39m | \u001b[39m44.83    \u001b[39m | \u001b[39m0.6568   \u001b[39m |\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m-0.01611 \u001b[39m | \u001b[39m0.7312   \u001b[39m | \u001b[39m5.017    \u001b[39m | \u001b[39m10.18    \u001b[39m | \u001b[39m6.922    \u001b[39m | \u001b[39m28.03    \u001b[39m | \u001b[39m0.7353   \u001b[39m |\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m-0.01645 \u001b[39m | \u001b[39m0.6205   \u001b[39m | \u001b[39m20.12    \u001b[39m | \u001b[39m7.162    \u001b[39m | \u001b[39m3.665    \u001b[39m | \u001b[39m14.29    \u001b[39m | \u001b[39m0.7924   \u001b[39m |\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m-0.01672 \u001b[39m | \u001b[39m0.3541   \u001b[39m | \u001b[39m16.28    \u001b[39m | \u001b[39m3.78     \u001b[39m | \u001b[39m7.734    \u001b[39m | \u001b[39m13.36    \u001b[39m | \u001b[39m0.7282   \u001b[39m |\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m-0.01621 \u001b[39m | \u001b[39m0.3543   \u001b[39m | \u001b[39m24.49    \u001b[39m | \u001b[39m4.598    \u001b[39m | \u001b[39m3.828    \u001b[39m | \u001b[39m14.28    \u001b[39m | \u001b[39m0.705    \u001b[39m |\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m-0.01525 \u001b[39m | \u001b[39m0.1698   \u001b[39m | \u001b[39m6.456    \u001b[39m | \u001b[39m9.102    \u001b[39m | \u001b[39m4.962    \u001b[39m | \u001b[39m49.9     \u001b[39m | \u001b[39m0.8259   \u001b[39m |\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m-0.0166  \u001b[39m | \u001b[39m0.1133   \u001b[39m | \u001b[39m25.03    \u001b[39m | \u001b[39m4.698    \u001b[39m | \u001b[39m9.981    \u001b[39m | \u001b[39m7.069    \u001b[39m | \u001b[39m0.7619   \u001b[39m |\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m-0.01606 \u001b[39m | \u001b[39m0.2367   \u001b[39m | \u001b[39m21.72    \u001b[39m | \u001b[39m4.526    \u001b[39m | \u001b[39m5.948    \u001b[39m | \u001b[39m30.13    \u001b[39m | \u001b[39m0.5016   \u001b[39m |\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m-0.0163  \u001b[39m | \u001b[39m0.7655   \u001b[39m | \u001b[39m7.871    \u001b[39m | \u001b[39m9.534    \u001b[39m | \u001b[39m6.159    \u001b[39m | \u001b[39m28.54    \u001b[39m | \u001b[39m0.7496   \u001b[39m |\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m-0.01655 \u001b[39m | \u001b[39m0.7795   \u001b[39m | \u001b[39m6.764    \u001b[39m | \u001b[39m10.39    \u001b[39m | \u001b[39m6.056    \u001b[39m | \u001b[39m28.68    \u001b[39m | \u001b[39m0.7269   \u001b[39m |\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m-0.01669 \u001b[39m | \u001b[39m0.532    \u001b[39m | \u001b[39m19.84    \u001b[39m | \u001b[39m7.134    \u001b[39m | \u001b[39m3.926    \u001b[39m | \u001b[39m13.87    \u001b[39m | \u001b[39m0.6708   \u001b[39m |\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m-0.01587 \u001b[39m | \u001b[39m0.7806   \u001b[39m | \u001b[39m4.186    \u001b[39m | \u001b[39m5.395    \u001b[39m | \u001b[39m6.754    \u001b[39m | \u001b[39m7.235    \u001b[39m | \u001b[39m0.6488   \u001b[39m |\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m-0.01828 \u001b[39m | \u001b[39m0.8348   \u001b[39m | \u001b[39m13.63    \u001b[39m | \u001b[39m5.062    \u001b[39m | \u001b[39m10.46    \u001b[39m | \u001b[39m36.44    \u001b[39m | \u001b[39m0.9204   \u001b[39m |\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m-0.01635 \u001b[39m | \u001b[39m0.3688   \u001b[39m | \u001b[39m15.58    \u001b[39m | \u001b[39m3.965    \u001b[39m | \u001b[39m9.797    \u001b[39m | \u001b[39m11.74    \u001b[39m | \u001b[39m0.9307   \u001b[39m |\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m-0.0171  \u001b[39m | \u001b[39m0.396    \u001b[39m | \u001b[39m21.76    \u001b[39m | \u001b[39m4.243    \u001b[39m | \u001b[39m5.554    \u001b[39m | \u001b[39m30.03    \u001b[39m | \u001b[39m0.7143   \u001b[39m |\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m-0.01698 \u001b[39m | \u001b[39m0.8603   \u001b[39m | \u001b[39m6.525    \u001b[39m | \u001b[39m9.308    \u001b[39m | \u001b[39m4.83     \u001b[39m | \u001b[39m50.17    \u001b[39m | \u001b[39m0.7385   \u001b[39m |\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m-0.01538 \u001b[39m | \u001b[39m0.1965   \u001b[39m | \u001b[39m12.89    \u001b[39m | \u001b[39m4.676    \u001b[39m | \u001b[39m4.321    \u001b[39m | \u001b[39m21.97    \u001b[39m | \u001b[39m0.8557   \u001b[39m |\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m-0.01586 \u001b[39m | \u001b[39m0.2736   \u001b[39m | \u001b[39m18.26    \u001b[39m | \u001b[39m2.521    \u001b[39m | \u001b[39m3.465    \u001b[39m | \u001b[39m10.97    \u001b[39m | \u001b[39m0.5123   \u001b[39m |\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m-0.0154  \u001b[39m | \u001b[39m0.07624  \u001b[39m | \u001b[39m12.84    \u001b[39m | \u001b[39m4.57     \u001b[39m | \u001b[39m4.095    \u001b[39m | \u001b[39m21.76    \u001b[39m | \u001b[39m0.7373   \u001b[39m |\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m-0.01842 \u001b[39m | \u001b[39m0.9663   \u001b[39m | \u001b[39m21.47    \u001b[39m | \u001b[39m6.906    \u001b[39m | \u001b[39m6.715    \u001b[39m | \u001b[39m17.6     \u001b[39m | \u001b[39m0.8583   \u001b[39m |\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m-0.01778 \u001b[39m | \u001b[39m0.5409   \u001b[39m | \u001b[39m12.54    \u001b[39m | \u001b[39m3.744    \u001b[39m | \u001b[39m4.587    \u001b[39m | \u001b[39m22.61    \u001b[39m | \u001b[39m0.7201   \u001b[39m |\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m-0.01797 \u001b[39m | \u001b[39m0.6748   \u001b[39m | \u001b[39m17.72    \u001b[39m | \u001b[39m7.754    \u001b[39m | \u001b[39m4.162    \u001b[39m | \u001b[39m45.23    \u001b[39m | \u001b[39m0.594    \u001b[39m |\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m-0.0171  \u001b[39m | \u001b[39m0.03184  \u001b[39m | \u001b[39m12.36    \u001b[39m | \u001b[39m4.236    \u001b[39m | \u001b[39m4.743    \u001b[39m | \u001b[39m21.2     \u001b[39m | \u001b[39m0.5576   \u001b[39m |\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m-0.01642 \u001b[39m | \u001b[39m0.5678   \u001b[39m | \u001b[39m15.08    \u001b[39m | \u001b[39m9.594    \u001b[39m | \u001b[39m10.41    \u001b[39m | \u001b[39m15.77    \u001b[39m | \u001b[39m0.543    \u001b[39m |\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m-0.01834 \u001b[39m | \u001b[39m0.7874   \u001b[39m | \u001b[39m22.0     \u001b[39m | \u001b[39m9.653    \u001b[39m | \u001b[39m10.93    \u001b[39m | \u001b[39m49.61    \u001b[39m | \u001b[39m0.7548   \u001b[39m |\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m-0.01608 \u001b[39m | \u001b[39m0.4921   \u001b[39m | \u001b[39m5.041    \u001b[39m | \u001b[39m9.791    \u001b[39m | \u001b[39m7.469    \u001b[39m | \u001b[39m26.79    \u001b[39m | \u001b[39m0.5839   \u001b[39m |\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m-0.01629 \u001b[39m | \u001b[39m0.5806   \u001b[39m | \u001b[39m7.245    \u001b[39m | \u001b[39m9.937    \u001b[39m | \u001b[39m6.843    \u001b[39m | \u001b[39m27.97    \u001b[39m | \u001b[39m0.8136   \u001b[39m |\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m-0.01534 \u001b[39m | \u001b[39m0.1868   \u001b[39m | \u001b[39m5.278    \u001b[39m | \u001b[39m9.398    \u001b[39m | \u001b[39m7.375    \u001b[39m | \u001b[39m27.13    \u001b[39m | \u001b[39m0.7165   \u001b[39m |\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m-0.0153  \u001b[39m | \u001b[39m0.2487   \u001b[39m | \u001b[39m7.721    \u001b[39m | \u001b[39m9.504    \u001b[39m | \u001b[39m6.707    \u001b[39m | \u001b[39m27.89    \u001b[39m | \u001b[39m0.748    \u001b[39m |\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m-0.01594 \u001b[39m | \u001b[39m0.2045   \u001b[39m | \u001b[39m21.81    \u001b[39m | \u001b[39m7.065    \u001b[39m | \u001b[39m9.632    \u001b[39m | \u001b[39m32.06    \u001b[39m | \u001b[39m0.9701   \u001b[39m |\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m-0.01561 \u001b[39m | \u001b[39m0.5063   \u001b[39m | \u001b[39m5.545    \u001b[39m | \u001b[39m10.79    \u001b[39m | \u001b[39m7.102    \u001b[39m | \u001b[39m28.22    \u001b[39m | \u001b[39m0.7904   \u001b[39m |\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m-0.017   \u001b[39m | \u001b[39m0.6721   \u001b[39m | \u001b[39m15.58    \u001b[39m | \u001b[39m7.78     \u001b[39m | \u001b[39m4.073    \u001b[39m | \u001b[39m13.41    \u001b[39m | \u001b[39m0.8771   \u001b[39m |\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m-0.01674 \u001b[39m | \u001b[39m0.5675   \u001b[39m | \u001b[39m15.25    \u001b[39m | \u001b[39m9.52     \u001b[39m | \u001b[39m10.39    \u001b[39m | \u001b[39m16.08    \u001b[39m | \u001b[39m0.5759   \u001b[39m |\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m-0.01576 \u001b[39m | \u001b[39m0.7887   \u001b[39m | \u001b[39m3.775    \u001b[39m | \u001b[39m5.29     \u001b[39m | \u001b[39m6.919    \u001b[39m | \u001b[39m7.404    \u001b[39m | \u001b[39m0.8214   \u001b[39m |\n",
      "=================================================================================================\n",
      "Execution time: 231.29374432563782 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bayes_opt.maximize(init_points=10, n_iter=100)\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = np.argmin([res['target'] for res in bayes_opt.res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.7032957363528153, 'max_depth': 12.1808852204168, 'min_samples_leaf': 4.027384367661961, 'min_samples_split': 8.546300204803815, 'n_estimators': 32.751883059926286, 'subsample': 0.5176940128404173}\n"
     ]
    }
   ],
   "source": [
    "best_params = bayes_opt.res[best_iter]['params']\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.7032957363528153, max_depth=12,\n",
       "                          min_samples_leaf=32, min_samples_split=8,\n",
       "                          n_estimators=32, subsample=0.5176940128404173)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.7032957363528153, max_depth=12,\n",
       "                          min_samples_leaf=32, min_samples_split=8,\n",
       "                          n_estimators=32, subsample=0.5176940128404173)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.7032957363528153, max_depth=12,\n",
       "                          min_samples_leaf=32, min_samples_split=8,\n",
       "                          n_estimators=32, subsample=0.5176940128404173)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bs = GradientBoostingRegressor(\n",
    "    learning_rate=(best_params['learning_rate']),\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    subsample=(best_params['subsample']), \n",
    "    min_samples_split=int(best_params['min_samples_split']), \n",
    "    min_samples_leaf=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    loss='squared_error'\n",
    ")\n",
    "best_bs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.016311796038417415\n",
      "MAPE: 23732661298.70%\n"
     ]
    }
   ],
   "source": [
    "y_pred_bs = best_bs.predict(X_test)\n",
    "rmse_bs = np.sqrt(mean_squared_error(y_test, y_pred_bs))\n",
    "mape_bs = mean_absolute_percentage_error(y_test, y_pred_bs)\n",
    "\n",
    "print(f\"RMSE: {rmse_bs}\")\n",
    "print(f\"MAPE: {mape_bs:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
