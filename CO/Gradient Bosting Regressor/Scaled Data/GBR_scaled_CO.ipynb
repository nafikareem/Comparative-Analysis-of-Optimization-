{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backhoe</th>\n",
       "      <th>HP(watt)</th>\n",
       "      <th>Norm_MAP</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Age</th>\n",
       "      <th>Load_Factor</th>\n",
       "      <th>Engine_Tier</th>\n",
       "      <th>TEMP[C]</th>\n",
       "      <th>Fuel[g/s]</th>\n",
       "      <th>NOx[g/s]</th>\n",
       "      <th>...</th>\n",
       "      <th>NOx[g/hr]</th>\n",
       "      <th>HC[g/hr]</th>\n",
       "      <th>CO[g/hr]</th>\n",
       "      <th>CO2[g/hr]</th>\n",
       "      <th>PM[mg/hr]</th>\n",
       "      <th>Nox (g/kl)</th>\n",
       "      <th>HC (g/kl)</th>\n",
       "      <th>CO (g/kl)</th>\n",
       "      <th>CO2 (g/kl)</th>\n",
       "      <th>PM (g/kl)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>833.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.024090</td>\n",
       "      <td>...</td>\n",
       "      <td>86.724000</td>\n",
       "      <td>25.848000</td>\n",
       "      <td>13.176000</td>\n",
       "      <td>4780.656000</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3730.117500</td>\n",
       "      <td>1111.757728</td>\n",
       "      <td>566.717728</td>\n",
       "      <td>2.056225e+05</td>\n",
       "      <td>0.619362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>800.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>...</td>\n",
       "      <td>109.152000</td>\n",
       "      <td>25.668000</td>\n",
       "      <td>16.164000</td>\n",
       "      <td>7008.264000</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4694.776362</td>\n",
       "      <td>1104.015681</td>\n",
       "      <td>695.235681</td>\n",
       "      <td>3.014350e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>826.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>...</td>\n",
       "      <td>110.628000</td>\n",
       "      <td>10.980000</td>\n",
       "      <td>10.584000</td>\n",
       "      <td>5722.920000</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4758.261138</td>\n",
       "      <td>472.264772</td>\n",
       "      <td>455.232272</td>\n",
       "      <td>2.461506e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>831.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.390522</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>...</td>\n",
       "      <td>85.293664</td>\n",
       "      <td>20.747853</td>\n",
       "      <td>4.825082</td>\n",
       "      <td>4382.553038</td>\n",
       "      <td>21.6</td>\n",
       "      <td>3668.596780</td>\n",
       "      <td>892.393432</td>\n",
       "      <td>207.533355</td>\n",
       "      <td>1.884996e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>65621.6</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>834.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.413024</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>...</td>\n",
       "      <td>93.985262</td>\n",
       "      <td>6.979907</td>\n",
       "      <td>9.880556</td>\n",
       "      <td>4673.503069</td>\n",
       "      <td>21.6</td>\n",
       "      <td>4042.434273</td>\n",
       "      <td>300.215326</td>\n",
       "      <td>424.976193</td>\n",
       "      <td>2.010137e+05</td>\n",
       "      <td>0.929047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37523</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>...</td>\n",
       "      <td>211.788000</td>\n",
       "      <td>19.908000</td>\n",
       "      <td>28.152000</td>\n",
       "      <td>17957.592000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>445343.100000</td>\n",
       "      <td>41862.100000</td>\n",
       "      <td>59197.400000</td>\n",
       "      <td>3.776083e+07</td>\n",
       "      <td>3785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37524</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>...</td>\n",
       "      <td>214.200000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>30.780000</td>\n",
       "      <td>14905.044000</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>542545.340909</td>\n",
       "      <td>50151.250000</td>\n",
       "      <td>77962.397727</td>\n",
       "      <td>3.775286e+07</td>\n",
       "      <td>4194.468182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37525</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>...</td>\n",
       "      <td>214.704000</td>\n",
       "      <td>21.744000</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>17349.048000</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>469179.694118</td>\n",
       "      <td>47515.850980</td>\n",
       "      <td>73948.509804</td>\n",
       "      <td>3.791183e+07</td>\n",
       "      <td>4090.768627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37526</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>...</td>\n",
       "      <td>202.320000</td>\n",
       "      <td>22.356000</td>\n",
       "      <td>34.740000</td>\n",
       "      <td>19948.572000</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>384340.943182</td>\n",
       "      <td>42468.990341</td>\n",
       "      <td>65994.485795</td>\n",
       "      <td>3.789568e+07</td>\n",
       "      <td>3761.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37527</th>\n",
       "      <td>8</td>\n",
       "      <td>72332.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>...</td>\n",
       "      <td>191.556000</td>\n",
       "      <td>21.168000</td>\n",
       "      <td>29.880000</td>\n",
       "      <td>19825.308000</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>365972.298857</td>\n",
       "      <td>40441.968000</td>\n",
       "      <td>57086.451429</td>\n",
       "      <td>3.787672e+07</td>\n",
       "      <td>3232.606286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37528 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backhoe  HP(watt)  Norm_MAP     RPM  Age  Load_Factor  Engine_Tier  \\\n",
       "0            1   65621.6  0.000000   833.0   12         0.21            2   \n",
       "1            1   65621.6  0.012346   800.0   12         0.21            2   \n",
       "2            1   65621.6  0.012346   826.0   12         0.21            2   \n",
       "3            1   65621.6  0.012346   831.0   12         0.21            2   \n",
       "4            1   65621.6  0.012346   834.0   12         0.21            2   \n",
       "...        ...       ...       ...     ...  ...          ...          ...   \n",
       "37523        8   72332.9  0.975904  1676.0   36         0.21            2   \n",
       "37524        8   72332.9  0.975904  1683.0   36         0.21            2   \n",
       "37525        8   72332.9  0.975904  1846.0   36         0.21            2   \n",
       "37526        8   72332.9  0.987952  1876.0   36         0.21            2   \n",
       "37527        8   72332.9  1.000000  1762.0   36         0.21            2   \n",
       "\n",
       "       TEMP[C]  Fuel[g/s]  NOx[g/s]  ...   NOx[g/hr]   HC[g/hr]   CO[g/hr]  \\\n",
       "0         22.0   0.430000  0.024090  ...   86.724000  25.848000  13.176000   \n",
       "1         22.0   0.620000  0.030320  ...  109.152000  25.668000  16.164000   \n",
       "2         22.0   0.510000  0.030730  ...  110.628000  10.980000  10.584000   \n",
       "3         22.0   0.390522  0.023693  ...   85.293664  20.747853   4.825082   \n",
       "4         22.0   0.413024  0.026107  ...   93.985262   6.979907   9.880556   \n",
       "...        ...        ...       ...  ...         ...        ...        ...   \n",
       "37523     41.0   1.590000  0.058830  ...  211.788000  19.908000  28.152000   \n",
       "37524     42.0   1.320000  0.059500  ...  214.200000  19.800000  30.780000   \n",
       "37525     42.0   1.530000  0.059640  ...  214.704000  21.744000  33.840000   \n",
       "37526     42.0   1.760000  0.056200  ...  202.320000  22.356000  34.740000   \n",
       "37527     42.0   1.750000  0.053210  ...  191.556000  21.168000  29.880000   \n",
       "\n",
       "          CO2[g/hr]  PM[mg/hr]     Nox (g/kl)     HC (g/kl)     CO (g/kl)  \\\n",
       "0       4780.656000       14.4    3730.117500   1111.757728    566.717728   \n",
       "1       7008.264000       21.6    4694.776362   1104.015681    695.235681   \n",
       "2       5722.920000       21.6    4758.261138    472.264772    455.232272   \n",
       "3       4382.553038       21.6    3668.596780    892.393432    207.533355   \n",
       "4       4673.503069       21.6    4042.434273    300.215326    424.976193   \n",
       "...             ...        ...            ...           ...           ...   \n",
       "37523  17957.592000     1800.0  445343.100000  41862.100000  59197.400000   \n",
       "37524  14905.044000     1656.0  542545.340909  50151.250000  77962.397727   \n",
       "37525  17349.048000     1872.0  469179.694118  47515.850980  73948.509804   \n",
       "37526  19948.572000     1980.0  384340.943182  42468.990341  65994.485795   \n",
       "37527  19825.308000     1692.0  365972.298857  40441.968000  57086.451429   \n",
       "\n",
       "         CO2 (g/kl)    PM (g/kl)  \n",
       "0      2.056225e+05     0.619362  \n",
       "1      3.014350e+05     0.929047  \n",
       "2      2.461506e+05     0.929047  \n",
       "3      1.884996e+05     0.929047  \n",
       "4      2.010137e+05     0.929047  \n",
       "...             ...          ...  \n",
       "37523  3.776083e+07  3785.000000  \n",
       "37524  3.775286e+07  4194.468182  \n",
       "37525  3.791183e+07  4090.768627  \n",
       "37526  3.789568e+07  3761.343750  \n",
       "37527  3.787672e+07  3232.606286  \n",
       "\n",
       "[37528 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data diolah darin.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37527 entries, 0 to 37527\n",
      "Data columns (total 30 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Backhoe      37527 non-null  int64  \n",
      " 1   HP(watt)     37527 non-null  float64\n",
      " 2   Norm_MAP     37527 non-null  float64\n",
      " 3   RPM          37527 non-null  float64\n",
      " 4   Age          37527 non-null  int64  \n",
      " 5   Load_Factor  37527 non-null  float64\n",
      " 6   Engine_Tier  37527 non-null  int64  \n",
      " 7   TEMP[C]      37527 non-null  float64\n",
      " 8   Fuel[g/s]    37527 non-null  float64\n",
      " 9   NOx[g/s]     37527 non-null  float64\n",
      " 10  HC[g/s]      37527 non-null  float64\n",
      " 11  CO[g/s]      37527 non-null  float64\n",
      " 12  CO2[g/s]     37527 non-null  float64\n",
      " 13  PM[mg/s]     37527 non-null  float64\n",
      " 14  Nox (g/l)    37527 non-null  float64\n",
      " 15  HC (g/l)     37527 non-null  float64\n",
      " 16  CO (g/l)     37527 non-null  float64\n",
      " 17  CO2 (g/l)    37527 non-null  float64\n",
      " 18  PM (g/l)     37527 non-null  float64\n",
      " 19  Fuel[g/hr]   37527 non-null  float64\n",
      " 20  NOx[g/hr]    37527 non-null  float64\n",
      " 21  HC[g/hr]     37527 non-null  float64\n",
      " 22  CO[g/hr]     37527 non-null  float64\n",
      " 23  CO2[g/hr]    37527 non-null  float64\n",
      " 24  PM[mg/hr]    37527 non-null  float64\n",
      " 25  Nox (g/kl)   37527 non-null  float64\n",
      " 26  HC (g/kl)    37527 non-null  float64\n",
      " 27  CO (g/kl)    37527 non-null  float64\n",
      " 28  CO2 (g/kl)   37527 non-null  float64\n",
      " 29  PM (g/kl)    37527 non-null  float64\n",
      "dtypes: float64(27), int64(3)\n",
      "memory usage: 8.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Backhoe', 'HP(watt)', 'Norm_MAP', 'RPM', 'Age', 'Load_Factor', 'Engine_Tier']]\n",
    "y = df['CO[g/s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictorScaler = StandardScaler()\n",
    "TargetVarScaler = StandardScaler()\n",
    "\n",
    "PredictorScalerFit = PredictorScaler.fit(X)\n",
    "TargetVarScalerFit = TargetVarScaler.fit(y.values.reshape(-1, 1))  # Convert y to numpy array and reshape\n",
    "\n",
    "X = PredictorScalerFit.transform(X)\n",
    "y = TargetVarScalerFit.transform(y.values.reshape(-1, 1))  # Convert y to numpy array and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26268, 7)\n",
      "(26268,)\n",
      "(11259, 7)\n",
      "(11259,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(loss='squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.fit(X_train,y_train)\n",
    "y_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.71\n",
      "MAPE: 2.60%\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "rmse_score = rmse(y_test, y_pred)\n",
    "mape_score = mape(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_score:.2f}')\n",
    "print(f\"MAPE: {mape_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': np.arange(0.1, 1.0, 0.1),\n",
    "    'n_estimators': np.arange(1, 51, 5),\n",
    "    'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "    'min_samples_split': range(2, 11),\n",
    "    'min_samples_leaf': range(1, 11),\n",
    "    'max_depth': range(1, 26)\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1012500 candidates, totalling 2025000 fits\n",
      "Best: 1.767951 using {'learning_rate': 0.9, 'max_depth': 21, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 46, 'subsample': 0.5}\n",
      "Best RMSE: 1.7679512709290626\n",
      "Best MAPE: 8.991574914950089\n",
      "Execution time: 57757.544157505035 s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=params,\n",
    "    scoring={'RMSE': rmse_scorer, 'MAPE': mape_scorer},\n",
    "    refit='RMSE', \n",
    "    cv=2,  \n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "gbr_result = grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print(\"Best RMSE:\", grid.best_score_)\n",
    "print(\"Best MAPE:\", grid.cv_results_['mean_test_MAPE'][grid.best_index_])\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.55\n",
      "MAPE: 7.52%\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid.best_estimator_\n",
    "y_pred_grid = best_grid.predict(X_test)\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test, y_pred_grid))\n",
    "mape_grid = mean_absolute_percentage_error(y_test, y_pred_grid)\n",
    "print(f\"RMSE: {rmse_grid:.2f}\")\n",
    "print(f\"MAPE: {mape_grid:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "pd.DataFrame(grid.cv_results_).to_excel('GBR_GS_Scal_CO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1.341086 using {'subsample': 0.5, 'n_estimators': 21, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 17, 'learning_rate': 0.9}\n",
      "Best RMSE: 1.341086498799206\n",
      "Best MAPE: 7.862634786910357\n",
      "Execution time: 22.67489457130432 s\n"
     ]
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(\n",
    "    gbr,\n",
    "    params,\n",
    "    scoring={'RMSE': rmse_scorer, 'MAPE': mape_scorer},\n",
    "    refit='RMSE',\n",
    "    n_iter=100,\n",
    "    cv=5,  \n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "rs_result = rs.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (rs.best_score_, rs.best_params_))\n",
    "print(\"Best RMSE:\", rs.best_score_)\n",
    "print(\"Best MAPE:\", rs.cv_results_['mean_test_MAPE'][rs.best_index_])\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.26\n",
      "MAPE: 6.46%\n"
     ]
    }
   ],
   "source": [
    "best_rs = rs.best_estimator_\n",
    "y_pred_rs = best_rs.predict(X_test)\n",
    "rmse_rs = np.sqrt(mean_squared_error(y_test, y_pred_rs))\n",
    "mape_rs = mean_absolute_percentage_error(y_test, y_pred_rs)\n",
    "print(f\"RMSE: {rmse_rs:.2f}\")\n",
    "print(f\"MAPE: {mape_rs:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.22059975, 1.35688024, 0.08530703, 0.7355041 , 0.69095707,\n",
       "        0.41489954, 0.59229469, 0.02838101, 0.48672924, 0.23743181,\n",
       "        0.09823618, 1.57034836, 0.49887667, 0.5560122 , 0.66408219,\n",
       "        0.1166965 , 1.00716581, 1.83244252, 0.1890099 , 0.03142285,\n",
       "        1.2152142 , 0.67746277, 0.09347868, 1.0252027 , 2.74413347,\n",
       "        1.31388688, 1.85813851, 0.63392444, 0.28931203, 0.47188249,\n",
       "        0.44964509, 0.02450924, 0.16954198, 1.10412402, 0.72450314,\n",
       "        2.58812013, 0.02704468, 0.27580423, 2.04149904, 0.50009532,\n",
       "        0.05108943, 0.72181859, 0.24067554, 0.39256716, 1.12085624,\n",
       "        0.47823477, 2.06093135, 1.14173951, 0.21937737, 0.3265224 ,\n",
       "        1.79640021, 0.132164  , 1.26656561, 2.5407186 , 0.86998072,\n",
       "        0.29108162, 2.48081117, 1.56511159, 0.49352694, 2.27887554,\n",
       "        0.72312775, 0.93266926, 2.37073336, 0.32058873, 1.71319571,\n",
       "        0.0503366 , 2.26981168, 1.34477639, 1.30005727, 0.50267215,\n",
       "        0.26098971, 1.06882153, 0.22651606, 0.78597422, 0.21558199,\n",
       "        1.26548634, 0.88222132, 0.17994614, 0.42580233, 1.82564058,\n",
       "        2.51826444, 0.68081493, 0.90461779, 1.19490347, 0.49192042,\n",
       "        1.15358062, 0.11774797, 0.00881934, 1.35502687, 0.24847527,\n",
       "        0.28850427, 0.01479807, 1.41306849, 0.965241  , 0.02482991,\n",
       "        0.04354401, 0.10579791, 2.02481766, 0.28455982, 0.41040735]),\n",
       " 'std_fit_time': array([0.01897507, 0.11860166, 0.00768559, 0.08579138, 0.08556435,\n",
       "        0.03469077, 0.06202672, 0.00497643, 0.00502998, 0.02008845,\n",
       "        0.00096603, 0.03977004, 0.04573118, 0.01461733, 0.07598908,\n",
       "        0.01208068, 0.0966747 , 0.01685775, 0.01254579, 0.00347293,\n",
       "        0.10344191, 0.07344696, 0.00980749, 0.09553809, 0.24503428,\n",
       "        0.13451517, 0.07284634, 0.0282584 , 0.02428466, 0.0410832 ,\n",
       "        0.03880924, 0.00349137, 0.0197185 , 0.05827511, 0.02108872,\n",
       "        0.36276852, 0.00663072, 0.0319262 , 0.24254941, 0.05116971,\n",
       "        0.00820262, 0.08186594, 0.02191647, 0.04153172, 0.07931955,\n",
       "        0.04122426, 0.21552522, 0.1035219 , 0.01697308, 0.0178428 ,\n",
       "        0.10847811, 0.0096345 , 0.06999766, 0.16825832, 0.09154787,\n",
       "        0.04536016, 0.22783815, 0.16691446, 0.05604838, 0.20013259,\n",
       "        0.10050861, 0.03756985, 0.36233503, 0.0445625 , 0.25721297,\n",
       "        0.0121893 , 0.09454051, 0.12851738, 0.02245841, 0.00743205,\n",
       "        0.02680866, 0.07960251, 0.01988392, 0.05281497, 0.02190188,\n",
       "        0.05361226, 0.08724475, 0.01715564, 0.0619232 , 0.19727727,\n",
       "        0.10718239, 0.05699178, 0.04047351, 0.15303057, 0.01019169,\n",
       "        0.08078643, 0.01220058, 0.00754831, 0.10097344, 0.02771894,\n",
       "        0.03833677, 0.00549594, 0.02963148, 0.094542  , 0.00971602,\n",
       "        0.00650488, 0.00726787, 0.04882291, 0.01285226, 0.01140791]),\n",
       " 'mean_score_time': array([0.00124412, 0.01256776, 0.00274487, 0.0123033 , 0.01554809,\n",
       "        0.00610194, 0.00674229, 0.00016441, 0.00618811, 0.00351033,\n",
       "        0.00236588, 0.01887121, 0.00843163, 0.0078228 , 0.01146927,\n",
       "        0.00094404, 0.01049166, 0.02627506, 0.00196285, 0.00234408,\n",
       "        0.01888494, 0.00248289, 0.        , 0.01322055, 0.03130908,\n",
       "        0.02051425, 0.02420402, 0.01133494, 0.008711  , 0.00449843,\n",
       "        0.00738435, 0.        , 0.00055184, 0.0073204 , 0.00844984,\n",
       "        0.03086143, 0.00020008, 0.00513239, 0.0215323 , 0.01555839,\n",
       "        0.00131307, 0.01928449, 0.00636072, 0.00471897, 0.01286864,\n",
       "        0.00961938, 0.02118249, 0.02218075, 0.00778842, 0.01011901,\n",
       "        0.02189074, 0.00025368, 0.0223516 , 0.02684059, 0.01582518,\n",
       "        0.00509562, 0.03020954, 0.01545496, 0.00153913, 0.03380547,\n",
       "        0.01157966, 0.01310916, 0.03134937, 0.00150805, 0.02565093,\n",
       "        0.00082841, 0.03228726, 0.00684013, 0.01744485, 0.00715089,\n",
       "        0.0046216 , 0.01650624, 0.00554204, 0.00967484, 0.00190153,\n",
       "        0.01550622, 0.01351972, 0.00299506, 0.00212388, 0.02936115,\n",
       "        0.02139449, 0.01226001, 0.01161995, 0.01234236, 0.00595441,\n",
       "        0.012114  , 0.00381556, 0.00310125, 0.00997419, 0.00302663,\n",
       "        0.00454383, 0.00080013, 0.01821656, 0.01367841, 0.        ,\n",
       "        0.00100718, 0.00383692, 0.01776557, 0.00294404, 0.00432639]),\n",
       " 'std_score_time': array([0.00101736, 0.00201621, 0.00427103, 0.00442003, 0.00616555,\n",
       "        0.00126829, 0.00282124, 0.00032883, 0.00502147, 0.00340711,\n",
       "        0.00304733, 0.00515791, 0.0022249 , 0.00535886, 0.00447076,\n",
       "        0.00136487, 0.00563234, 0.00293355, 0.0039257 , 0.00256678,\n",
       "        0.00279935, 0.002833  , 0.        , 0.00813658, 0.00619069,\n",
       "        0.00488154, 0.004723  , 0.00652757, 0.00508913, 0.00426083,\n",
       "        0.00690112, 0.        , 0.00110369, 0.00442348, 0.00725737,\n",
       "        0.01243027, 0.00040016, 0.00613914, 0.00459848, 0.00258048,\n",
       "        0.00119572, 0.01098599, 0.00629572, 0.00441828, 0.00775697,\n",
       "        0.00546705, 0.00323151, 0.00819654, 0.00571745, 0.00832356,\n",
       "        0.00557338, 0.00050735, 0.00792078, 0.00753877, 0.00920853,\n",
       "        0.00341324, 0.00951444, 0.00548525, 0.00167589, 0.01021245,\n",
       "        0.00658169, 0.01023122, 0.00358539, 0.00202401, 0.01392384,\n",
       "        0.00068153, 0.00473053, 0.00543357, 0.00933683, 0.00577577,\n",
       "        0.00574025, 0.01055986, 0.00650912, 0.00486259, 0.00290826,\n",
       "        0.00398144, 0.00268608, 0.00508522, 0.00175281, 0.01215084,\n",
       "        0.00404049, 0.00407233, 0.00801461, 0.00559478, 0.0061432 ,\n",
       "        0.00354324, 0.00406446, 0.00620251, 0.00412202, 0.00391043,\n",
       "        0.00426969, 0.0011663 , 0.00265371, 0.00289428, 0.        ,\n",
       "        0.00090259, 0.00503702, 0.00267956, 0.00398955, 0.00633359]),\n",
       " 'param_subsample': masked_array(data=[0.8999999999999999, 0.7999999999999999, 0.5, 0.7, 0.6,\n",
       "                    0.8999999999999999, 0.7999999999999999, 0.5, 0.5, 0.6,\n",
       "                    0.6, 0.7999999999999999, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.8999999999999999, 0.7, 0.7, 0.7999999999999999, 0.7,\n",
       "                    0.7, 0.6, 0.7999999999999999, 0.6, 0.7999999999999999,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.5, 0.7999999999999999,\n",
       "                    0.8999999999999999, 0.7, 0.8999999999999999, 0.6,\n",
       "                    0.8999999999999999, 0.8999999999999999, 0.6,\n",
       "                    0.8999999999999999, 0.8999999999999999,\n",
       "                    0.8999999999999999, 0.5, 0.5, 0.8999999999999999, 0.7,\n",
       "                    0.5, 0.6, 0.8999999999999999, 0.7999999999999999, 0.7,\n",
       "                    0.5, 0.7, 0.7, 0.7, 0.6, 0.6, 0.7999999999999999, 0.7,\n",
       "                    0.6, 0.5, 0.6, 0.8999999999999999, 0.7, 0.7,\n",
       "                    0.7999999999999999, 0.8999999999999999,\n",
       "                    0.7999999999999999, 0.7999999999999999,\n",
       "                    0.7999999999999999, 0.7999999999999999,\n",
       "                    0.8999999999999999, 0.7, 0.6, 0.8999999999999999, 0.6,\n",
       "                    0.5, 0.8999999999999999, 0.6, 0.8999999999999999, 0.6,\n",
       "                    0.7999999999999999, 0.5, 0.8999999999999999,\n",
       "                    0.8999999999999999, 0.5, 0.5, 0.8999999999999999, 0.5,\n",
       "                    0.7, 0.5, 0.5, 0.5, 0.7999999999999999, 0.6,\n",
       "                    0.8999999999999999, 0.8999999999999999,\n",
       "                    0.8999999999999999, 0.6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[11, 46, 6, 16, 16, 11, 16, 1, 21, 21, 6, 36, 11, 41,\n",
       "                    26, 21, 31, 31, 6, 1, 31, 21, 6, 41, 46, 36, 36, 16,\n",
       "                    11, 11, 16, 1, 31, 31, 31, 41, 1, 6, 41, 16, 1, 16, 6,\n",
       "                    11, 36, 11, 46, 46, 6, 11, 26, 6, 26, 46, 16, 6, 46,\n",
       "                    26, 41, 31, 36, 46, 46, 11, 26, 1, 31, 31, 21, 11, 6,\n",
       "                    16, 11, 16, 16, 21, 16, 26, 36, 31, 36, 16, 16, 31, 16,\n",
       "                    16, 6, 1, 41, 6, 6, 1, 31, 21, 1, 1, 6, 46, 6, 21],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[9, 3, 10, 10, 2, 6, 6, 8, 6, 3, 4, 9, 10, 9, 5, 3, 10,\n",
       "                    5, 5, 8, 8, 10, 4, 4, 10, 2, 8, 10, 4, 2, 9, 10, 4, 8,\n",
       "                    9, 2, 7, 3, 7, 5, 9, 6, 9, 7, 9, 3, 9, 10, 7, 10, 8, 5,\n",
       "                    7, 10, 4, 3, 2, 7, 5, 4, 2, 2, 9, 4, 5, 8, 4, 2, 4, 6,\n",
       "                    10, 5, 6, 8, 7, 8, 8, 8, 5, 7, 8, 3, 7, 2, 5, 6, 5, 4,\n",
       "                    3, 9, 7, 3, 7, 4, 3, 7, 4, 5, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[7, 4, 10, 5, 1, 7, 6, 4, 4, 6, 4, 6, 1, 5, 7, 1, 8, 1,\n",
       "                    8, 3, 6, 4, 1, 5, 3, 4, 1, 9, 5, 4, 4, 7, 6, 4, 1, 7,\n",
       "                    2, 2, 1, 5, 6, 1, 9, 6, 6, 3, 1, 9, 10, 4, 5, 2, 3, 7,\n",
       "                    3, 6, 4, 3, 8, 2, 1, 7, 1, 1, 2, 10, 4, 8, 6, 4, 1, 7,\n",
       "                    3, 8, 1, 10, 3, 6, 5, 6, 10, 5, 7, 3, 2, 7, 9, 3, 1, 4,\n",
       "                    10, 6, 8, 1, 1, 4, 7, 3, 9, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 11, 6, 23, 21, 16, 14, 19, 13, 4, 7, 20, 20, 5, 10,\n",
       "                    1, 13, 25, 12, 16, 20, 12, 5, 11, 25, 18, 22, 22, 12,\n",
       "                    22, 13, 20, 1, 11, 10, 22, 14, 16, 17, 24, 18, 16, 22,\n",
       "                    25, 17, 17, 15, 10, 14, 7, 25, 5, 22, 19, 17, 23, 21,\n",
       "                    24, 2, 23, 6, 6, 19, 6, 21, 25, 20, 10, 22, 16, 12, 22,\n",
       "                    4, 17, 3, 25, 20, 1, 2, 25, 22, 16, 19, 14, 8, 22, 7,\n",
       "                    2, 8, 18, 15, 5, 23, 17, 5, 15, 4, 18, 18, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.4, 0.9, 0.1, 0.7000000000000001, 0.1,\n",
       "                    0.30000000000000004, 0.4, 0.7000000000000001, 0.4, 0.6,\n",
       "                    0.7000000000000001, 0.2, 0.9, 0.2, 0.1, 0.8, 0.5,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.5, 0.1, 0.5,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6, 0.30000000000000004, 0.7000000000000001, 0.6,\n",
       "                    0.30000000000000004, 0.9, 0.6, 0.7000000000000001, 0.8,\n",
       "                    0.8, 0.6, 0.5, 0.2, 0.1, 0.6, 0.2, 0.4, 0.6,\n",
       "                    0.7000000000000001, 0.1, 0.6, 0.1, 0.5, 0.5,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.6,\n",
       "                    0.30000000000000004, 0.9, 0.1, 0.2, 0.2, 0.9, 0.8, 0.6,\n",
       "                    0.4, 0.6, 0.2, 0.6, 0.1, 0.7000000000000001, 0.8,\n",
       "                    0.7000000000000001, 0.1, 0.7000000000000001, 0.5,\n",
       "                    0.7000000000000001, 0.30000000000000004, 0.8, 0.2, 0.5,\n",
       "                    0.30000000000000004, 0.4, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.2, 0.8, 0.4, 0.4, 0.6, 0.2,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.4, 0.9, 0.8,\n",
       "                    0.8, 0.9, 0.8, 0.2, 0.1, 0.8, 0.1, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 21,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 13,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 11,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 24,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 21,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 24,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 21,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 26,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 1,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 25,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 36,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'max_depth': 16,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 19,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 14,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 22,\n",
       "   'learning_rate': 0.6},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 2,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 41,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.4},\n",
       "  {'subsample': 0.7,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 31,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 23,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 17,\n",
       "   'learning_rate': 0.9},\n",
       "  {'subsample': 0.7999999999999999,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 1,\n",
       "   'min_samples_split': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.2},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 46,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.8},\n",
       "  {'subsample': 0.8999999999999999,\n",
       "   'n_estimators': 6,\n",
       "   'min_samples_split': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'max_depth': 18,\n",
       "   'learning_rate': 0.1},\n",
       "  {'subsample': 0.6,\n",
       "   'n_estimators': 21,\n",
       "   'min_samples_split': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.8}],\n",
       " 'split0_test_RMSE': array([0.70328494, 0.79224674, 0.94758247, 0.79644354, 0.7137684 ,\n",
       "        0.6998474 , 0.70962503, 0.8275383 , 0.75637719, 0.72473863,\n",
       "        0.76150699, 0.70949743, 0.89626494, 0.7011463 , 0.71284669,\n",
       "        1.07864836, 0.71811704, 0.76888365, 0.73377559, 0.94827863,\n",
       "        0.70374918, 0.7457334 , 0.71602572, 0.7200313 , 0.76533028,\n",
       "        0.81449204, 0.77358541, 0.76784107, 0.76967836, 0.76836774,\n",
       "        0.72044079, 0.83872536, 1.07405822, 0.77921882, 0.88329719,\n",
       "        0.79793863, 0.78042749, 0.70206357, 0.72475468, 0.7590378 ,\n",
       "        0.85733234, 0.70747312, 0.72007291, 0.80716627, 0.81696734,\n",
       "        0.7680624 , 0.79543752, 0.71789979, 0.70887525, 0.69491795,\n",
       "        0.75005755, 0.72872784, 0.84924167, 0.71418271, 0.84653223,\n",
       "        0.90244729, 0.73781436, 0.72430221, 0.77674549, 0.86089283,\n",
       "        0.79842642, 0.7322052 , 0.88915004, 0.70059107, 0.82482414,\n",
       "        1.09744605, 0.79935435, 0.73788721, 0.77661516, 0.79507267,\n",
       "        0.72565901, 0.74300159, 0.71942802, 0.70552746, 0.75829724,\n",
       "        0.70788143, 0.78140682, 1.09099051, 0.77460195, 0.72299492,\n",
       "        0.71508022, 0.74144304, 0.76247837, 0.77274978, 0.68784414,\n",
       "        0.73991719, 0.80877776, 1.06818977, 0.71015188, 0.76766305,\n",
       "        0.74592512, 0.84523239, 0.79641477, 1.17227565, 0.77774744,\n",
       "        1.03798849, 0.9324854 , 0.79741448, 0.90892714, 0.75302652]),\n",
       " 'split1_test_RMSE': array([0.64659211, 0.88468073, 0.66569875, 0.82155488, 0.63777299,\n",
       "        0.67542813, 0.72741404, 0.73880132, 0.72985509, 0.65410974,\n",
       "        0.6847874 , 0.71244815, 1.06270019, 0.65846224, 0.63027168,\n",
       "        0.81273968, 0.76112595, 0.89579997, 0.73801243, 0.75472548,\n",
       "        0.6601122 , 0.73571036, 0.6123937 , 0.74822899, 0.76830334,\n",
       "        0.85521431, 0.89481045, 0.67108435, 0.7133631 , 0.83790739,\n",
       "        0.69292802, 0.65834728, 0.80293682, 0.80238204, 0.90746305,\n",
       "        0.84780776, 0.70938256, 0.75707882, 0.81442548, 0.62385602,\n",
       "        0.68957998, 0.7730126 , 0.64726824, 0.77714891, 0.82984552,\n",
       "        0.64609093, 0.95823035, 0.65463947, 0.6858712 , 0.65371697,\n",
       "        0.71377543, 0.63421351, 0.85583854, 0.71702976, 1.02868985,\n",
       "        0.69312512, 0.71230413, 0.70447836, 0.70645182, 0.92459399,\n",
       "        0.84285352, 0.69886157, 0.89522698, 0.62745944, 0.87177853,\n",
       "        0.83576039, 0.84337064, 0.79665386, 0.79648675, 0.63303608,\n",
       "        0.7648157 , 0.7286938 , 0.6420397 , 0.65379933, 0.65872548,\n",
       "        0.66965833, 0.72724234, 0.81950308, 0.66396394, 0.71669285,\n",
       "        0.69486939, 0.6948672 , 0.84311475, 0.77153816, 0.67978961,\n",
       "        0.73685919, 0.63001864, 0.80524554, 0.80886941, 0.72039788,\n",
       "        0.71727421, 0.65101221, 0.82748033, 1.46066451, 0.66488994,\n",
       "        0.79375233, 0.72183648, 0.8985593 , 0.68399888, 0.72365843]),\n",
       " 'split2_test_RMSE': array([0.60863966, 0.77704874, 0.75622179, 0.720221  , 0.6798256 ,\n",
       "        0.61729706, 0.63146006, 0.68044232, 0.68605204, 0.62175443,\n",
       "        0.6612985 , 0.64782785, 0.94082675, 0.58793506, 0.61539473,\n",
       "        0.90963586, 0.68881502, 0.84626436, 0.62796905, 0.74925112,\n",
       "        0.62104852, 0.6527101 , 0.63052955, 0.69284474, 0.72555499,\n",
       "        0.70778596, 0.84818826, 0.62426268, 0.67085402, 0.68757793,\n",
       "        0.65120505, 0.67634475, 0.89803223, 0.71779452, 0.80382085,\n",
       "        0.73856488, 0.78878957, 0.70341984, 0.74116237, 0.63558479,\n",
       "        0.71435335, 0.73338142, 0.63325227, 0.67455925, 0.74898847,\n",
       "        0.7058207 , 0.77218451, 0.62913346, 0.62484146, 0.60335283,\n",
       "        0.65411217, 0.61977208, 0.78521565, 0.67019586, 0.7662338 ,\n",
       "        0.74267379, 0.65785767, 0.63372863, 0.66667658, 0.85274879,\n",
       "        0.76503631, 0.63682684, 0.88602151, 0.60920485, 0.74565302,\n",
       "        0.92054032, 0.79866027, 0.68535917, 0.74295875, 0.68406065,\n",
       "        0.72521916, 0.67669292, 0.65387079, 0.6095573 , 0.60670439,\n",
       "        0.62192585, 0.75774848, 0.9154403 , 0.65393573, 0.65475242,\n",
       "        0.64758691, 0.63124916, 0.72160281, 0.72869859, 0.63445019,\n",
       "        0.66773135, 0.66623007, 0.86756661, 0.77441243, 0.63003548,\n",
       "        0.68975614, 0.65179463, 0.77826167, 1.31118245, 0.62762339,\n",
       "        0.87203404, 0.7741231 , 0.78011757, 0.74941701, 0.6721727 ]),\n",
       " 'split3_test_RMSE': array([0.85787564, 0.94595553, 0.86614835, 0.96378744, 0.85222011,\n",
       "        0.86319629, 0.88735156, 0.87105067, 0.84804703, 0.84385704,\n",
       "        0.88651802, 0.88076139, 1.13849896, 0.85409363, 0.82790433,\n",
       "        1.01621557, 0.8637565 , 0.98881365, 0.90002941, 0.85602913,\n",
       "        0.84274564, 0.91964744, 0.83182246, 0.88352611, 0.97449275,\n",
       "        0.93405995, 1.01755994, 0.83788597, 0.91843385, 0.91006875,\n",
       "        0.86487758, 0.83398104, 1.01525616, 0.94538655, 1.08999545,\n",
       "        0.96355258, 0.84015218, 0.95443875, 0.95034857, 0.80396887,\n",
       "        0.85799565, 0.92975587, 0.8562746 , 0.87963739, 0.96826778,\n",
       "        0.84210024, 0.94269875, 0.80471376, 0.83842705, 0.84237275,\n",
       "        0.88902736, 0.83115686, 0.97137004, 0.8814998 , 1.09596874,\n",
       "        0.84810009, 0.88992781, 0.85311868, 0.84749144, 1.0849249 ,\n",
       "        0.9937102 , 0.88424621, 1.04995317, 0.82844804, 1.00501011,\n",
       "        1.04073149, 0.92641996, 0.89991053, 0.96041554, 0.81807368,\n",
       "        0.96442172, 0.8746581 , 0.85637462, 0.83977449, 0.865924  ,\n",
       "        0.86004697, 0.92988545, 1.03052908, 0.86968577, 0.88475921,\n",
       "        0.8677289 , 0.84193515, 0.92282966, 0.95031742, 0.92465086,\n",
       "        0.910808  , 0.7949739 , 1.01846141, 0.98270598, 0.83306771,\n",
       "        0.85684169, 0.83957621, 0.94015198, 1.41361431, 0.88811522,\n",
       "        0.98944859, 0.88627559, 1.00142564, 0.86753098, 0.89495368]),\n",
       " 'split4_test_RMSE': array([0.61993502, 0.75445136, 0.67714407, 0.73083897, 0.60564292,\n",
       "        0.63676165, 0.64280364, 0.63311602, 0.65219964, 0.67724434,\n",
       "        0.64710247, 0.64085775, 0.77813497, 0.63010735, 0.58830784,\n",
       "        0.79944333, 0.67044131, 0.75199812, 0.61707147, 0.69332515,\n",
       "        0.60916677, 0.67447882, 0.59060942, 0.61414524, 0.7108194 ,\n",
       "        0.70392226, 0.73913754, 0.63829522, 0.7233996 , 0.74987131,\n",
       "        0.62972328, 0.73041277, 0.79593576, 0.71497356, 0.87988663,\n",
       "        0.77542287, 0.69715554, 0.69987656, 0.70121045, 0.59957742,\n",
       "        0.66438082, 0.65510202, 0.60256822, 0.67498307, 0.76520802,\n",
       "        0.62759144, 0.79829787, 0.58012225, 0.61928315, 0.64169084,\n",
       "        0.64395579, 0.59399721, 0.74587466, 0.66190827, 0.85088081,\n",
       "        0.66764198, 0.64594824, 0.64879255, 0.63542404, 0.78912915,\n",
       "        0.79913209, 0.64594999, 0.82205771, 0.60642459, 0.74076243,\n",
       "        0.82592332, 0.74196499, 0.70428785, 0.76794535, 0.61867688,\n",
       "        0.69325138, 0.65836628, 0.63228571, 0.59632481, 0.63365145,\n",
       "        0.59681209, 0.68700494, 0.81141191, 0.60742494, 0.64215579,\n",
       "        0.62485527, 0.5941325 , 0.72053584, 0.66021144, 0.71267301,\n",
       "        0.64874494, 0.61750425, 0.77563301, 0.73698262, 0.6165362 ,\n",
       "        0.67021332, 0.61355081, 0.82169794, 1.34769557, 0.63482541,\n",
       "        0.77667955, 0.69000391, 0.76901104, 0.66801113, 0.73054925]),\n",
       " 'mean_test_RMSE': array([0.68726547, 0.83087662, 0.78255909, 0.80656917, 0.69784601,\n",
       "        0.69850611, 0.71973086, 0.75018973, 0.7345062 , 0.70434084,\n",
       "        0.72824268, 0.71827852, 0.96328516, 0.68634892, 0.67494506,\n",
       "        0.92333656, 0.74045116, 0.85035195, 0.72337159, 0.8003219 ,\n",
       "        0.68736446, 0.74565602, 0.67627617, 0.73175528, 0.78890015,\n",
       "        0.80309491, 0.85465632, 0.70787386, 0.75914579, 0.79075862,\n",
       "        0.71183494, 0.74756224, 0.91724384, 0.7919511 , 0.91289263,\n",
       "        0.82465734, 0.76318147, 0.76337551, 0.78638031, 0.68440498,\n",
       "        0.75672843, 0.75974501, 0.69188725, 0.76269898, 0.82585543,\n",
       "        0.71793314, 0.8533698 , 0.67730174, 0.69545962, 0.68721027,\n",
       "        0.73018566, 0.6815735 , 0.84150811, 0.72896328, 0.91766109,\n",
       "        0.77079765, 0.72877044, 0.71288409, 0.72655787, 0.90245793,\n",
       "        0.83983171, 0.71961796, 0.90848188, 0.6744256 , 0.83760564,\n",
       "        0.94408031, 0.82195404, 0.76481972, 0.80888431, 0.70978399,\n",
       "        0.77467339, 0.73628254, 0.70079977, 0.68099668, 0.70466051,\n",
       "        0.69126494, 0.77665761, 0.93357498, 0.71392247, 0.72427104,\n",
       "        0.71002414, 0.70072541, 0.79411229, 0.77670308, 0.72788156,\n",
       "        0.74081213, 0.70350092, 0.90701927, 0.80262446, 0.71354007,\n",
       "        0.7360021 , 0.72023325, 0.83280134, 1.3410865 , 0.71864028,\n",
       "        0.8939806 , 0.8009449 , 0.84930561, 0.77557703, 0.75487211]),\n",
       " 'std_test_RMSE': array([0.09136102, 0.07262034, 0.10925401, 0.08744799, 0.08546321,\n",
       "        0.08725197, 0.09161593, 0.08864628, 0.06710241, 0.07740638,\n",
       "        0.08844345, 0.0865668 , 0.1263803 , 0.09163331, 0.08704141,\n",
       "        0.11001561, 0.06884495, 0.08667691, 0.10191363, 0.09069736,\n",
       "        0.08445962, 0.09389044, 0.08864219, 0.0880788 , 0.09542913,\n",
       "        0.08822378, 0.09809063, 0.08207887, 0.08561881, 0.07652097,\n",
       "        0.08279117, 0.07629452, 0.11166736, 0.0839501 , 0.09513867,\n",
       "        0.07794571, 0.05316284, 0.0979089 , 0.09029774, 0.08137676,\n",
       "        0.08391524, 0.09322796, 0.09080137, 0.07914976, 0.07741167,\n",
       "        0.07924651, 0.07994437, 0.07766549, 0.07937428, 0.08289836,\n",
       "        0.08845071, 0.0875565 , 0.07673837, 0.07947106, 0.12374987,\n",
       "        0.09030212, 0.0874217 , 0.07776899, 0.07673216, 0.10082288,\n",
       "        0.08081204, 0.0894126 , 0.07554753, 0.08425111, 0.09714865,\n",
       "        0.10872986, 0.06135697, 0.07741626, 0.07769027, 0.08228396,\n",
       "        0.09754925, 0.07599   , 0.08354615, 0.08811897, 0.09553065,\n",
       "        0.09269259, 0.08287141, 0.11175404, 0.09526824, 0.08647689,\n",
       "        0.08518   , 0.08697291, 0.07828311, 0.0959781 , 0.10158219,\n",
       "        0.09244695, 0.08201793, 0.11625148, 0.09604613, 0.08203164,\n",
       "        0.06560222, 0.10072146, 0.05652312, 0.09898911, 0.10041267,\n",
       "        0.10405701, 0.09366929, 0.08887443, 0.09682883, 0.07487502]),\n",
       " 'rank_test_RMSE': array([ 91,  21,  36,  26,  86,  85,  68,  50,  57,  81,  62,  71,   2,\n",
       "         93,  99,   5,  54,  15,  66,  30,  90,  52,  98,  58,  34,  27,\n",
       "         13,  79,  47,  33,  76,  51,   7,  32,   8,  23,  44,  43,  35,\n",
       "         94,  48,  46,  88,  45,  22,  72,  14,  97,  87,  92,  59,  95,\n",
       "         17,  60,   6,  41,  61,  75,  64,  11,  18,  69,   9, 100,  19,\n",
       "          3,  24,  42,  25,  78,  40,  55,  83,  96,  80,  89,  38,   4,\n",
       "         73,  65,  77,  84,  31,  37,  63,  53,  82,  10,  28,  74,  56,\n",
       "         67,  20,   1,  70,  12,  29,  16,  39,  49]),\n",
       " 'split0_test_MAPE': array([3.03509534, 7.30384255, 1.89210653, 4.4545431 , 4.10585594,\n",
       "        4.32670673, 5.22155323, 2.74306191, 5.47728112, 4.10568135,\n",
       "        4.39769303, 4.78658255, 6.31674859, 3.88770664, 3.46931614,\n",
       "        7.80211075, 5.05985454, 2.85428846, 5.22472506, 2.53123874,\n",
       "        4.57948256, 4.47937297, 3.21191806, 3.88514063, 6.12043591,\n",
       "        7.44402509, 3.40382767, 4.61599906, 5.86136457, 5.15160326,\n",
       "        5.04883959, 3.48019592, 7.61594975, 4.19961476, 6.80331203,\n",
       "        5.61740161, 2.47596031, 4.18270333, 4.7642236 , 3.69654239,\n",
       "        2.89778413, 4.2380285 , 4.72505298, 6.06046636, 4.28166127,\n",
       "        3.10146634, 5.76563509, 3.77540259, 5.57182764, 3.58677779,\n",
       "        4.88367226, 4.86343993, 7.49183082, 5.80257979, 7.13768845,\n",
       "        2.35164451, 5.46633187, 5.34566345, 3.73449301, 6.14335465,\n",
       "        2.90955103, 3.88439551, 5.03080565, 2.9236109 , 4.72426963,\n",
       "        1.09197335, 4.53883961, 6.20929156, 3.90352641, 3.00232566,\n",
       "        4.58114777, 5.49409542, 5.27297289, 4.78489788, 3.14561476,\n",
       "        5.23194009, 6.32459781, 4.85986525, 2.54404186, 6.40086476,\n",
       "        5.52073846, 4.82620682, 4.02998177, 5.11181872, 3.77584781,\n",
       "        5.93862081, 2.12394716, 4.69808418, 5.69919725, 5.05464145,\n",
       "        3.02724813, 5.95529586, 8.93052193, 8.91763039, 5.46613226,\n",
       "        1.26670183, 3.34584521, 6.43520498, 2.44259671, 3.40209833]),\n",
       " 'split1_test_MAPE': array([ 3.32072097,  5.07298683,  1.5628567 ,  3.58450156,  2.06730591,\n",
       "         3.10419916,  3.37011119,  1.51350989,  4.15859846,  3.03112695,\n",
       "         2.35838599,  4.07561881,  5.23761436,  2.77303451,  2.75845387,\n",
       "         3.31221632,  3.8400677 ,  7.5549622 ,  3.45053088,  1.42285886,\n",
       "         3.15779698,  3.05831605,  2.9464607 ,  3.45657664,  4.93988571,\n",
       "         4.96862921,  6.17168495,  3.24197401,  4.32204134,  3.54694435,\n",
       "         3.06585828,  2.4883504 ,  3.21248033,  4.10019661,  4.41032424,\n",
       "         5.78143951,  3.55024367,  3.4325197 ,  5.21877958,  2.57528143,\n",
       "         1.56499148,  3.73875893,  2.84679409,  4.89622937,  4.63020054,\n",
       "         2.70861234,  7.13973638,  2.6732706 ,  3.43966167,  4.26187198,\n",
       "         4.01067169,  2.32852103,  4.53778222,  3.85567401,  6.69855502,\n",
       "         1.99354757,  3.16349061,  3.80232938,  2.43137241,  7.1396869 ,\n",
       "         3.92274948,  3.15765048,  4.62558863,  2.77269587,  5.90423447,\n",
       "         1.02688348,  4.93020292,  4.32463219,  5.24105847,  2.41312073,\n",
       "         3.3239297 ,  3.78349739,  2.84816576,  3.07479808,  2.49997088,\n",
       "         3.22534947,  3.99508201,  2.6354228 ,  2.4042058 ,  4.54595482,\n",
       "         3.62691447,  3.26649841,  3.98727983,  4.8379248 ,  3.80813419,\n",
       "         5.44533492,  2.0331651 ,  1.97349969,  3.48617037,  3.60472188,\n",
       "         4.96087732,  2.1238943 ,  5.38945564, 11.50778858,  2.84730706,\n",
       "         1.36716572,  1.56008966,  4.66623794,  1.80861561,  3.35298356]),\n",
       " 'split2_test_MAPE': array([2.178299  , 4.04567184, 1.3788912 , 3.51559034, 2.30047004,\n",
       "        2.68805221, 2.70383619, 1.73573594, 2.81295567, 2.07012191,\n",
       "        2.43487707, 2.93605168, 3.50686515, 2.1462888 , 2.15891088,\n",
       "        3.41329134, 3.17572243, 3.04160024, 2.27092968, 1.68666588,\n",
       "        2.55150956, 2.62714022, 1.83262811, 2.98577435, 3.75010131,\n",
       "        3.57877944, 3.4980655 , 2.69589201, 3.14094706, 4.1650506 ,\n",
       "        2.43511737, 2.38049441, 3.69411106, 3.44995281, 3.6418671 ,\n",
       "        3.66323646, 1.84457437, 2.83571693, 2.82622934, 2.22875028,\n",
       "        1.66514537, 2.63997162, 2.41168729, 2.89402231, 4.66897102,\n",
       "        1.66895835, 3.96845753, 2.12319511, 2.30010077, 2.19357148,\n",
       "        3.12092194, 1.84753938, 4.03790473, 3.15798272, 3.96400086,\n",
       "        1.51418197, 3.16732647, 2.84805288, 3.57776244, 4.33109121,\n",
       "        3.11718386, 3.03395287, 4.68381323, 1.90474433, 4.01084518,\n",
       "        1.06730733, 4.2798485 , 3.54165563, 3.56389612, 1.83371861,\n",
       "        2.2981493 , 3.39664441, 2.27787309, 2.61744673, 2.39360623,\n",
       "        2.66641348, 3.62630705, 3.19424359, 1.98812585, 3.19624745,\n",
       "        3.15435705, 2.34305509, 3.85392009, 3.46579609, 2.14458085,\n",
       "        3.68347084, 1.68347953, 1.66587102, 2.50257168, 2.4089505 ,\n",
       "        3.29474385, 1.85356024, 4.68239575, 7.3890379 , 1.81849791,\n",
       "        1.32079675, 1.34829795, 3.69546514, 1.43229952, 3.30158041]),\n",
       " 'split3_test_MAPE': array([2.09214754, 3.29307525, 1.54071272, 2.70817691, 1.81366571,\n",
       "        2.4881512 , 2.10063347, 1.62602347, 2.66890531, 2.25829075,\n",
       "        2.12323372, 2.17224567, 3.95665635, 2.25379511, 1.62995202,\n",
       "        3.88479988, 2.82244461, 2.50926426, 2.47359118, 1.27900057,\n",
       "        1.8534161 , 2.29397246, 1.95268559, 2.70437869, 2.66119708,\n",
       "        3.53882065, 3.37572645, 2.40663082, 2.83261334, 3.2043614 ,\n",
       "        2.11545613, 2.04477951, 3.90549186, 2.30347939, 3.2944258 ,\n",
       "        3.11244149, 1.48883041, 2.16698238, 2.31779848, 1.75498493,\n",
       "        1.3738459 , 2.27585436, 1.94909194, 3.49457448, 3.58374893,\n",
       "        1.5690165 , 2.91177329, 1.90106075, 2.17225017, 2.08981212,\n",
       "        2.75445281, 1.76011883, 3.48436372, 2.3179374 , 3.19558468,\n",
       "        1.25549998, 2.66005168, 2.10057841, 3.33629335, 3.69427961,\n",
       "        2.77715248, 2.40374033, 3.37372232, 2.12664908, 3.18069163,\n",
       "        1.01275302, 3.10717683, 2.95064416, 3.00492518, 1.54257651,\n",
       "        2.13666075, 2.70694835, 2.88207786, 2.06512263, 3.95699766,\n",
       "        2.09905528, 2.6413163 , 2.82461045, 2.75023293, 2.91628516,\n",
       "        2.38988582, 2.05269561, 3.02042375, 2.71117175, 2.72917239,\n",
       "        2.64661533, 1.82662683, 2.11908098, 2.50666627, 2.12088369,\n",
       "        2.96465056, 2.16070864, 3.84878773, 5.10795904, 2.01386829,\n",
       "        1.01328682, 1.49885684, 2.79870671, 1.21862297, 2.52844817]),\n",
       " 'split4_test_MAPE': array([3.21842854, 7.45776359, 1.86107873, 6.07974771, 3.9842101 ,\n",
       "        4.10804676, 4.58413692, 1.92947501, 4.66460804, 4.00203231,\n",
       "        4.30573521, 4.87192734, 5.81740348, 3.89400909, 3.80991348,\n",
       "        4.34012739, 5.57077153, 4.29764393, 4.95059393, 1.93548426,\n",
       "        3.71850713, 5.7781193 , 3.62132108, 4.35664406, 5.76659418,\n",
       "        6.08182265, 6.43772156, 4.43299606, 5.50638699, 5.10299609,\n",
       "        3.71598848, 3.09192118, 4.24131242, 5.51481265, 4.79924855,\n",
       "        5.91260052, 3.06050314, 5.1169995 , 4.70840334, 3.28884731,\n",
       "        2.6125876 , 4.1194417 , 3.38442483, 4.38115501, 6.02608522,\n",
       "        3.02682177, 4.97634373, 3.728441  , 4.75727885, 3.56829475,\n",
       "        5.33274378, 3.24230736, 6.82048894, 5.07252334, 5.85648689,\n",
       "        2.16310718, 4.51539173, 3.58771194, 3.71765834, 6.45797146,\n",
       "        5.44001617, 4.6934612 , 6.97094832, 3.62138552, 5.99227838,\n",
       "        1.19004867, 5.62265936, 4.10457201, 5.45216089, 2.8749464 ,\n",
       "        4.44569297, 5.71508996, 3.37143244, 4.60582281, 3.0016701 ,\n",
       "        4.47640996, 4.94817618, 3.38310129, 3.04925818, 4.67369243,\n",
       "        4.44017708, 3.31811531, 4.78781325, 6.50388665, 4.02445995,\n",
       "        5.16940859, 2.27751657, 2.40688826, 4.02438912, 3.96909816,\n",
       "        4.57155063, 2.68205981, 7.5591176 , 6.39075802, 2.84844488,\n",
       "        1.62038343, 1.86341167, 7.51597999, 2.20719985, 4.87438348]),\n",
       " 'mean_test_MAPE': array([2.76893828, 5.43466801, 1.64712918, 4.06851193, 2.85430154,\n",
       "        3.34303121, 3.5960542 , 1.90956125, 3.95646972, 3.09345065,\n",
       "        3.123985  , 3.76848521, 4.96705759, 2.99096683, 2.76530928,\n",
       "        4.55050914, 4.09377216, 4.05155182, 3.67407414, 1.77104966,\n",
       "        3.17214247, 3.6473842 , 2.71300271, 3.47770288, 4.64764284,\n",
       "        5.12241541, 4.57740523, 3.47869839, 4.33267066, 4.23419114,\n",
       "        3.27625197, 2.69714828, 4.53386908, 3.91361124, 4.58983554,\n",
       "        4.81742392, 2.48402238, 3.54698437, 3.96708687, 2.70888127,\n",
       "        2.0228709 , 3.40241102, 3.06341022, 4.34528951, 4.6381334 ,\n",
       "        2.41497506, 4.9523892 , 2.84027401, 3.64822382, 3.14006563,\n",
       "        4.0204925 , 2.80838531, 5.27447409, 4.04133945, 5.37046318,\n",
       "        1.85559624, 3.79451847, 3.53686721, 3.35951591, 5.55327677,\n",
       "        3.6333306 , 3.43464008, 4.93697563, 2.66981714, 4.76246386,\n",
       "        1.07779317, 4.49574544, 4.22615911, 4.23311342, 2.33333758,\n",
       "        3.3571161 , 4.2192551 , 3.33050441, 3.42961763, 2.99957193,\n",
       "        3.53983366, 4.30709587, 3.37944867, 2.54717292, 4.34660893,\n",
       "        3.82641458, 3.16131425, 3.93588374, 4.5261196 , 3.29643904,\n",
       "        4.5766901 , 1.98894704, 2.57268483, 3.64379894, 3.43165914,\n",
       "        3.7638141 , 2.95510377, 6.08205573, 7.86263479, 2.99885008,\n",
       "        1.31766691, 1.92330027, 5.02231896, 1.82186693, 3.49189879]),\n",
       " 'std_test_MAPE': array([0.52616455, 1.68720315, 0.19807385, 1.1475704 , 0.98509859,\n",
       "        0.74427473, 1.15775135, 0.43876771, 1.07894668, 0.84837605,\n",
       "        1.0081052 , 1.05729504, 1.07433957, 0.76472547, 0.80543475,\n",
       "        1.66655187, 1.06191311, 1.85291869, 1.22425213, 0.4416777 ,\n",
       "        0.93846158, 1.30014305, 0.70450025, 0.59649198, 1.28515563,\n",
       "        1.4983036 , 1.41342103, 0.89691583, 1.21531932, 0.79172026,\n",
       "        1.04255983, 0.5173897 , 1.57676443, 1.04766042, 1.22900666,\n",
       "        1.18387634, 0.75743299, 1.02883382, 1.16390892, 0.70286955,\n",
       "        0.61189763, 0.79698974, 0.9568153 , 1.10241056, 0.79576669,\n",
       "        0.66393318, 1.45455596, 0.78581421, 1.33937947, 0.85326022,\n",
       "        0.9878525 , 1.15446049, 1.58638877, 1.26096892, 1.53826947,\n",
       "        0.40898329, 1.03857587, 1.08463726, 0.48548842, 1.3139992 ,\n",
       "        0.98703408, 0.7857402 , 1.16195206, 0.61005666, 1.08484807,\n",
       "        0.06282411, 0.82888837, 1.10025253, 0.95571499, 0.56959155,\n",
       "        1.02910412, 1.1845999 , 1.03117685, 1.08329204, 0.55763655,\n",
       "        1.15568203, 1.25035561, 0.78579482, 0.35392259, 1.24385265,\n",
       "        1.07726638, 0.97016503, 0.56250599, 1.32439799, 0.73078696,\n",
       "        1.22341682, 0.21123962, 1.08921086, 1.18235597, 1.06929212,\n",
       "        0.83505896, 1.52388166, 1.88264178, 2.20812661, 1.30357115,\n",
       "        0.194598  , 0.73074244, 1.7347264 , 0.45817651, 0.76198211]),\n",
       " 'rank_test_MAPE': array([ 80,   4,  98,  32,  77,  63,  49,  94,  37,  71,  70,  42,   9,\n",
       "         75,  81,  19,  31,  33,  44,  97,  67,  46,  82,  55,  14,   7,\n",
       "         17,  54,  25,  27,  66,  84,  20,  39,  16,  12,  88,  50,  36,\n",
       "         83,  91,  59,  72,  24,  15,  89,  10,  78,  45,  69,  35,  79,\n",
       "          6,  34,   5,  95,  41,  52,  61,   3,  48,  56,  11,  85,  13,\n",
       "        100,  22,  29,  28,  90,  62,  30,  64,  58,  73,  51,  26,  60,\n",
       "         87,  23,  40,  68,  38,  21,  65,  18,  92,  86,  47,  57,  43,\n",
       "         76,   2,   1,  74,  99,  93,   8,  96,  53])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "      <th>split0_test_MAPE</th>\n",
       "      <th>split1_test_MAPE</th>\n",
       "      <th>split2_test_MAPE</th>\n",
       "      <th>split3_test_MAPE</th>\n",
       "      <th>split4_test_MAPE</th>\n",
       "      <th>mean_test_MAPE</th>\n",
       "      <th>std_test_MAPE</th>\n",
       "      <th>rank_test_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091361</td>\n",
       "      <td>91</td>\n",
       "      <td>3.035095</td>\n",
       "      <td>3.320721</td>\n",
       "      <td>2.178299</td>\n",
       "      <td>2.092148</td>\n",
       "      <td>3.218429</td>\n",
       "      <td>2.768938</td>\n",
       "      <td>0.526165</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.356880</td>\n",
       "      <td>0.118602</td>\n",
       "      <td>0.012568</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.8</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>21</td>\n",
       "      <td>7.303843</td>\n",
       "      <td>5.072987</td>\n",
       "      <td>4.045672</td>\n",
       "      <td>3.293075</td>\n",
       "      <td>7.457764</td>\n",
       "      <td>5.434668</td>\n",
       "      <td>1.687203</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>36</td>\n",
       "      <td>1.892107</td>\n",
       "      <td>1.562857</td>\n",
       "      <td>1.378891</td>\n",
       "      <td>1.540713</td>\n",
       "      <td>1.861079</td>\n",
       "      <td>1.647129</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735504</td>\n",
       "      <td>0.085791</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087448</td>\n",
       "      <td>26</td>\n",
       "      <td>4.454543</td>\n",
       "      <td>3.584502</td>\n",
       "      <td>3.515590</td>\n",
       "      <td>2.708177</td>\n",
       "      <td>6.079748</td>\n",
       "      <td>4.068512</td>\n",
       "      <td>1.147570</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690957</td>\n",
       "      <td>0.085564</td>\n",
       "      <td>0.015548</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>86</td>\n",
       "      <td>4.105856</td>\n",
       "      <td>2.067306</td>\n",
       "      <td>2.300470</td>\n",
       "      <td>1.813666</td>\n",
       "      <td>3.984210</td>\n",
       "      <td>2.854302</td>\n",
       "      <td>0.985099</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.043544</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>12</td>\n",
       "      <td>1.266702</td>\n",
       "      <td>1.367166</td>\n",
       "      <td>1.320797</td>\n",
       "      <td>1.013287</td>\n",
       "      <td>1.620383</td>\n",
       "      <td>1.317667</td>\n",
       "      <td>0.194598</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.105798</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093669</td>\n",
       "      <td>29</td>\n",
       "      <td>3.345845</td>\n",
       "      <td>1.560090</td>\n",
       "      <td>1.348298</td>\n",
       "      <td>1.498857</td>\n",
       "      <td>1.863412</td>\n",
       "      <td>1.923300</td>\n",
       "      <td>0.730742</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.024818</td>\n",
       "      <td>0.048823</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.9</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088874</td>\n",
       "      <td>16</td>\n",
       "      <td>6.435205</td>\n",
       "      <td>4.666238</td>\n",
       "      <td>3.695465</td>\n",
       "      <td>2.798707</td>\n",
       "      <td>7.515980</td>\n",
       "      <td>5.022319</td>\n",
       "      <td>1.734726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.284560</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096829</td>\n",
       "      <td>39</td>\n",
       "      <td>2.442597</td>\n",
       "      <td>1.808616</td>\n",
       "      <td>1.432300</td>\n",
       "      <td>1.218623</td>\n",
       "      <td>2.207200</td>\n",
       "      <td>1.821867</td>\n",
       "      <td>0.458177</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.6</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074875</td>\n",
       "      <td>49</td>\n",
       "      <td>3.402098</td>\n",
       "      <td>3.352984</td>\n",
       "      <td>3.301580</td>\n",
       "      <td>2.528448</td>\n",
       "      <td>4.874383</td>\n",
       "      <td>3.491899</td>\n",
       "      <td>0.761982</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.220600      0.018975         0.001244        0.001017   \n",
       "1        1.356880      0.118602         0.012568        0.002016   \n",
       "2        0.085307      0.007686         0.002745        0.004271   \n",
       "3        0.735504      0.085791         0.012303        0.004420   \n",
       "4        0.690957      0.085564         0.015548        0.006166   \n",
       "..            ...           ...              ...             ...   \n",
       "95       0.043544      0.006505         0.001007        0.000903   \n",
       "96       0.105798      0.007268         0.003837        0.005037   \n",
       "97       2.024818      0.048823         0.017766        0.002680   \n",
       "98       0.284560      0.012852         0.002944        0.003990   \n",
       "99       0.410407      0.011408         0.004326        0.006334   \n",
       "\n",
       "   param_subsample param_n_estimators param_min_samples_split  \\\n",
       "0              0.9                 11                       9   \n",
       "1              0.8                 46                       3   \n",
       "2              0.5                  6                      10   \n",
       "3              0.7                 16                      10   \n",
       "4              0.6                 16                       2   \n",
       "..             ...                ...                     ...   \n",
       "95             0.6                  1                       7   \n",
       "96             0.9                  6                       4   \n",
       "97             0.9                 46                       5   \n",
       "98             0.9                  6                       8   \n",
       "99             0.6                 21                       9   \n",
       "\n",
       "   param_min_samples_leaf param_max_depth param_learning_rate  ...  \\\n",
       "0                       7               6                 0.4  ...   \n",
       "1                       4              11                 0.9  ...   \n",
       "2                      10               6                 0.1  ...   \n",
       "3                       5              23                 0.7  ...   \n",
       "4                       1              21                 0.1  ...   \n",
       "..                    ...             ...                 ...  ...   \n",
       "95                      4              15                 0.2  ...   \n",
       "96                      7               4                 0.1  ...   \n",
       "97                      3              18                 0.8  ...   \n",
       "98                      9              18                 0.1  ...   \n",
       "99                      8               7                 0.8  ...   \n",
       "\n",
       "   std_test_RMSE  rank_test_RMSE  split0_test_MAPE  split1_test_MAPE  \\\n",
       "0       0.091361              91          3.035095          3.320721   \n",
       "1       0.072620              21          7.303843          5.072987   \n",
       "2       0.109254              36          1.892107          1.562857   \n",
       "3       0.087448              26          4.454543          3.584502   \n",
       "4       0.085463              86          4.105856          2.067306   \n",
       "..           ...             ...               ...               ...   \n",
       "95      0.104057              12          1.266702          1.367166   \n",
       "96      0.093669              29          3.345845          1.560090   \n",
       "97      0.088874              16          6.435205          4.666238   \n",
       "98      0.096829              39          2.442597          1.808616   \n",
       "99      0.074875              49          3.402098          3.352984   \n",
       "\n",
       "    split2_test_MAPE  split3_test_MAPE  split4_test_MAPE  mean_test_MAPE  \\\n",
       "0           2.178299          2.092148          3.218429        2.768938   \n",
       "1           4.045672          3.293075          7.457764        5.434668   \n",
       "2           1.378891          1.540713          1.861079        1.647129   \n",
       "3           3.515590          2.708177          6.079748        4.068512   \n",
       "4           2.300470          1.813666          3.984210        2.854302   \n",
       "..               ...               ...               ...             ...   \n",
       "95          1.320797          1.013287          1.620383        1.317667   \n",
       "96          1.348298          1.498857          1.863412        1.923300   \n",
       "97          3.695465          2.798707          7.515980        5.022319   \n",
       "98          1.432300          1.218623          2.207200        1.821867   \n",
       "99          3.301580          2.528448          4.874383        3.491899   \n",
       "\n",
       "    std_test_MAPE  rank_test_MAPE  \n",
       "0        0.526165              80  \n",
       "1        1.687203               4  \n",
       "2        0.198074              98  \n",
       "3        1.147570              32  \n",
       "4        0.985099              77  \n",
       "..            ...             ...  \n",
       "95       0.194598              99  \n",
       "96       0.730742              93  \n",
       "97       1.734726               8  \n",
       "98       0.458177              96  \n",
       "99       0.761982              53  \n",
       "\n",
       "[100 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "pd.DataFrame(rs.cv_results_).to_excel('GBR_RS_Scal_CO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAYESSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_regression_cv(learning_rate,n_estimators, subsample, min_samples_split, min_samples_leaf, max_depth):\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        subsample= (subsample), \n",
    "        min_samples_split=int(min_samples_split), \n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        max_depth=int(max_depth)\n",
    "    )\n",
    "    scores = cross_val_score(gbr, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    return -rmse  # Return only the RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt = BayesianOptimization(\n",
    "    gb_regression_cv,\n",
    "    {\n",
    "        'learning_rate': (0.01, 1.0),\n",
    "        'n_estimators': (1, 51),\n",
    "        'subsample': (0.5, 1.0),\n",
    "        'min_samples_split': (2, 11),\n",
    "        'min_samples_leaf': (1, 11),\n",
    "        'max_depth': (1, 26),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_sa... | min_sa... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.8884  \u001b[39m | \u001b[39m0.6451   \u001b[39m | \u001b[39m21.74    \u001b[39m | \u001b[39m1.394    \u001b[39m | \u001b[39m9.803    \u001b[39m | \u001b[39m36.48    \u001b[39m | \u001b[39m0.6939   \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m-0.7527  \u001b[39m | \u001b[35m0.8267   \u001b[39m | \u001b[35m6.827    \u001b[39m | \u001b[35m4.57     \u001b[39m | \u001b[35m9.816    \u001b[39m | \u001b[35m49.75    \u001b[39m | \u001b[35m0.9295   \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-0.7776  \u001b[39m | \u001b[39m0.4922   \u001b[39m | \u001b[39m14.41    \u001b[39m | \u001b[39m5.22     \u001b[39m | \u001b[39m8.241    \u001b[39m | \u001b[39m50.86    \u001b[39m | \u001b[39m0.8059   \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-0.727   \u001b[39m | \u001b[35m0.9686   \u001b[39m | \u001b[35m2.961    \u001b[39m | \u001b[35m9.655    \u001b[39m | \u001b[35m10.2     \u001b[39m | \u001b[35m23.76    \u001b[39m | \u001b[35m0.5897   \u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m-0.6884  \u001b[39m | \u001b[35m0.3917   \u001b[39m | \u001b[35m24.16    \u001b[39m | \u001b[35m9.279    \u001b[39m | \u001b[35m8.053    \u001b[39m | \u001b[35m6.441    \u001b[39m | \u001b[35m0.6989   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.7324  \u001b[39m | \u001b[39m0.1959   \u001b[39m | \u001b[39m18.65    \u001b[39m | \u001b[39m3.795    \u001b[39m | \u001b[39m2.859    \u001b[39m | \u001b[39m44.75    \u001b[39m | \u001b[39m0.7276   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.7118  \u001b[39m | \u001b[39m0.2868   \u001b[39m | \u001b[39m21.15    \u001b[39m | \u001b[39m3.925    \u001b[39m | \u001b[39m10.91    \u001b[39m | \u001b[39m11.1     \u001b[39m | \u001b[39m0.6273   \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.7503  \u001b[39m | \u001b[39m0.6333   \u001b[39m | \u001b[39m15.25    \u001b[39m | \u001b[39m9.072    \u001b[39m | \u001b[39m6.732    \u001b[39m | \u001b[39m29.18    \u001b[39m | \u001b[39m0.7724   \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.7331  \u001b[39m | \u001b[39m0.3083   \u001b[39m | \u001b[39m13.4     \u001b[39m | \u001b[39m7.391    \u001b[39m | \u001b[39m4.445    \u001b[39m | \u001b[39m40.64    \u001b[39m | \u001b[39m0.8329   \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.7166  \u001b[39m | \u001b[39m0.7039   \u001b[39m | \u001b[39m9.616    \u001b[39m | \u001b[39m10.62    \u001b[39m | \u001b[39m5.487    \u001b[39m | \u001b[39m5.082    \u001b[39m | \u001b[39m0.7716   \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.8033  \u001b[39m | \u001b[39m0.7467   \u001b[39m | \u001b[39m24.49    \u001b[39m | \u001b[39m8.288    \u001b[39m | \u001b[39m8.558    \u001b[39m | \u001b[39m6.349    \u001b[39m | \u001b[39m0.5456   \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.8637  \u001b[39m | \u001b[39m0.9379   \u001b[39m | \u001b[39m11.2     \u001b[39m | \u001b[39m5.871    \u001b[39m | \u001b[39m7.571    \u001b[39m | \u001b[39m33.75    \u001b[39m | \u001b[39m0.808    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.7526  \u001b[39m | \u001b[39m0.2955   \u001b[39m | \u001b[39m14.4     \u001b[39m | \u001b[39m2.2      \u001b[39m | \u001b[39m8.695    \u001b[39m | \u001b[39m16.35    \u001b[39m | \u001b[39m0.9164   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.9174  \u001b[39m | \u001b[39m0.2728   \u001b[39m | \u001b[39m2.922    \u001b[39m | \u001b[39m2.675    \u001b[39m | \u001b[39m2.907    \u001b[39m | \u001b[39m2.837    \u001b[39m | \u001b[39m0.5096   \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.9192  \u001b[39m | \u001b[39m0.9694   \u001b[39m | \u001b[39m23.65    \u001b[39m | \u001b[39m7.808    \u001b[39m | \u001b[39m3.416    \u001b[39m | \u001b[39m28.18    \u001b[39m | \u001b[39m0.5829   \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.6955  \u001b[39m | \u001b[39m0.1983   \u001b[39m | \u001b[39m22.72    \u001b[39m | \u001b[39m9.414    \u001b[39m | \u001b[39m3.507    \u001b[39m | \u001b[39m15.87    \u001b[39m | \u001b[39m0.8557   \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.7858  \u001b[39m | \u001b[39m0.8121   \u001b[39m | \u001b[39m6.493    \u001b[39m | \u001b[39m9.202    \u001b[39m | \u001b[39m2.74     \u001b[39m | \u001b[39m37.41    \u001b[39m | \u001b[39m0.7166   \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.7042  \u001b[39m | \u001b[39m0.5112   \u001b[39m | \u001b[39m4.167    \u001b[39m | \u001b[39m9.991    \u001b[39m | \u001b[39m3.375    \u001b[39m | \u001b[39m28.43    \u001b[39m | \u001b[39m0.6542   \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-0.7169  \u001b[39m | \u001b[39m0.7867   \u001b[39m | \u001b[39m19.88    \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m3.788    \u001b[39m | \u001b[39m1.63     \u001b[39m | \u001b[39m0.839    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.7895  \u001b[39m | \u001b[39m0.4313   \u001b[39m | \u001b[39m22.06    \u001b[39m | \u001b[39m1.378    \u001b[39m | \u001b[39m9.547    \u001b[39m | \u001b[39m34.36    \u001b[39m | \u001b[39m0.9676   \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.6925  \u001b[39m | \u001b[39m0.2545   \u001b[39m | \u001b[39m7.877    \u001b[39m | \u001b[39m10.55    \u001b[39m | \u001b[39m9.008    \u001b[39m | \u001b[39m8.465    \u001b[39m | \u001b[39m0.8961   \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.8189  \u001b[39m | \u001b[39m0.6938   \u001b[39m | \u001b[39m21.28    \u001b[39m | \u001b[39m4.652    \u001b[39m | \u001b[39m3.091    \u001b[39m | \u001b[39m50.38    \u001b[39m | \u001b[39m0.8934   \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.8112  \u001b[39m | \u001b[39m0.6067   \u001b[39m | \u001b[39m13.27    \u001b[39m | \u001b[39m3.114    \u001b[39m | \u001b[39m2.448    \u001b[39m | \u001b[39m49.05    \u001b[39m | \u001b[39m0.8351   \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-0.7138  \u001b[39m | \u001b[39m0.1285   \u001b[39m | \u001b[39m18.26    \u001b[39m | \u001b[39m3.534    \u001b[39m | \u001b[39m2.556    \u001b[39m | \u001b[39m44.7     \u001b[39m | \u001b[39m0.6276   \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.7975  \u001b[39m | \u001b[39m0.08811  \u001b[39m | \u001b[39m23.89    \u001b[39m | \u001b[39m10.13    \u001b[39m | \u001b[39m7.62     \u001b[39m | \u001b[39m6.52     \u001b[39m | \u001b[39m0.83     \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.7076  \u001b[39m | \u001b[39m0.5519   \u001b[39m | \u001b[39m24.43    \u001b[39m | \u001b[39m9.463    \u001b[39m | \u001b[39m8.38     \u001b[39m | \u001b[39m6.698    \u001b[39m | \u001b[39m0.9424   \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.7029  \u001b[39m | \u001b[39m0.2524   \u001b[39m | \u001b[39m22.91    \u001b[39m | \u001b[39m9.442    \u001b[39m | \u001b[39m4.131    \u001b[39m | \u001b[39m15.22    \u001b[39m | \u001b[39m0.6722   \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.7757  \u001b[39m | \u001b[39m0.7971   \u001b[39m | \u001b[39m23.01    \u001b[39m | \u001b[39m9.082    \u001b[39m | \u001b[39m4.241    \u001b[39m | \u001b[39m16.21    \u001b[39m | \u001b[39m0.6104   \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.7685  \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m23.56    \u001b[39m | \u001b[39m9.139    \u001b[39m | \u001b[39m8.011    \u001b[39m | \u001b[39m6.761    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.928   \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m22.59    \u001b[39m | \u001b[39m9.758    \u001b[39m | \u001b[39m3.287    \u001b[39m | \u001b[39m15.02    \u001b[39m | \u001b[39m0.9492   \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-0.7033  \u001b[39m | \u001b[39m0.314    \u001b[39m | \u001b[39m24.51    \u001b[39m | \u001b[39m9.408    \u001b[39m | \u001b[39m8.258    \u001b[39m | \u001b[39m6.365    \u001b[39m | \u001b[39m0.6744   \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-0.7405  \u001b[39m | \u001b[39m0.1306   \u001b[39m | \u001b[39m18.61    \u001b[39m | \u001b[39m3.626    \u001b[39m | \u001b[39m2.3      \u001b[39m | \u001b[39m44.43    \u001b[39m | \u001b[39m0.8137   \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-0.9299  \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m22.9     \u001b[39m | \u001b[39m9.28     \u001b[39m | \u001b[39m4.018    \u001b[39m | \u001b[39m15.81    \u001b[39m | \u001b[39m0.693    \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-0.6904  \u001b[39m | \u001b[39m0.2169   \u001b[39m | \u001b[39m24.04    \u001b[39m | \u001b[39m10.19    \u001b[39m | \u001b[39m3.169    \u001b[39m | \u001b[39m18.54    \u001b[39m | \u001b[39m0.5471   \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-0.7118  \u001b[39m | \u001b[39m0.5412   \u001b[39m | \u001b[39m24.36    \u001b[39m | \u001b[39m9.356    \u001b[39m | \u001b[39m8.175    \u001b[39m | \u001b[39m6.512    \u001b[39m | \u001b[39m0.7698   \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-0.7787  \u001b[39m | \u001b[39m0.7055   \u001b[39m | \u001b[39m19.06    \u001b[39m | \u001b[39m7.941    \u001b[39m | \u001b[39m8.378    \u001b[39m | \u001b[39m23.11    \u001b[39m | \u001b[39m0.8438   \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-0.7015  \u001b[39m | \u001b[39m0.2069   \u001b[39m | \u001b[39m24.22    \u001b[39m | \u001b[39m9.379    \u001b[39m | \u001b[39m8.288    \u001b[39m | \u001b[39m6.558    \u001b[39m | \u001b[39m0.8249   \u001b[39m |\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-0.7128  \u001b[39m | \u001b[39m0.5033   \u001b[39m | \u001b[39m23.04    \u001b[39m | \u001b[39m7.096    \u001b[39m | \u001b[39m7.581    \u001b[39m | \u001b[39m2.911    \u001b[39m | \u001b[39m0.8669   \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-0.8666  \u001b[39m | \u001b[39m0.8916   \u001b[39m | \u001b[39m22.59    \u001b[39m | \u001b[39m6.817    \u001b[39m | \u001b[39m4.014    \u001b[39m | \u001b[39m26.13    \u001b[39m | \u001b[39m0.7641   \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-0.7364  \u001b[39m | \u001b[39m0.4938   \u001b[39m | \u001b[39m15.5     \u001b[39m | \u001b[39m7.902    \u001b[39m | \u001b[39m4.754    \u001b[39m | \u001b[39m33.65    \u001b[39m | \u001b[39m0.9838   \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-0.9387  \u001b[39m | \u001b[39m0.9056   \u001b[39m | \u001b[39m14.13    \u001b[39m | \u001b[39m1.011    \u001b[39m | \u001b[39m3.56     \u001b[39m | \u001b[39m33.64    \u001b[39m | \u001b[39m0.8409   \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-0.6885  \u001b[39m | \u001b[39m0.1899   \u001b[39m | \u001b[39m24.95    \u001b[39m | \u001b[39m9.672    \u001b[39m | \u001b[39m9.679    \u001b[39m | \u001b[39m36.12    \u001b[39m | \u001b[39m0.5084   \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-0.9208  \u001b[39m | \u001b[39m0.6078   \u001b[39m | \u001b[39m1.712    \u001b[39m | \u001b[39m6.146    \u001b[39m | \u001b[39m3.446    \u001b[39m | \u001b[39m47.84    \u001b[39m | \u001b[39m0.8275   \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-0.7323  \u001b[39m | \u001b[39m0.7138   \u001b[39m | \u001b[39m5.594    \u001b[39m | \u001b[39m9.498    \u001b[39m | \u001b[39m10.41    \u001b[39m | \u001b[39m35.57    \u001b[39m | \u001b[39m0.5376   \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-0.7163  \u001b[39m | \u001b[39m0.5989   \u001b[39m | \u001b[39m22.94    \u001b[39m | \u001b[39m7.152    \u001b[39m | \u001b[39m7.874    \u001b[39m | \u001b[39m2.994    \u001b[39m | \u001b[39m0.9682   \u001b[39m |\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-0.6996  \u001b[39m | \u001b[39m0.4015   \u001b[39m | \u001b[39m24.05    \u001b[39m | \u001b[39m9.423    \u001b[39m | \u001b[39m8.391    \u001b[39m | \u001b[39m6.223    \u001b[39m | \u001b[39m0.6035   \u001b[39m |\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-0.7575  \u001b[39m | \u001b[39m0.4976   \u001b[39m | \u001b[39m15.13    \u001b[39m | \u001b[39m10.77    \u001b[39m | \u001b[39m5.977    \u001b[39m | \u001b[39m44.41    \u001b[39m | \u001b[39m0.6269   \u001b[39m |\n",
      "| \u001b[35m48       \u001b[39m | \u001b[35m-0.6849  \u001b[39m | \u001b[35m0.5368   \u001b[39m | \u001b[35m7.715    \u001b[39m | \u001b[35m10.63    \u001b[39m | \u001b[35m3.201    \u001b[39m | \u001b[35m4.115    \u001b[39m | \u001b[35m0.7535   \u001b[39m |\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-0.7632  \u001b[39m | \u001b[39m0.7707   \u001b[39m | \u001b[39m16.06    \u001b[39m | \u001b[39m8.641    \u001b[39m | \u001b[39m8.225    \u001b[39m | \u001b[39m8.044    \u001b[39m | \u001b[39m0.9654   \u001b[39m |\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-0.7069  \u001b[39m | \u001b[39m0.306    \u001b[39m | \u001b[39m20.77    \u001b[39m | \u001b[39m7.126    \u001b[39m | \u001b[39m4.253    \u001b[39m | \u001b[39m16.36    \u001b[39m | \u001b[39m0.7484   \u001b[39m |\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-0.7325  \u001b[39m | \u001b[39m0.3621   \u001b[39m | \u001b[39m12.53    \u001b[39m | \u001b[39m6.192    \u001b[39m | \u001b[39m9.495    \u001b[39m | \u001b[39m34.27    \u001b[39m | \u001b[39m0.9498   \u001b[39m |\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-0.7066  \u001b[39m | \u001b[39m0.3935   \u001b[39m | \u001b[39m4.32     \u001b[39m | \u001b[39m5.35     \u001b[39m | \u001b[39m2.951    \u001b[39m | \u001b[39m36.64    \u001b[39m | \u001b[39m0.5053   \u001b[39m |\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-0.8106  \u001b[39m | \u001b[39m0.7396   \u001b[39m | \u001b[39m13.3     \u001b[39m | \u001b[39m8.271    \u001b[39m | \u001b[39m8.25     \u001b[39m | \u001b[39m38.5     \u001b[39m | \u001b[39m0.5932   \u001b[39m |\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-0.7204  \u001b[39m | \u001b[39m0.3392   \u001b[39m | \u001b[39m11.28    \u001b[39m | \u001b[39m3.066    \u001b[39m | \u001b[39m2.331    \u001b[39m | \u001b[39m10.83    \u001b[39m | \u001b[39m0.8929   \u001b[39m |\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-0.7023  \u001b[39m | \u001b[39m0.2899   \u001b[39m | \u001b[39m24.2     \u001b[39m | \u001b[39m9.261    \u001b[39m | \u001b[39m8.178    \u001b[39m | \u001b[39m6.101    \u001b[39m | \u001b[39m0.9716   \u001b[39m |\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-0.687   \u001b[39m | \u001b[39m0.5187   \u001b[39m | \u001b[39m3.326    \u001b[39m | \u001b[39m8.465    \u001b[39m | \u001b[39m10.41    \u001b[39m | \u001b[39m23.13    \u001b[39m | \u001b[39m0.5008   \u001b[39m |\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-0.6862  \u001b[39m | \u001b[39m0.5391   \u001b[39m | \u001b[39m5.575    \u001b[39m | \u001b[39m10.78    \u001b[39m | \u001b[39m8.709    \u001b[39m | \u001b[39m28.19    \u001b[39m | \u001b[39m0.643    \u001b[39m |\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-0.7106  \u001b[39m | \u001b[39m0.746    \u001b[39m | \u001b[39m7.909    \u001b[39m | \u001b[39m10.8     \u001b[39m | \u001b[39m3.395    \u001b[39m | \u001b[39m4.309    \u001b[39m | \u001b[39m0.9537   \u001b[39m |\n",
      "| \u001b[35m59       \u001b[39m | \u001b[35m-0.6827  \u001b[39m | \u001b[35m0.2763   \u001b[39m | \u001b[35m5.767    \u001b[39m | \u001b[35m10.97    \u001b[39m | \u001b[35m8.493    \u001b[39m | \u001b[35m28.44    \u001b[39m | \u001b[35m0.5722   \u001b[39m |\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-0.7504  \u001b[39m | \u001b[39m0.652    \u001b[39m | \u001b[39m17.3     \u001b[39m | \u001b[39m10.73    \u001b[39m | \u001b[39m7.042    \u001b[39m | \u001b[39m22.08    \u001b[39m | \u001b[39m0.828    \u001b[39m |\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m-0.8152  \u001b[39m | \u001b[39m0.8847   \u001b[39m | \u001b[39m24.96    \u001b[39m | \u001b[39m3.295    \u001b[39m | \u001b[39m4.552    \u001b[39m | \u001b[39m10.76    \u001b[39m | \u001b[39m0.8542   \u001b[39m |\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m-0.717   \u001b[39m | \u001b[39m0.2634   \u001b[39m | \u001b[39m13.71    \u001b[39m | \u001b[39m8.706    \u001b[39m | \u001b[39m3.979    \u001b[39m | \u001b[39m30.4     \u001b[39m | \u001b[39m0.8864   \u001b[39m |\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m-0.6973  \u001b[39m | \u001b[39m0.6016   \u001b[39m | \u001b[39m5.887    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.82     \u001b[39m | \u001b[39m28.53    \u001b[39m | \u001b[39m0.7522   \u001b[39m |\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m-0.6943  \u001b[39m | \u001b[39m0.3057   \u001b[39m | \u001b[39m7.332    \u001b[39m | \u001b[39m7.113    \u001b[39m | \u001b[39m9.356    \u001b[39m | \u001b[39m29.39    \u001b[39m | \u001b[39m0.7573   \u001b[39m |\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m-0.7493  \u001b[39m | \u001b[39m0.4589   \u001b[39m | \u001b[39m6.807    \u001b[39m | \u001b[39m4.062    \u001b[39m | \u001b[39m10.11    \u001b[39m | \u001b[39m37.19    \u001b[39m | \u001b[39m0.6117   \u001b[39m |\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m-0.8098  \u001b[39m | \u001b[39m0.1596   \u001b[39m | \u001b[39m7.835    \u001b[39m | \u001b[39m10.88    \u001b[39m | \u001b[39m3.882    \u001b[39m | \u001b[39m3.856    \u001b[39m | \u001b[39m0.6654   \u001b[39m |\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m-0.7019  \u001b[39m | \u001b[39m0.5443   \u001b[39m | \u001b[39m5.658    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.375    \u001b[39m | \u001b[39m28.31    \u001b[39m | \u001b[39m0.9714   \u001b[39m |\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m-0.7124  \u001b[39m | \u001b[39m0.2737   \u001b[39m | \u001b[39m15.09    \u001b[39m | \u001b[39m3.192    \u001b[39m | \u001b[39m5.03     \u001b[39m | \u001b[39m8.679    \u001b[39m | \u001b[39m0.854    \u001b[39m |\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m-0.6991  \u001b[39m | \u001b[39m0.2712   \u001b[39m | \u001b[39m10.91    \u001b[39m | \u001b[39m4.011    \u001b[39m | \u001b[39m6.685    \u001b[39m | \u001b[39m17.67    \u001b[39m | \u001b[39m0.5407   \u001b[39m |\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m-0.7256  \u001b[39m | \u001b[39m0.6962   \u001b[39m | \u001b[39m5.92     \u001b[39m | \u001b[39m10.71    \u001b[39m | \u001b[39m8.383    \u001b[39m | \u001b[39m28.37    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m-0.7185  \u001b[39m | \u001b[39m0.4323   \u001b[39m | \u001b[39m8.503    \u001b[39m | \u001b[39m7.776    \u001b[39m | \u001b[39m6.514    \u001b[39m | \u001b[39m47.73    \u001b[39m | \u001b[39m0.8232   \u001b[39m |\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m-0.8693  \u001b[39m | \u001b[39m0.7357   \u001b[39m | \u001b[39m18.16    \u001b[39m | \u001b[39m1.51     \u001b[39m | \u001b[39m3.419    \u001b[39m | \u001b[39m5.323    \u001b[39m | \u001b[39m0.7678   \u001b[39m |\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m-0.867   \u001b[39m | \u001b[39m0.03936  \u001b[39m | \u001b[39m13.19    \u001b[39m | \u001b[39m2.108    \u001b[39m | \u001b[39m2.911    \u001b[39m | \u001b[39m7.896    \u001b[39m | \u001b[39m0.978    \u001b[39m |\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m-0.7408  \u001b[39m | \u001b[39m0.8379   \u001b[39m | \u001b[39m2.701    \u001b[39m | \u001b[39m9.478    \u001b[39m | \u001b[39m10.28    \u001b[39m | \u001b[39m24.03    \u001b[39m | \u001b[39m0.5752   \u001b[39m |\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m-0.7875  \u001b[39m | \u001b[39m0.4417   \u001b[39m | \u001b[39m12.53    \u001b[39m | \u001b[39m1.043    \u001b[39m | \u001b[39m8.952    \u001b[39m | \u001b[39m27.77    \u001b[39m | \u001b[39m0.8154   \u001b[39m |\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m-0.6856  \u001b[39m | \u001b[39m0.1858   \u001b[39m | \u001b[39m5.61     \u001b[39m | \u001b[39m10.66    \u001b[39m | \u001b[39m8.733    \u001b[39m | \u001b[39m28.53    \u001b[39m | \u001b[39m0.9085   \u001b[39m |\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m-0.9225  \u001b[39m | \u001b[39m0.7863   \u001b[39m | \u001b[39m19.72    \u001b[39m | \u001b[39m2.619    \u001b[39m | \u001b[39m2.389    \u001b[39m | \u001b[39m39.67    \u001b[39m | \u001b[39m0.7721   \u001b[39m |\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m-0.6853  \u001b[39m | \u001b[39m0.1237   \u001b[39m | \u001b[39m5.916    \u001b[39m | \u001b[39m10.91    \u001b[39m | \u001b[39m8.793    \u001b[39m | \u001b[39m28.07    \u001b[39m | \u001b[39m0.8717   \u001b[39m |\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m-0.706   \u001b[39m | \u001b[39m0.6337   \u001b[39m | \u001b[39m4.951    \u001b[39m | \u001b[39m7.738    \u001b[39m | \u001b[39m10.68    \u001b[39m | \u001b[39m2.9      \u001b[39m | \u001b[39m0.9501   \u001b[39m |\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m-0.6833  \u001b[39m | \u001b[39m0.1784   \u001b[39m | \u001b[39m7.079    \u001b[39m | \u001b[39m10.69    \u001b[39m | \u001b[39m6.145    \u001b[39m | \u001b[39m49.67    \u001b[39m | \u001b[39m0.7758   \u001b[39m |\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m-0.9183  \u001b[39m | \u001b[39m0.8409   \u001b[39m | \u001b[39m1.903    \u001b[39m | \u001b[39m1.403    \u001b[39m | \u001b[39m7.367    \u001b[39m | \u001b[39m49.72    \u001b[39m | \u001b[39m0.9321   \u001b[39m |\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m-0.7122  \u001b[39m | \u001b[39m0.04637  \u001b[39m | \u001b[39m5.48     \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m9.054    \u001b[39m | \u001b[39m28.34    \u001b[39m | \u001b[39m0.5548   \u001b[39m |\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m-0.7969  \u001b[39m | \u001b[39m0.638    \u001b[39m | \u001b[39m24.07    \u001b[39m | \u001b[39m5.769    \u001b[39m | \u001b[39m3.095    \u001b[39m | \u001b[39m39.22    \u001b[39m | \u001b[39m0.9635   \u001b[39m |\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m-0.6864  \u001b[39m | \u001b[39m0.5443   \u001b[39m | \u001b[39m5.585    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m9.201    \u001b[39m | \u001b[39m27.99    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m-0.8042  \u001b[39m | \u001b[39m0.4624   \u001b[39m | \u001b[39m24.85    \u001b[39m | \u001b[39m3.863    \u001b[39m | \u001b[39m8.134    \u001b[39m | \u001b[39m33.69    \u001b[39m | \u001b[39m0.9234   \u001b[39m |\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m-0.8376  \u001b[39m | \u001b[39m0.8864   \u001b[39m | \u001b[39m13.91    \u001b[39m | \u001b[39m4.295    \u001b[39m | \u001b[39m7.291    \u001b[39m | \u001b[39m46.21    \u001b[39m | \u001b[39m0.9073   \u001b[39m |\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m-0.6859  \u001b[39m | \u001b[39m0.1303   \u001b[39m | \u001b[39m5.262    \u001b[39m | \u001b[39m10.91    \u001b[39m | \u001b[39m8.692    \u001b[39m | \u001b[39m27.9     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m-0.874   \u001b[39m | \u001b[39m0.1332   \u001b[39m | \u001b[39m22.96    \u001b[39m | \u001b[39m7.342    \u001b[39m | \u001b[39m7.441    \u001b[39m | \u001b[39m2.764    \u001b[39m | \u001b[39m0.9389   \u001b[39m |\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m-0.6946  \u001b[39m | \u001b[39m0.4768   \u001b[39m | \u001b[39m5.178    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.894    \u001b[39m | \u001b[39m28.4     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m-0.7402  \u001b[39m | \u001b[39m0.6578   \u001b[39m | \u001b[39m24.09    \u001b[39m | \u001b[39m10.42    \u001b[39m | \u001b[39m3.109    \u001b[39m | \u001b[39m18.29    \u001b[39m | \u001b[39m0.8676   \u001b[39m |\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m-0.7515  \u001b[39m | \u001b[39m0.5751   \u001b[39m | \u001b[39m10.72    \u001b[39m | \u001b[39m10.96    \u001b[39m | \u001b[39m8.301    \u001b[39m | \u001b[39m13.55    \u001b[39m | \u001b[39m0.5499   \u001b[39m |\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m-0.6868  \u001b[39m | \u001b[39m0.717    \u001b[39m | \u001b[39m3.306    \u001b[39m | \u001b[39m2.758    \u001b[39m | \u001b[39m7.334    \u001b[39m | \u001b[39m27.01    \u001b[39m | \u001b[39m0.5546   \u001b[39m |\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m-0.8849  \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m5.556    \u001b[39m | \u001b[39m10.59    \u001b[39m | \u001b[39m8.32     \u001b[39m | \u001b[39m28.06    \u001b[39m | \u001b[39m0.7146   \u001b[39m |\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m-0.685   \u001b[39m | \u001b[39m0.2805   \u001b[39m | \u001b[39m5.602    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.875    \u001b[39m | \u001b[39m28.27    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m-0.6831  \u001b[39m | \u001b[39m0.3144   \u001b[39m | \u001b[39m5.279    \u001b[39m | \u001b[39m10.61    \u001b[39m | \u001b[39m9.129    \u001b[39m | \u001b[39m28.03    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m-0.6888  \u001b[39m | \u001b[39m0.03947  \u001b[39m | \u001b[39m21.41    \u001b[39m | \u001b[39m4.407    \u001b[39m | \u001b[39m6.532    \u001b[39m | \u001b[39m43.44    \u001b[39m | \u001b[39m0.813    \u001b[39m |\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m-0.6943  \u001b[39m | \u001b[39m0.3847   \u001b[39m | \u001b[39m5.855    \u001b[39m | \u001b[39m10.56    \u001b[39m | \u001b[39m9.188    \u001b[39m | \u001b[39m28.27    \u001b[39m | \u001b[39m0.8544   \u001b[39m |\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m-0.7985  \u001b[39m | \u001b[39m0.6617   \u001b[39m | \u001b[39m19.75    \u001b[39m | \u001b[39m7.332    \u001b[39m | \u001b[39m2.663    \u001b[39m | \u001b[39m41.69    \u001b[39m | \u001b[39m0.5945   \u001b[39m |\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m-0.6874  \u001b[39m | \u001b[39m0.3747   \u001b[39m | \u001b[39m4.162    \u001b[39m | \u001b[39m10.54    \u001b[39m | \u001b[39m7.046    \u001b[39m | \u001b[39m34.9     \u001b[39m | \u001b[39m0.7072   \u001b[39m |\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m-0.9047  \u001b[39m | \u001b[39m0.03866  \u001b[39m | \u001b[39m16.0     \u001b[39m | \u001b[39m2.509    \u001b[39m | \u001b[39m2.133    \u001b[39m | \u001b[39m5.602    \u001b[39m | \u001b[39m0.5776   \u001b[39m |\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m-0.977   \u001b[39m | \u001b[39m0.02479  \u001b[39m | \u001b[39m14.02    \u001b[39m | \u001b[39m3.576    \u001b[39m | \u001b[39m10.47    \u001b[39m | \u001b[39m2.046    \u001b[39m | \u001b[39m0.6525   \u001b[39m |\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m-0.6949  \u001b[39m | \u001b[39m0.4694   \u001b[39m | \u001b[39m5.425    \u001b[39m | \u001b[39m10.93    \u001b[39m | \u001b[39m8.6      \u001b[39m | \u001b[39m28.91    \u001b[39m | \u001b[39m0.5811   \u001b[39m |\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m-0.7102  \u001b[39m | \u001b[39m0.7326   \u001b[39m | \u001b[39m5.385    \u001b[39m | \u001b[39m10.44    \u001b[39m | \u001b[39m9.001    \u001b[39m | \u001b[39m28.65    \u001b[39m | \u001b[39m0.8988   \u001b[39m |\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m-0.8806  \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m6.042    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.725    \u001b[39m | \u001b[39m28.89    \u001b[39m | \u001b[39m0.7832   \u001b[39m |\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m-0.7586  \u001b[39m | \u001b[39m0.6865   \u001b[39m | \u001b[39m5.396    \u001b[39m | \u001b[39m10.88    \u001b[39m | \u001b[39m9.225    \u001b[39m | \u001b[39m28.37    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m-0.7168  \u001b[39m | \u001b[39m0.04781  \u001b[39m | \u001b[39m5.556    \u001b[39m | \u001b[39m10.98    \u001b[39m | \u001b[39m9.149    \u001b[39m | \u001b[39m27.69    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m-0.7296  \u001b[39m | \u001b[39m0.7512   \u001b[39m | \u001b[39m5.259    \u001b[39m | \u001b[39m11.0     \u001b[39m | \u001b[39m8.395    \u001b[39m | \u001b[39m28.52    \u001b[39m | \u001b[39m0.571    \u001b[39m |\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m-0.7335  \u001b[39m | \u001b[39m0.446    \u001b[39m | \u001b[39m22.61    \u001b[39m | \u001b[39m9.423    \u001b[39m | \u001b[39m3.172    \u001b[39m | \u001b[39m16.15    \u001b[39m | \u001b[39m0.9564   \u001b[39m |\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m-0.7124  \u001b[39m | \u001b[39m0.5759   \u001b[39m | \u001b[39m19.51    \u001b[39m | \u001b[39m5.388    \u001b[39m | \u001b[39m9.947    \u001b[39m | \u001b[39m2.556    \u001b[39m | \u001b[39m0.9434   \u001b[39m |\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m-0.6876  \u001b[39m | \u001b[39m0.103    \u001b[39m | \u001b[39m5.094    \u001b[39m | \u001b[39m10.55    \u001b[39m | \u001b[39m9.025    \u001b[39m | \u001b[39m28.6     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "=================================================================================================\n",
      "Execution time: 229.09457755088806 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bayes_opt.maximize(init_points=10, n_iter=100)\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = np.argmin([res['target'] for res in bayes_opt.res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.024792137877421433, 'max_depth': 14.023942485367312, 'min_samples_leaf': 3.5758751050275555, 'min_samples_split': 10.468767391901286, 'n_estimators': 2.0458839744440116, 'subsample': 0.6524984224765533}\n"
     ]
    }
   ],
   "source": [
    "best_params = bayes_opt.res[best_iter]['params']\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.024792137877421433, max_depth=14,\n",
       "                          min_samples_leaf=2, min_samples_split=10,\n",
       "                          n_estimators=2, subsample=0.6524984224765533)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.024792137877421433, max_depth=14,\n",
       "                          min_samples_leaf=2, min_samples_split=10,\n",
       "                          n_estimators=2, subsample=0.6524984224765533)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.024792137877421433, max_depth=14,\n",
       "                          min_samples_leaf=2, min_samples_split=10,\n",
       "                          n_estimators=2, subsample=0.6524984224765533)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bs = GradientBoostingRegressor(\n",
    "    learning_rate=(best_params['learning_rate']),\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    subsample=(best_params['subsample']), \n",
    "    min_samples_split=int(best_params['min_samples_split']), \n",
    "    min_samples_leaf=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    loss='squared_error'\n",
    ")\n",
    "best_bs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.96\n",
      "MAPE: 1.02%\n"
     ]
    }
   ],
   "source": [
    "y_pred_bs = best_bs.predict(X_test)\n",
    "rmse_bs = np.sqrt(mean_squared_error(y_test, y_pred_bs))\n",
    "mape_bs = mean_absolute_percentage_error(y_test, y_pred_bs)\n",
    "\n",
    "print(f\"RMSE: {rmse_bs:.2f}\")\n",
    "print(f\"MAPE: {mape_bs:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
